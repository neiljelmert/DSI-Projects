{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "# Project 6\n",
    "\n",
    "\n",
    "## NLP and Machine Learning on [travel.statsexchange.com](http://travel.stackexchange.com/) data\n",
    "\n",
    "---\n",
    "\n",
    "In Project 7 you'll be doing NLP and machine learning on post data from stackexchange's travel subdomain. \n",
    "\n",
    "This project is setup like a mini Kaggle competition. You are given the training data and when projects are submitted your model will be tested on the held-out testing data. There will be prizes for the people who build models that perform best on the held out test set!\n",
    "\n",
    "---\n",
    "\n",
    "## Notes on the data\n",
    "\n",
    "The data is again compressed into the `.7z` file format to save space. There are 6 .csv files and one readme file that contains some information on the fields.\n",
    "\n",
    "    posts_train.csv\n",
    "    comments_train.csv\n",
    "    users.csv\n",
    "    badges.csv\n",
    "    votes_train.csv\n",
    "    tags.csv\n",
    "    readme.txt\n",
    "    \n",
    "The data is located in your datasets folder:\n",
    "\n",
    "    DSI-SF-2/datasets/stack_exchange_travel.7z\n",
    "    \n",
    "If you're interested in where this data came from and where to get more data from other stackexchange subdomains, see here:\n",
    "\n",
    "https://ia800500.us.archive.org/22/items/stackexchange/readme.txt\n",
    "\n",
    "\n",
    "### Recommended Utilities for .7z\n",
    "\n",
    "- For OSX [Keka](http://www.kekaosx.com/en/) or [The Unarchiver](http://wakaba.c3.cx/s/apps/unarchiver.html). \n",
    "- For Windows [7-zip](http://www.7-zip.org/) is the standard. \n",
    "- For Linux try the `p7zip` utility.  `sudo apt-get install p7zip`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path = \"/Users/ga/Desktop/DSI-SF-3_repo/DSI-SF-3/datasets/stack_exchange_travel/\"\n",
    "posts_train = pd.read_csv(path + \"posts_train.csv\")\n",
    "comments_train = pd.read_csv(path + \"comments_train.csv\")\n",
    "users = pd.read_csv(path + \"users.csv\")\n",
    "badges = pd.read_csv(path + \"badges.csv\")\n",
    "votes_train = pd.read_csv(path + \"votes_train.csv\")\n",
    "tags = pd.read_csv(path + \"tags.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posts1 = posts_train[[\"Id\", \"Body\", \"Tags\", \"Title\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments1 = comments_train[[\"PostId\", \"Text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comments1_agg = pd.DataFrame(comments1.groupby(\"PostId\")[\"Text\"].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "comments1_agg[\"PostId\"] = comments1_agg.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text      0\n",
       "PostId    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for nulls and drop\n",
    "comments1_agg.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id           0\n",
       "Body       813\n",
       "Tags     27301\n",
       "Title    27301\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40476, 2) Id      0\n",
      "Body    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Since there are way too many nulls on Tags and Title, we'll ignore these columns\n",
    "posts1 = posts1[[\"Id\", \"Body\"]]\n",
    "posts1.dropna(axis=0, inplace=True)\n",
    "print posts1.shape, posts1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Merge (left) posts1 and comments1_agg on Id, PostId resp.\n",
    "posts_comments = pd.merge(posts1, comments1_agg, how = \"left\", left_on = \"Id\", right_on = \"PostId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Body</th>\n",
       "      <th>Text</th>\n",
       "      <th>PostId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>&lt;p&gt;My fiancée and I are looking for a good Car...</td>\n",
       "      <td>To help with the cruise line question: Where a...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>&lt;p&gt;Singapore Airlines has an all-business clas...</td>\n",
       "      <td>This route (as well as LAX-SIN) is being cance...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>&lt;p&gt;Another definition question that interested...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>&lt;p&gt;Can anyone suggest the best way to get from...</td>\n",
       "      <td>To those voting down, please explain why with ...</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>&lt;p&gt;We are considering visiting Argentina for u...</td>\n",
       "      <td>I agree with @user27478, you need to specify w...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                               Body  \\\n",
       "0   1  <p>My fiancée and I are looking for a good Car...   \n",
       "1   4  <p>Singapore Airlines has an all-business clas...   \n",
       "2   5  <p>Another definition question that interested...   \n",
       "3   8  <p>Can anyone suggest the best way to get from...   \n",
       "4   9  <p>We are considering visiting Argentina for u...   \n",
       "\n",
       "                                                Text  PostId  \n",
       "0  To help with the cruise line question: Where a...     1.0  \n",
       "1  This route (as well as LAX-SIN) is being cance...     4.0  \n",
       "2                                                NaN     NaN  \n",
       "3  To those voting down, please explain why with ...     8.0  \n",
       "4  I agree with @user27478, you need to specify w...     9.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Deal with the NaNs and combine body/text\n",
    "tres = zip(posts_comments.Body, posts_comments.Text, posts_comments.PostId)\n",
    "comb = [bod if np.isnan(pid) else bod + txt for bod, txt, pid in tres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40476"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_html(x):\n",
    "    soup = BeautifulSoup(x, \"lxml\")\n",
    "    return soup.get_text()\n",
    "\n",
    "cleaned_comb = map(remove_html, comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'My fianc\\xe9e and I are looking for a good Caribbean cruise in October and were wondering which islands are best to see and which Cruise line to take?\\nIt seems like a lot of the cruises don\\'t run in this month due to Hurricane season so I\\'m looking for other good options.\\nEDIT We\\'ll be travelling in 2012.\\nTo help with the cruise line question: Where are you located? My wife and I live in New Orleans, so we sail out of the port here. It limits us mainly to Carnival (though we are getting some more cruise lines in here), but saves us money on travel expenses getting *to* the port. If you\\'re closer to a specific port, and like the cruises offered out of it, then it would make more sense to choose a cruise line from there.Toronto, Ontario. We can fly out of anywhere though.\"Best\" for what?  Please read [this page](http://travel.stackexchange.com/questions/how-to-ask-beta) and particularly the blog posts linked on the right.What do you want out of a cruise? To relax on a boat? To visit islands? Culture? Adventure? Extreme sports? I think this question is still way too general.']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_comb[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "back_df = {\"PostId\": posts1[\"Id\"], \"Text\": cleaned_comb}\n",
    "\n",
    "df = pd.DataFrame(back_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PostId</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>My fiancée and I are looking for a good Caribb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Singapore Airlines has an all-business class f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Another definition question that interested me...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>Can anyone suggest the best way to get from Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>We are considering visiting Argentina for up t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PostId                                               Text\n",
       "0       1  My fiancée and I are looking for a good Caribb...\n",
       "1       4  Singapore Airlines has an all-business class f...\n",
       "2       5  Another definition question that interested me...\n",
       "3       8  Can anyone suggest the best way to get from Se...\n",
       "4       9  We are considering visiting Argentina for up t..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "### 1. Use LDA to find what topics are discussed on travel.stackexchange.com.\n",
    "\n",
    "---\n",
    "\n",
    "Text can be found in the posts and the comments datasets. The `ParentId` column in the posts dataset indicates what the \"question\" post was for a given post. Comment text can be merged onto the post they are part of with the `PostId` field.\n",
    "\n",
    "The text may have some HTML tags. BeautifulSoup has convenient ways to get rid of markup or extract text if you need to. You can also parse the strings yourself if you like.\n",
    "\n",
    "The tags dataset has the \"tags\" that the users have officially given the post.\n",
    "\n",
    "**1.1 Implement LDA against the text features of the dataset(s).**\n",
    "\n",
    "- This can be posts or a combination of posts and comments if you want more power.\n",
    "- Find optimal **K/num_topics**.\n",
    "\n",
    "**1.2 Compare your topics to the tags. Do the LDA topics make sense? How do they compare to the tags?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.9, max_features=None, min_df=0.025,\n",
       "        ngram_range=(1, 3), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tvec = TfidfVectorizer(stop_words='english', \n",
    "                        ngram_range=(1,3), \n",
    "                        min_df = 0.025, max_df = 0.9)\n",
    "tvec.fit(df[\"Text\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf-idf features for NMF...\n",
      "done in 81.908s.\n",
      "Extracting tf features for LDA...\n",
      "done in 16.725s.\n",
      "Fitting the NMF model with tf-idf features, n_samples=2000 and n_features=1000...\n",
      "done in 10.435s.\n",
      "\n",
      "Topics in NMF model:\n",
      "Topic #0:\n",
      "like just people don time know ve good want think really place city question places ll going way answer make\n",
      "Topic #1:\n",
      "visa transit uk need apply application visas entry valid visit tourist embassy visitor canada citizen indian immigration enter stay india\n",
      "Topic #2:\n",
      "airport international transit city terminal airports hours located security code taxi layover area hour need luggage london main domestic minutes\n",
      "Topic #3:\n",
      "passport passports country new enter id valid uk citizen travel stamp old countries border immigration expired citizenship eu document british\n",
      "Topic #4:\n",
      "train bus station trains ticket tickets buses day hours journey buy time route rail minutes way london line transport taxi\n",
      "Topic #5:\n",
      "schengen days area 90 country stay entry eu visa countries france germany border 180 residence day enter permit italy period\n",
      "Topic #6:\n",
      "flight airline flights airlines ticket check luggage baggage air tickets checked time booking bag plane seat flying bags boarding fly\n",
      "Topic #7:\n",
      "car rental insurance drive driving license rent cars road driver company companies vehicle parking drivers roads traffic need park way\n",
      "Topic #8:\n",
      "card credit cards sim cash bank use phone money pay buy atm data exchange account ticket currency mobile fees fee\n",
      "Topic #9:\n",
      "http com questions travel www stackexchange question travelling specifically related answer site en html passports https uk topic org duplicate\n",
      "\n",
      "Fitting LDA models with tf features, n_samples=2000 and n_features=1000...\n",
      "done in 91.576s.\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0:\n",
      "visa passport uk schengen country need travel entry days apply stay application enter valid eu visit immigration visas citizen countries\n",
      "Topic #1:\n",
      "card use credit bank phone money pay cards data cash account service need id buy fee exchange number free charge\n",
      "Topic #2:\n",
      "car insurance france driving germany drive rental italy license spain driver pay company rent french price speed cars german tax\n",
      "Topic #3:\n",
      "airport flight time hours transit terminal international need airports minutes hour flights pass layover leave departure heathrow plane boarding day\n",
      "Topic #4:\n",
      "country countries south border china states new north state city europe canada island russia mexico america russian australia sea united\n",
      "Topic #5:\n",
      "people india water use food japan just like right used usually don law common case person legal japanese police rules\n",
      "Topic #6:\n",
      "train bus station day trains city time london route way paris public maps hours trip transport buses map want google\n",
      "Topic #7:\n",
      "question like just don http com know answer travel people ve want time think good really www hotel going questions\n",
      "Topic #8:\n",
      "luggage check customs bag carry security baggage checked bags airline items allowed passengers just plane bring dubai airlines need case\n",
      "Topic #9:\n",
      "ticket flight airline tickets airlines flights booking travel seat book fare price booked class seats return way air buy fly\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_topics = 10\n",
    "n_top_words = 20\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "\n",
    "\n",
    "# Use tf-idf features for NMF.\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(df[\"Text\"])\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(df[\"Text\"])\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model with tf-idf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_topics, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model:\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)\n",
    "\n",
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In LDA model, looks like\n",
    "    # Topic 0: travel documents / travel\n",
    "    # Topic 1: financials\n",
    "    # Topic 2: auto-related / car rent\n",
    "    # Topic 3: airports / flights\n",
    "    # Topic 4: countries / countries to visit\n",
    "    # Topic 5: oriental countries / law / food\n",
    "    # Topic 6: public transportation\n",
    "    # Topic 7: Ambiguous...\n",
    "    # Topic 8: security / luggage / airlines\n",
    "    # Topic 9: airline tickets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tags = posts1[\"Tags\"].dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_list = []\n",
    "def parse_tags(tags_series):\n",
    "    for tags in tags_series:\n",
    "        tags = tags.split(\"><\")\n",
    "        for tag in tags:\n",
    "            tag = tag.replace(\"<\", \"\")\n",
    "            tag = tag.replace(\">\", \"\")\n",
    "            tag_list.append(tag)\n",
    "    return tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parsed_tags = parse_tags(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('visas', 5551),\n",
       " ('air-travel', 3304),\n",
       " ('usa', 3123),\n",
       " ('schengen', 2216),\n",
       " ('uk', 2128),\n",
       " ('customs-and-immigration', 1522),\n",
       " ('transit', 1458),\n",
       " ('trains', 1281),\n",
       " ('public-transport', 1061),\n",
       " ('passports', 1020),\n",
       " ('tickets', 986),\n",
       " ('luggage', 978),\n",
       " ('budget', 977),\n",
       " ('legal', 922),\n",
       " ('europe', 881),\n",
       " ('canada', 878),\n",
       " ('indian-citizens', 840),\n",
       " ('online-resources', 814),\n",
       " ('india', 802),\n",
       " ('france', 794),\n",
       " ('germany', 770),\n",
       " ('japan', 716),\n",
       " ('international-travel', 714),\n",
       " ('airports', 708),\n",
       " ('safety', 628),\n",
       " ('airlines', 590),\n",
       " ('money', 568),\n",
       " ('health', 546),\n",
       " ('planning', 531),\n",
       " ('food-and-drink', 524)]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(parsed_tags).most_common()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# It looks like the most common tags are pretty in line with the topics\n",
    "# what the hell is schengen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "### 2. What makes an answer likely to be \"accepted\"?\n",
    "\n",
    "---\n",
    "\n",
    "**2.1 Build a model to predict whether a post will be marked as the answer.**\n",
    "\n",
    "- This is a classification problem.\n",
    "- You're free to use any of the machine learning algorithms or techniques we have learned in class to build the best model you can.\n",
    "- NLP will be very useful here for pulling out useful and relevant features from the data. \n",
    "- Though not required, using bagging and boosting models like Random Forests and Gradient Boosted Trees will _probably_ get you the highest performance on the test data (but who knows!).\n",
    "\n",
    "\n",
    "**2.2 Evaluate the performance of your classifier with a confusion matrix and accuracy. Explain how your model is performing.**\n",
    "\n",
    "**2.3 Plot either a ROC curve or precision-recall curve (or both!) and explain what they tell you about your model.**\n",
    "\n",
    "NOTE: You should only be predicting this for `PostTypeID=2` posts, which are the \"answer\" posts. This doesn't mean, however, that you can't or shouldn't use the parent questions as predictors!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AcceptedAnswerId</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>Body</th>\n",
       "      <th>ClosedDate</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>CommunityOwnedDate</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>FavoriteCount</th>\n",
       "      <th>Id</th>\n",
       "      <th>LastActivityDate</th>\n",
       "      <th>...</th>\n",
       "      <th>LastEditorUserId</th>\n",
       "      <th>OwnerDisplayName</th>\n",
       "      <th>OwnerUserId</th>\n",
       "      <th>ParentId</th>\n",
       "      <th>PostTypeId</th>\n",
       "      <th>Score</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Title</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>Accepted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>393.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;p&gt;My fiancée and I are looking for a good Car...</td>\n",
       "      <td>2013-02-25T23:52:47.953</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:19:34.730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2012-05-24T14:52:14.760</td>\n",
       "      <td>...</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;caribbean&gt;&lt;cruising&gt;&lt;vacations&gt;</td>\n",
       "      <td>What are some Caribbean cruises for October?</td>\n",
       "      <td>361.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>&lt;p&gt;Singapore Airlines has an all-business clas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:24:57.160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-09T09:55:22.743</td>\n",
       "      <td>...</td>\n",
       "      <td>693.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;loyalty-programs&gt;&lt;routes&gt;&lt;ewr&gt;&lt;singapore-airl...</td>\n",
       "      <td>Does Singapore Airlines offer any reward seats...</td>\n",
       "      <td>219.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>770.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>&lt;p&gt;Another definition question that interested...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:25:56.787</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2012-10-12T20:49:08.110</td>\n",
       "      <td>...</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;romania&gt;&lt;transportation&gt;</td>\n",
       "      <td>What is the easiest transportation to use thro...</td>\n",
       "      <td>340.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>&lt;p&gt;Can anyone suggest the best way to get from...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:30:38.687</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2016-03-28T03:41:28.130</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>&lt;usa&gt;&lt;airport-transfer&gt;&lt;taxis&gt;&lt;seattle&gt;</td>\n",
       "      <td>Best way to get from SeaTac airport to Redmond?</td>\n",
       "      <td>9219.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>178.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;p&gt;We are considering visiting Argentina for u...</td>\n",
       "      <td>2016-01-02T10:26:48.277</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-21T20:31:21.800</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>2016-01-01T21:58:02.303</td>\n",
       "      <td>...</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>&lt;sightseeing&gt;&lt;public-transport&gt;&lt;transportation...</td>\n",
       "      <td>What are must-visit destinations for the first...</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AcceptedAnswerId  AnswerCount  \\\n",
       "0             393.0          4.0   \n",
       "1               NaN          1.0   \n",
       "2             770.0          5.0   \n",
       "3              62.0          3.0   \n",
       "4             178.0          4.0   \n",
       "\n",
       "                                                Body               ClosedDate  \\\n",
       "0  <p>My fiancée and I are looking for a good Car...  2013-02-25T23:52:47.953   \n",
       "1  <p>Singapore Airlines has an all-business clas...                      NaN   \n",
       "2  <p>Another definition question that interested...                      NaN   \n",
       "3  <p>Can anyone suggest the best way to get from...                      NaN   \n",
       "4  <p>We are considering visiting Argentina for u...  2016-01-02T10:26:48.277   \n",
       "\n",
       "   CommentCount CommunityOwnedDate             CreationDate  FavoriteCount  \\\n",
       "0             4                NaN  2011-06-21T20:19:34.730            NaN   \n",
       "1             1                NaN  2011-06-21T20:24:57.160            NaN   \n",
       "2             0                NaN  2011-06-21T20:25:56.787            2.0   \n",
       "3             2                NaN  2011-06-21T20:30:38.687            1.0   \n",
       "4             1                NaN  2011-06-21T20:31:21.800            8.0   \n",
       "\n",
       "   Id         LastActivityDate   ...    LastEditorUserId OwnerDisplayName  \\\n",
       "0   1  2012-05-24T14:52:14.760   ...               101.0              NaN   \n",
       "1   4  2013-01-09T09:55:22.743   ...               693.0              NaN   \n",
       "2   5  2012-10-12T20:49:08.110   ...               101.0              NaN   \n",
       "3   8  2016-03-28T03:41:28.130   ...                 NaN              NaN   \n",
       "4   9  2016-01-01T21:58:02.303   ...               101.0              NaN   \n",
       "\n",
       "   OwnerUserId ParentId  PostTypeId  Score  \\\n",
       "0          9.0      NaN           1      8   \n",
       "1         24.0      NaN           1      8   \n",
       "2         13.0      NaN           1     11   \n",
       "3         26.0      NaN           1     11   \n",
       "4         23.0      NaN           1     12   \n",
       "\n",
       "                                                Tags  \\\n",
       "0                   <caribbean><cruising><vacations>   \n",
       "1  <loyalty-programs><routes><ewr><singapore-airl...   \n",
       "2                          <romania><transportation>   \n",
       "3            <usa><airport-transfer><taxis><seattle>   \n",
       "4  <sightseeing><public-transport><transportation...   \n",
       "\n",
       "                                               Title ViewCount Accepted  \n",
       "0       What are some Caribbean cruises for October?     361.0        0  \n",
       "1  Does Singapore Airlines offer any reward seats...     219.0        0  \n",
       "2  What is the easiest transportation to use thro...     340.0        0  \n",
       "3    Best way to get from SeaTac airport to Redmond?    9219.0        0  \n",
       "4  What are must-visit destinations for the first...    1503.0        0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts2 = posts_train.copy()\n",
    "acc_posts = list(posts_train[\"AcceptedAnswerId\"].unique())\n",
    "acc_posts = [post for post in acc_posts if not np.isnan(post)]\n",
    "posts2[\"Accepted\"] = np.zeros(posts2.shape[0], dtype = np.int8)\n",
    "posts2.loc[posts_train[\"Id\"].isin(acc_posts), \"Accepted\"] = 1\n",
    "posts2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = posts2.loc[posts2.PostTypeId == 2, \"Accepted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = posts2.loc[posts2.PostTypeId == 2, [\"Score\", \"ViewCount\", \"AnswerCount\", \"CommentCount\", \"FavoriteCount\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>ViewCount</th>\n",
       "      <th>AnswerCount</th>\n",
       "      <th>CommentCount</th>\n",
       "      <th>FavoriteCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Score  ViewCount  AnswerCount  CommentCount  FavoriteCount\n",
       "9      10        0.0          0.0             3            0.0\n",
       "10     51        0.0          0.0             3            0.0\n",
       "11     10        0.0          0.0             1            0.0\n",
       "16     10        0.0          0.0             4            0.0\n",
       "18     26        0.0          0.0             5            0.0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72891893019568565"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=100)\n",
    "scores = cross_val_score(clf, X, y)\n",
    "scores.mean()                             \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "### 3. What is the score of a post?\n",
    "\n",
    "---\n",
    "\n",
    "**3.1 Build a model that predicts the score of a post.**\n",
    "\n",
    "- This is a regression problem now. \n",
    "- You can and should be predicting score for both \"question\" and \"answer\" posts, so keep them both in your dataset.\n",
    "- Again, use any techniques that you think will get you the best model.\n",
    "\n",
    "**3.2 Evaluate the performance of your model with cross-validation and report the results.**\n",
    "\n",
    "**3.3 What is important for determining the score of a post, if anything?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "### 4. How many views does a post have?\n",
    "\n",
    "---\n",
    "\n",
    "**4.1 Build a model that predicts the number of views a post has.**\n",
    "\n",
    "- This is another regression problem. \n",
    "- Predict the views for all posts, not just the \"answer\" posts.\n",
    "\n",
    "**4.2 Evaluate the performance of your model with cross-validation and report the results.**\n",
    "\n",
    "**4.3 What is important for the number of views a post has, if anything?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "### 5. Build a pipeline or other code to automate evaluation of your models on the test data.\n",
    "\n",
    "---\n",
    "\n",
    "Now that you've constructed your three predictive models, build a pipeline or code that can easily load up the raw testing data and evaluate your models on it.\n",
    "\n",
    "The testing data that is held out is in the same raw format as the training data you have. _Any cleaning and preprocessing that you did on the training data will need to be done on the testing data as well!_\n",
    "\n",
    "This is a good opportunity to practice building pipelines, but you're not required to. Custom functions and classes are fine as long as they are able to process and test the new data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/xDpSobf.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 6. Lets Model - Tournament for stock market predictions\n",
    "\n",
    ">Start this section of the project by downloading the train and test datasets from the following site: https://numer.ai/rules\n",
    "\n",
    "> - The data set is clean, your goal is to develop a classification model(s) \n",
    "> - Report all the results including log loss, and other coefficients you consider iteresting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
