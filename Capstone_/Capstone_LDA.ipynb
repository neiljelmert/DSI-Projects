{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ga/anaconda/envs/dsi/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "import urllib2\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import requests\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "\n",
    "sns.set_style(\"darkgrid\", {\"text.color\": \".1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_statml = pd.read_csv(\"StatMLPapers_tweets.csv\")\n",
    "df_statml['year'] = 2016\n",
    "df_statml['genre'] = 'ML'\n",
    "df_statml['source'] = 'Twitter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_16_NIPS = pd.read_csv('/Users/ga/Desktop/Capstone/open_review_abstracts_NIPS2016.csv')\n",
    "df_16_NIPS['year'] = 2016\n",
    "df_16_NIPS['genre'] = 'ML'\n",
    "df_16_NIPS['source'] = 'NIPS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_17_ICLR = pd.read_csv('/Users/ga/Desktop/Capstone/open_review_abstracts_ICLR2017.csv')\n",
    "df_17_ICLR['year'] = 2017\n",
    "df_17_ICLR['genre'] = 'DL'\n",
    "df_17_ICLR['source'] = 'ICLR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_16_NIPS_NAMPI = pd.read_csv('/Users/ga/Desktop/Capstone/open_review_abstracts_NIPS16_NAMPI.csv')\n",
    "df_16_NIPS_NAMPI['year'] = 2016\n",
    "df_16_NIPS_NAMPI['genre'] = 'ML'\n",
    "df_16_NIPS_NAMPI['source'] = 'NIPS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_16_NIPS_MLITS = pd.read_csv('/Users/ga/Desktop/Capstone/open_review_abstracts_NIPS16_MLITS.csv')\n",
    "df_16_NIPS_MLITS['year'] = 2016\n",
    "df_16_NIPS_MLITS['genre'] = 'ML'\n",
    "df_16_NIPS_MLITS['source'] = 'NIPS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_16_ICLR = pd.read_csv('/Users/ga/Desktop/Capstone/open_review_abstracts_ICLR16.csv')\n",
    "df_16_ICLR['year'] = 2016\n",
    "df_16_ICLR['genre'] = 'DL'\n",
    "df_16_ICLR['source'] = 'ICLR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_CVPR_16 = pd.read_csv('/Users/ga/Desktop/Capstone/CVPR_2016/cvpr_2016.csv')\n",
    "df_CVPR_16['year'] = 2016\n",
    "df_CVPR_16['genre'] = 'CV'\n",
    "df_CVPR_16['source'] = 'CVPR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_CVPR_15 = pd.read_csv('/Users/ga/Desktop/Capstone/CVPR_2016/cvpr_2015.csv')\n",
    "df_CVPR_15['year'] = 2015\n",
    "df_CVPR_15['genre'] = 'CV'\n",
    "df_CVPR_15['source'] = 'CVPR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_CVPR_14 = pd.read_csv('/Users/ga/Desktop/Capstone/CVPR_2016/cvpr_2014.csv')\n",
    "df_CVPR_14['year'] = 2014\n",
    "df_CVPR_14['genre'] = 'CV'\n",
    "df_CVPR_14['source'] = 'CVPR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_CVPR_13 = pd.read_csv('/Users/ga/Desktop/Capstone/CVPR_2016/cvpr_2013.csv')\n",
    "df_CVPR_13['year'] = 2013\n",
    "df_CVPR_13['genre'] = 'CV'\n",
    "df_CVPR_13['source'] = 'CVPR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_NIPS = pd.read_csv('/Users/ga/Desktop/Capstone/NIPS/NIPS.csv')\n",
    "df_NIPS['genre'] = 'ML'\n",
    "df_NIPS['source'] = 'NIPS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_JMLR_16 = pd.read_csv('/Users/ga/Desktop/Capstone/JMLR/JMLR_16.csv')\n",
    "df_JMLR_16['genre'] = 'ML'\n",
    "df_JMLR_16['source'] = 'JMLR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_JMLR_15 = pd.read_csv('/Users/ga/Desktop/Capstone/JMLR/JMLR_15.csv')\n",
    "df_JMLR_15['genre'] = 'ML'\n",
    "df_JMLR_15['source'] = 'JMLR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_JMLR_14 = pd.read_csv('/Users/ga/Desktop/Capstone/JMLR/JMLR_14.csv')\n",
    "df_JMLR_14['genre'] = 'ML'\n",
    "df_JMLR_14['source'] = 'JMLR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_JMLR_13 = pd.read_csv('/Users/ga/Desktop/Capstone/JMLR/JMLR_13.csv')\n",
    "df_JMLR_13['genre'] = 'ML'\n",
    "df_JMLR_13['source'] = 'JMLR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_arxiv = pd.read_csv(\"/Users/ga/Desktop/Capstone/reddit/reddit_scraped_arxivs.csv\")\n",
    "df_arxiv['year'] = 2016\n",
    "df_arxiv['genre'] = 'ML'\n",
    "df_arxiv['source'] = 'arXiv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_open_rev = pd.read_csv(\"/Users/ga/Desktop/Capstone/reddit/reddit_scraped_openreview.csv\")\n",
    "df_open_rev['year'] = 2016\n",
    "df_open_rev['genre'] = 'ML'\n",
    "df_open_rev['source'] = 'OpenReview'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_open_rev_s = df_open_rev[['title', 'abstract', 'genre', 'source', 'year']]\n",
    "df_arxiv_s = df_arxiv[['title', 'abstract', 'genre', 'source', 'year']]\n",
    "df_statml_s = df_statml[['text', 'abstract', 'genre', 'source', 'year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None \n",
    "\n",
    "#find = re.compile(r\"^(.*?)\\..*\")\n",
    "new_text = []\n",
    "find = re.compile(r\"^([^.]*).*\")\n",
    "for l in df_statml_s['text']:\n",
    "    m = re.match(find, l)\n",
    "    new_text.append(m.group(1))\n",
    "\n",
    "df_statml_s['title'] = new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_statml_s.drop([\"text\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frames = [df_statml_s, df_arxiv_s, df_open_rev_s, df_JMLR_13, df_JMLR_14, df_JMLR_15,\n",
    "         df_JMLR_16, df_CVPR_13, df_CVPR_14, df_CVPR_15, df_CVPR_16, df_16_ICLR,\n",
    "         df_16_NIPS_MLITS, df_16_NIPS_NAMPI, df_17_ICLR, df_16_NIPS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = pd.concat(frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7503, 5)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6806"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result.abstract.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6759"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unik_titles = result.title.unique().tolist()\n",
    "len(result.title.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = result.drop_duplicates(\"abstract\")\n",
    "result = result.drop_duplicates(\"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6605, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6605"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result.title.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result['abstract'] = result['abstract'].str.replace('Abstract:?' , '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result['title'] = result['title'].str.replace('\\[R\\]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3722, 5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result.year == 2016].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(867, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result.year == 2015].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(849, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result.year == 2014].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(753, 5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result.year == 2013].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(414, 5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result.year == 2017].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genre</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CV</th>\n",
       "      <td>2247</td>\n",
       "      <td>2247</td>\n",
       "      <td>2247</td>\n",
       "      <td>2247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DL</th>\n",
       "      <td>518</td>\n",
       "      <td>518</td>\n",
       "      <td>518</td>\n",
       "      <td>518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML</th>\n",
       "      <td>3839</td>\n",
       "      <td>3840</td>\n",
       "      <td>3840</td>\n",
       "      <td>3840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       abstract  source  title  year\n",
       "genre                               \n",
       "CV         2247    2247   2247  2247\n",
       "DL          518     518    518   518\n",
       "ML         3839    3840   3840  3840"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.groupby(['genre']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year\n",
       "2013    0.114005\n",
       "2014    0.128539\n",
       "2015    0.131264\n",
       "2016    0.563512\n",
       "2017    0.062680\n",
       "Name: title, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.groupby(['year'])['title'].count()/result.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([6142, 6143, 6144, 6145, 6146, 6147, 6148, 6149, 6150, 6151, 6152,\n",
       "            6153, 6154, 6569, 6570, 6571, 6572, 6573, 6574, 6575, 6576, 6577,\n",
       "            6578, 6579, 6580, 6581, 6582, 6583, 6584, 6585, 6586, 6587, 6588,\n",
       "            6589, 6590, 6591, 6592, 6593, 6594, 6595, 6596, 6597, 6598, 6599,\n",
       "            6600, 6601, 6602, 6603, 6604],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[result['source'] == 'NIPS'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6605, 5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = pd.DataFrame(result.groupby(['year', 'genre'])[\"title\"].count()).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1199cb290>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAE4CAYAAABVMDj3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11a93c850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result.groupby(['year', 'genre']).count()[\"title\"].plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_abs = result['abstract'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import enchant \n",
    "import inflect\n",
    "p = inflect.engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'analysi'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.singular_noun(\"analysis\", count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bad_words = ['tasks', 'methods', 'using', 'propose', 'based', 'problem',\n",
    "            'results', 'method', 'different', 'demonstrate', 'paper',\n",
    "            'approach', 'task', 'used', 'proposed', 'provide', 'study'\n",
    "            'use', 'problems', 'work', 'present', \"es\", \"al\", \"et\", \"em\", \"ed\", \"ca\", \n",
    "            \"ial\", \"rl\", \"i\", \"ii\", \"iii\", \"res\", \"ing\", \"ts\", 'consider', \n",
    "            'include', 'issue', 'follow', 'remain', 'reation', \n",
    "            'achiev', 'techniqu', 'mage', 'cifar', 'learnng', 'ful', \n",
    "            'gorithms', 'ths', 'gorithm', 'featur', 'ful', 'subs', 'rs', 'ell']\n",
    "\n",
    "bad_symb = ['\\\\',',','^',';',':','/','`','*','_','`','~','%','&','|','@',\n",
    "               '{','}','[',']','(',')','>','<','\"','#','+','.','!','=','?','$','\\'']\n",
    "\n",
    "def abstract_cleaner(abstract):\n",
    "    is_english = enchant.Dict(\"en_US\")\n",
    "    abstract = \"\".join([i for i in abstract if not i.isdigit()])\n",
    "    abstract = abstract.replace(\"\\n\", \" \")\n",
    "    abstract = abstract.replace(\"-\", \"\")\n",
    "    for char in bad_symb:\n",
    "        if char in abstract:\n",
    "            abstract = abstract.replace(char, \"\")\n",
    "    for char in bad_words:\n",
    "        if char.strip() in abstract.split(\" \"):\n",
    "            abstract = abstract.replace(char, \"\")\n",
    "    for word in abstract:\n",
    "        if not is_english.check(word):\n",
    "            abstract = abstract.replace(word, \"\")\n",
    "#     for word in abstract.split(\" \"):                            # first word squash original\n",
    "#         if word in first_word_squasher.keys():\n",
    "#             abstract = abstract.replace(word, first_word_squasher[word])    # if mess up, delete,\n",
    "#     for word in abstract.split(\" \"):                               # try again\n",
    "#         if p.singular_noun(word, count=None) is not False:\n",
    "#             abstract = abstract.replace(word, p.singular_noun(word, count=None))\n",
    "    abstract = filter(None, abstract)\n",
    "    return abstract "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_abs = map(str, result_abs)\n",
    "result_abs = map(abstract_cleaner, result_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def first_word_squash(abstract):\n",
    "    for word in abstract.split(\" \"):                            # first word squash original\n",
    "        if word in first_word_squasher.keys():\n",
    "            abstract = abstract.replace(word, first_word_squasher[word]) \n",
    "    return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_abs = map(first_word_squash, result_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def second_word_squash(abstract):\n",
    "    for word in abstract.split(\" \"):   \n",
    "        word_strip = word.strip()\n",
    "        # first word squash original\n",
    "        if word_strip in second_word_squasher.keys():\n",
    "            abstract = abstract.replace(word, second_word_squasher[word_strip]) \n",
    "    return abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_abs = map(second_word_squash, result_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dl_abs = result[result.genre=='DL']['abstract'].tolist()\n",
    "dl_abs_join = \" \".join(str(v) for v in dl_abs)\n",
    "dl_abs_join = \"\".join([i for i in dl_abs_join if not i.isdigit()])\n",
    "dl_abs_join = dl_abs_join.replace(\"\\n\", \" \")\n",
    "dl_abs_join = dl_abs_join.replace(\".\", \"\")\n",
    "dl_abs_split = dl_abs_join.split(\" \")\n",
    "dl_abs_split = filter(None, dl_abs_split) # fastest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ml_abs = result[result.genre=='ML']['abstract'].tolist()\n",
    "ml_abs_join = \" \".join(str(v) for v in ml_abs)\n",
    "ml_abs_join = \"\".join([i for i in ml_abs_join if not i.isdigit()])\n",
    "ml_abs_join = ml_abs_join.replace(\"\\n\", \" \")\n",
    "ml_abs_join = ml_abs_join.replace(\".\", \"\")\n",
    "ml_abs_split = ml_abs_join.split(\" \")\n",
    "ml_abs_split = filter(None, ml_abs_split) # fastest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_abs = result[result.genre=='CV']['abstract'].tolist()\n",
    "cv_abs_join = \" \".join(str(v) for v in cv_abs)\n",
    "cv_abs_join = \"\".join([i for i in cv_abs_join if not i.isdigit()])\n",
    "cv_abs_join = cv_abs_join.replace(\"\\n\", \" \")\n",
    "cv_abs_join = cv_abs_join.replace(\".\", \"\")\n",
    "cv_abs_split = cv_abs_join.split(\" \")\n",
    "cv_abs_split = filter(None, cv_abs_split) # fastest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ml_abs_join = ml_abs_join.replace('infinitedimensional', 'infinite dimensional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "s=set(stopwords.words('english'))\n",
    "\n",
    "new_s = s\n",
    "for sw in list(s):\n",
    "    new_s.add(sw.title())\n",
    "    \n",
    "nonstop_dl = filter(lambda w: not w in new_s, dl_abs_split)\n",
    "nonstop_ml = filter(lambda w: not w in new_s, ml_abs_split)\n",
    "nonstop_cv = filter(lambda w: not w in new_s, cv_abs_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# counts = Counter(nonstop_dl)\n",
    "# print counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from itertools import dropwhile\n",
    "\n",
    "# for key, count in dropwhile(lambda key_count: key_count[1] >= 2, counts.most_common()):\n",
    "#     del counts[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# labels, values = zip(*counts.items())\n",
    "# values = sorted(values)\n",
    "\n",
    "# indexes = np.arange(len(labels))\n",
    "# width = 1\n",
    "\n",
    "# plt.bar(indexes, values, width)\n",
    "# #plt.xticks(indexes + width * 0.1, labels)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dl = ' '.join(nonstop_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ml = ' '.join(nonstop_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = ' '.join(nonstop_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.97, max_features=None, min_df=0.005,\n",
       "        ngram_range=(1, 3), preprocessor=None, stop_words='english',\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvec = CountVectorizer(stop_words='english', min_df=0.005, max_df=0.97, ngram_range=(1,3))\n",
    "cvec.fit(result_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_countvect  = pd.DataFrame(cvec.transform(result_abs).todense(),\n",
    "             columns=cvec.get_feature_names())\n",
    "\n",
    "#df = df.transpose().sort_values(0, ascending=False).transpose()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Twitter', 'arXiv', 'OpenReview', 'JMLR', 'CVPR', 'ICLR', 'NIPS'], dtype=object)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.source.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_count_NIPS = df_countvect.iloc[result[result.source=='NIPS'].index,:]\n",
    "df_count_Twitter = df_countvect.iloc[result[result.source=='Twitter'].index,:]\n",
    "df_count_arXiv = df_countvect.iloc[result[result.source=='arXiv'].index,:]\n",
    "df_count_OpenReview = df_countvect.iloc[result[result.source=='OpenReview'].index,:]\n",
    "df_count_CVPR = df_countvect.iloc[result[result.source=='CVPR'].index,:]\n",
    "df_count_ICLR = df_countvect.iloc[result[result.source=='ICLR'].index,:]\n",
    "df_count_JMLR = df_countvect.iloc[result[result.source=='JMLR'].index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plurals = ['algorithms', 'models', 'features', 'datasets', 'errors', 'functions',\n",
    "          'variables', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_count_Twitter.sum(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model                         7529\n",
       "data                          5292\n",
       "algorithm                     5150\n",
       "learning                      4628\n",
       "imag                          4253\n",
       "network                       2791\n",
       "feature                       2777\n",
       "dataset                       2694\n",
       "performance                   2426\n",
       "new                           2272\n",
       "object                        2241\n",
       "function                      2122\n",
       "set                           2106\n",
       "use                           2085\n",
       "training                      1836\n",
       "structure                     1832\n",
       "neural                        1730\n",
       "large                         1719\n",
       "number                        1650\n",
       "deep                          1631\n",
       "novel                         1613\n",
       "stateoftheart                 1611\n",
       "time                          1566\n",
       "information                   1528\n",
       "framework                     1443\n",
       "optimization                  1443\n",
       "distribution                  1439\n",
       "classification                1436\n",
       "sample                        1365\n",
       "space                         1335\n",
       "                              ... \n",
       "gradient descent sgd            36\n",
       "high accuracy                   36\n",
       "scale large                     36\n",
       "contrary                        36\n",
       "conjunction                     36\n",
       "cope                            35\n",
       "neural network cnns             35\n",
       "long shortterm memory           35\n",
       "imag data                       35\n",
       "unified framework               35\n",
       "standard dataset                35\n",
       "synthetic real dataset          35\n",
       "long shortterm                  35\n",
       "tuned                           35\n",
       "formal                          35\n",
       "given data                      35\n",
       "expectationmaximization         35\n",
       "assign                          35\n",
       "proposes novel                  35\n",
       "experiments synthetic           35\n",
       "remaining                       35\n",
       "ignore                          34\n",
       "secondly                        34\n",
       "thorough                        34\n",
       "improvement stateoftheart       34\n",
       "belonging                       34\n",
       "object scene                    34\n",
       "standard benchmark              34\n",
       "compute vision application      34\n",
       "actual                          34\n",
       "dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_countvect.sum(axis=0).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Twit_vocab = df_count_Twitter.sum(axis=0).sort_values(ascending=False).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_word_counts = df_countvect.sum(axis=0).sort_values(ascending=False).index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d1 = {}\n",
    "for word1 in all_word_counts:\n",
    "    for word2 in all_word_counts:\n",
    "        if (word1 in word2 and len(word2.split(\" \")) == 1 and word1 != word2 and\n",
    "           word1 not in [\"es\", \"al\", \"et\", \"em\", \"ed\", \"ca\", \n",
    "                         \"ial\", \"rl\", \"i\", \"ii\", \"iii\",\n",
    "                         \"res\", \"ing\", \"lie\", \"ts\"]):\n",
    "            d1.setdefault(word1, []).append(word2)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cand_to_word3 = {}\n",
    "for word in d1.keys():\n",
    "    for candidate in d1[word]:\n",
    "        if levenshteinDistance(word, candidate) == 1:\n",
    "            cand_to_word3[candidate] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in ['score', 'user', 'arise', 'draw', 'gpu']:\n",
    "    cand_to_word2.pop(key, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'arise': u'rise',\n",
       " u'based': u'base',\n",
       " u'cnns': u'cnn',\n",
       " u'compared': u'compare',\n",
       " u'dnns': u'dnn',\n",
       " u'draw': u'raw',\n",
       " u'experiments': u'experiment',\n",
       " u'gpu': u'gp',\n",
       " u'image': u'imag',\n",
       " u'machines': u'machine',\n",
       " u'models': u'model',\n",
       " u'nets': u'net',\n",
       " u'networks': u'network',\n",
       " u'results': u'result',\n",
       " u'rgbd': u'rgb',\n",
       " u'rnns': u'rnn',\n",
       " u'score': u'core',\n",
       " u'user': u'use'}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cand_to_word3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pickle.dump(cand_to_word, open(\"first_word_squasher.pkl\", \"wb\"))\n",
    "pickle.dump(cand_to_word2, open(\"second_word_squasher.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#first_word_squasher = pickle.load(open(\"first_word_squasher.pkl\", \"rb\"))\n",
    "second_word_squasher = pickle.load(open(\"second_word_squasher.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def levenshteinDistance(s1, s2):\n",
    "    if len(s1) > len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "\n",
    "    distances = range(len(s1) + 1)\n",
    "    for i2, c2 in enumerate(s2):\n",
    "        distances_ = [i2+1]\n",
    "        for i1, c1 in enumerate(s1):\n",
    "            if c1 == c2:\n",
    "                distances_.append(distances[i1])\n",
    "            else:\n",
    "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
    "        distances = distances_\n",
    "    return distances[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levenshteinDistance(\"algorithm\", \"algorithmic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 H\n",
      "1 E\n",
      "2 Y\n",
      "3 A\n"
     ]
    }
   ],
   "source": [
    "for x,y in enumerate(\"HEYA\"):\n",
    "    print str(x), str(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=0.95, max_features=None, min_df=0.005,\n",
       "        ngram_range=(1, 3), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tvec = TfidfVectorizer(stop_words='english', min_df=0.005, max_df=0.95, ngram_range=(1, 3))\n",
    "tvec.fit(result_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df  = pd.DataFrame(tvec.transform(result_abs).todense(),\n",
    "                   columns=tvec.get_feature_names(),\n",
    "                   index=result_abs)\n",
    "\n",
    "#df.transpose().sort_values('dl', ascending=False).head(10).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'fit': 773,\n",
       " u'combinatorial': 300,\n",
       " u'algorithm outperform': 59,\n",
       " u'recent advance': 1638,\n",
       " u'experiment conducted': 690,\n",
       " u'chain': 245,\n",
       " u'exact': 671,\n",
       " u'norm': 1333,\n",
       " u'hash': 872,\n",
       " u'learn': 1082,\n",
       " u'influence': 982,\n",
       " u'forest': 786,\n",
       " u'coherence': 290,\n",
       " u'illustrate': 922,\n",
       " u'dependencies': 500,\n",
       " u'transition': 2073,\n",
       " u'pattern': 1440,\n",
       " u'metric': 1210,\n",
       " u'relevant': 1694,\n",
       " u'visual recognition': 2164,\n",
       " u'new model': 1319,\n",
       " u'physics': 1466,\n",
       " u'similar': 1846,\n",
       " u'correlated': 420,\n",
       " u'camera': 218,\n",
       " u'assigned': 123,\n",
       " u'automatically': 143,\n",
       " u'new framework': 1318,\n",
       " u'considering': 371,\n",
       " u'risk minimization': 1750,\n",
       " u'deep neural': 479,\n",
       " u'convolutional': 405,\n",
       " u'subsequently': 1959,\n",
       " u'like': 1102,\n",
       " u'direct': 555,\n",
       " u'parallel': 1419,\n",
       " u'variational': 2141,\n",
       " u'providing': 1576,\n",
       " u'direction': 557,\n",
       " u'employing': 627,\n",
       " u'attention': 134,\n",
       " u'heavily': 877,\n",
       " u'parameter': 1420,\n",
       " u'order magnitude': 1394,\n",
       " u'relationship': 1689,\n",
       " u'focusing': 781,\n",
       " u'video': 2154,\n",
       " u'stochastic gradient': 1930,\n",
       " u'inferred': 979,\n",
       " u'index': 968,\n",
       " u'frequency': 797,\n",
       " u'trajectory': 2066,\n",
       " u'variety': 2144,\n",
       " u'latent': 1074,\n",
       " u'hidden layer': 882,\n",
       " u'goal': 840,\n",
       " u'window': 2184,\n",
       " u'storage': 1933,\n",
       " u'sparse coding': 1885,\n",
       " u'spatiotemporal': 1890,\n",
       " u'addition': 35,\n",
       " u'expansion': 683,\n",
       " u'crossvalidation': 443,\n",
       " u'lstm': 1151,\n",
       " u'identify': 916,\n",
       " u'starting': 1914,\n",
       " u'achieving': 15,\n",
       " u'individual': 970,\n",
       " u'alignment': 67,\n",
       " u'forward': 791,\n",
       " u'optimal solution': 1383,\n",
       " u'passing': 1434,\n",
       " u'center': 242,\n",
       " u'limitation': 1106,\n",
       " u'neighboring': 1294,\n",
       " u'linear convergence': 1113,\n",
       " u'connectivity': 364,\n",
       " u'latent variable model': 1076,\n",
       " u'rate': 1614,\n",
       " u'photometric': 1464,\n",
       " u'respect': 1727,\n",
       " u'procs': 1549,\n",
       " u'neural networks': 1312,\n",
       " u'remarkable': 1703,\n",
       " u'methodology': 1209,\n",
       " u'accuracy': 8,\n",
       " u'training set': 2063,\n",
       " u'assess': 121,\n",
       " u'desirable': 518,\n",
       " u'true': 2079,\n",
       " u'poisson': 1477,\n",
       " u'decompose': 470,\n",
       " u'reliability': 1695,\n",
       " u'perform better': 1448,\n",
       " u'precisely': 1507,\n",
       " u'based': 157,\n",
       " u'boltzmann machine': 193,\n",
       " u'presents novel': 1524,\n",
       " u'availability': 146,\n",
       " u'significantly outperform stateoftheart': 1844,\n",
       " u'iid': 920,\n",
       " u'limited': 1107,\n",
       " u'poorly': 1484,\n",
       " u'represented': 1713,\n",
       " u'automatic': 142,\n",
       " u'weak': 2171,\n",
       " u'procedure': 1545,\n",
       " u'environment': 646,\n",
       " u'discovering': 563,\n",
       " u'generative': 826,\n",
       " u'cope': 414,\n",
       " u'outcome': 1400,\n",
       " u'irrelevant': 1031,\n",
       " u'coupled': 431,\n",
       " u'style': 1952,\n",
       " u'inference algorithm': 977,\n",
       " u'characteristic': 255,\n",
       " u'subsampling': 1957,\n",
       " u'acquisition': 17,\n",
       " u'object': 1352,\n",
       " u'slightly': 1866,\n",
       " u'validity': 2131,\n",
       " u'longrange': 1136,\n",
       " u'note': 1337,\n",
       " u'scientific': 1780,\n",
       " u'input': 990,\n",
       " u'oracle': 1392,\n",
       " u'partial': 1425,\n",
       " u'singular': 1862,\n",
       " u'rule': 1759,\n",
       " u'bounding boxes': 204,\n",
       " u'analytical': 79,\n",
       " u'benefit': 174,\n",
       " u'stateoftheart performance': 1920,\n",
       " u'emerging': 619,\n",
       " u'unseen': 2109,\n",
       " u'synthetic realworld': 2000,\n",
       " u'presents': 1523,\n",
       " u'overhead': 1414,\n",
       " u'balance': 154,\n",
       " u'technique': 2011,\n",
       " u'finally': 764,\n",
       " u'additive': 38,\n",
       " u'order': 1393,\n",
       " u'ranking': 1610,\n",
       " u'yield': 2192,\n",
       " u'classification performance': 271,\n",
       " u'geometric': 830,\n",
       " u'different': 545,\n",
       " u'measuring': 1204,\n",
       " u'practical': 1503,\n",
       " u'phase': 1461,\n",
       " u'preliminary': 1520,\n",
       " u'posterior inference': 1497,\n",
       " u'trajectories': 2065,\n",
       " u'cnn': 284,\n",
       " u'imag dataset': 926,\n",
       " u'suboptimal': 1956,\n",
       " u'vector machine': 2149,\n",
       " u'expectation': 684,\n",
       " u'recursive': 1660,\n",
       " u'cross': 442,\n",
       " u'linear regression': 1115,\n",
       " u'sensitivity': 1804,\n",
       " u'data point': 458,\n",
       " u'internet': 1008,\n",
       " u'dimension': 551,\n",
       " u'empirical': 620,\n",
       " u'considerably': 369,\n",
       " u'considerable': 368,\n",
       " u'process': 1546,\n",
       " u'web': 2175,\n",
       " u'detecting': 525,\n",
       " u'counterparts': 430,\n",
       " u'divergence': 577,\n",
       " u'monte': 1253,\n",
       " u'large class': 1062,\n",
       " u'powerful': 1501,\n",
       " u'achieve': 11,\n",
       " u'current stateoftheart': 449,\n",
       " u'broad': 209,\n",
       " u'incorporating': 960,\n",
       " u'occlusion': 1368,\n",
       " u'autoencoder': 140,\n",
       " u'enforcing': 636,\n",
       " u'improvement stateoftheart': 954,\n",
       " u'shape': 1821,\n",
       " u'access': 5,\n",
       " u'composed': 329,\n",
       " u'longterm': 1137,\n",
       " u'numerical': 1349,\n",
       " u'indoor': 971,\n",
       " u'gaussian process': 814,\n",
       " u'reations': 1634,\n",
       " u'ubiquitous': 2087,\n",
       " u'lighting': 1101,\n",
       " u'bandit': 155,\n",
       " u'factor': 735,\n",
       " u'language modeling': 1058,\n",
       " u'real data': 1621,\n",
       " u'addrs': 42,\n",
       " u'main contribution': 1160,\n",
       " u'cumulative': 447,\n",
       " u'visual': 2163,\n",
       " u'grouping': 861,\n",
       " u'case': 234,\n",
       " u'contrast': 392,\n",
       " u'information': 983,\n",
       " u'specifically': 1895,\n",
       " u'sufficiently': 1970,\n",
       " u'kernel hilbert': 1043,\n",
       " u'recovering': 1656,\n",
       " u'candidate': 220,\n",
       " u'interested': 1004,\n",
       " u'speed': 1902,\n",
       " u'coverage': 436,\n",
       " u'neural network cnns': 1311,\n",
       " u'continuous': 390,\n",
       " u'nonrigid': 1329,\n",
       " u'private': 1539,\n",
       " u'learning algorithm': 1087,\n",
       " u'underlying': 2091,\n",
       " u'specific': 1894,\n",
       " u'core': 415,\n",
       " u'decoder': 468,\n",
       " u'regarding': 1670,\n",
       " u'changing': 252,\n",
       " u'heuristic': 880,\n",
       " u'provided': 1574,\n",
       " u'provides': 1575,\n",
       " u'lowdimensional': 1145,\n",
       " u'smoothness': 1872,\n",
       " u'inherent': 985,\n",
       " u'added': 33,\n",
       " u'batch': 161,\n",
       " u'model selection': 1240,\n",
       " u'patients': 1439,\n",
       " u'statistical': 1924,\n",
       " u'neural network cnn': 1310,\n",
       " u'square': 1905,\n",
       " u'matrix factorization': 1193,\n",
       " u'minima': 1215,\n",
       " u'fundamental': 802,\n",
       " u'subject': 1953,\n",
       " u'probability distribution': 1544,\n",
       " u'differentiable': 546,\n",
       " u'expressed': 710,\n",
       " u'unlike previous': 2108,\n",
       " u'lot': 1141,\n",
       " u'segment': 1790,\n",
       " u'implementation': 939,\n",
       " u'publicly': 1580,\n",
       " u'perform': 1447,\n",
       " u'attribute': 138,\n",
       " u'sufficient condition': 1969,\n",
       " u'powerful tool': 1502,\n",
       " u'remaining': 1701,\n",
       " u'seen': 1789,\n",
       " u'multilabel': 1265,\n",
       " u'emerged': 618,\n",
       " u'model model': 1237,\n",
       " u'implicit': 941,\n",
       " u'greater': 853,\n",
       " u'tranng': 2067,\n",
       " u'constructing': 383,\n",
       " u'functional': 801,\n",
       " u'generalization': 819,\n",
       " u'subsequent': 1958,\n",
       " u'imaging': 936,\n",
       " u'developed': 535,\n",
       " u'secondorder': 1787,\n",
       " u'general framework': 818,\n",
       " u'instead': 996,\n",
       " u'class': 263,\n",
       " u'similarly': 1849,\n",
       " u'framework': 795,\n",
       " u'derive': 506,\n",
       " u'manifold': 1169,\n",
       " u'context': 388,\n",
       " u'select': 1792,\n",
       " u'experiments synthetic': 696,\n",
       " u'feature learning': 751,\n",
       " u'imposed': 946,\n",
       " u'deep reinforcement learning': 483,\n",
       " u'semisupervised': 1799,\n",
       " u'extending': 715,\n",
       " u'exponential': 708,\n",
       " u'clinical': 277,\n",
       " u'optimisation': 1386,\n",
       " u'learning': 1086,\n",
       " u'comparison': 316,\n",
       " u'analyzing': 82,\n",
       " u'convex relaxation': 402,\n",
       " u'event': 668,\n",
       " u'plausible': 1474,\n",
       " u'structure': 1945,\n",
       " u'updating': 2114,\n",
       " u'mixture model': 1226,\n",
       " u'connected': 362,\n",
       " u'joint': 1037,\n",
       " u'arbitrarily': 108,\n",
       " u'overcome': 1412,\n",
       " u'upper bound': 2116,\n",
       " u'background': 152,\n",
       " u'statistic': 1923,\n",
       " u'vanishing': 2134,\n",
       " u'stacked': 1908,\n",
       " u'running': 1761,\n",
       " u'scale large': 1774,\n",
       " u'neighborhood': 1293,\n",
       " u'share': 1822,\n",
       " u'sharp': 1824,\n",
       " u'bottomup': 197,\n",
       " u'tradeoff': 2051,\n",
       " u'hypotheses': 911,\n",
       " u'adapting': 30,\n",
       " u'modified': 1251,\n",
       " u'minimize': 1217,\n",
       " u'relaxation': 1692,\n",
       " u'generation': 825,\n",
       " u'proof': 1559,\n",
       " u'sequence': 1810,\n",
       " u'dependence': 499,\n",
       " u'projection': 1557,\n",
       " u'adapt': 27,\n",
       " u'lasso': 1073,\n",
       " u'convergence rate': 399,\n",
       " u'visually': 2166,\n",
       " u'formulation': 790,\n",
       " u'shortterm memory': 1828,\n",
       " u'confidence': 358,\n",
       " u'integrating': 999,\n",
       " u'achieve stateoftheart': 13,\n",
       " u'similarities': 1847,\n",
       " u'embedded': 616,\n",
       " u'manually': 1172,\n",
       " u'producing': 1551,\n",
       " u'composition': 330,\n",
       " u'calibrated': 215,\n",
       " u'showing': 1830,\n",
       " u'higherorder': 895,\n",
       " u'surface': 1987,\n",
       " u'learning framework': 1090,\n",
       " u'demonstrates': 492,\n",
       " u'nuclear norm': 1344,\n",
       " u'demonstrated': 491,\n",
       " u'domain adaptation': 587,\n",
       " u'language processing': 1059,\n",
       " u'combination': 299,\n",
       " u'realtime': 1626,\n",
       " u'label': 1050,\n",
       " u'identifying': 917,\n",
       " u'depending': 503,\n",
       " u'constant': 378,\n",
       " u'plane': 1472,\n",
       " u'knowledge': 1048,\n",
       " u'realworld application': 1628,\n",
       " u'excellent': 675,\n",
       " u'description': 513,\n",
       " u'runtime': 1763,\n",
       " u'low dimensional': 1143,\n",
       " u'probabilistic': 1540,\n",
       " u'algorithm learning': 58,\n",
       " u'convolutional neural network': 410,\n",
       " u'matrix completion': 1192,\n",
       " u'auxiliary': 145,\n",
       " u'active learning': 22,\n",
       " u'data': 453,\n",
       " u'spatial': 1888,\n",
       " u'fewer': 759,\n",
       " u'blackbox': 187,\n",
       " u'gained': 807,\n",
       " u'symmetric': 1993,\n",
       " u'orthogonal': 1399,\n",
       " u'space': 1883,\n",
       " u'performance algorithm': 1450,\n",
       " u'communities': 307,\n",
       " u'referred': 1668,\n",
       " u'long shortterm memory': 1134,\n",
       " u'finding': 765,\n",
       " u'exhibit': 676,\n",
       " u'modeling': 1245,\n",
       " u'deep model': 477,\n",
       " u'imag feature': 927,\n",
       " u'assume': 127,\n",
       " u'encode': 630,\n",
       " u'random forest': 1603,\n",
       " u'computational complexity': 339,\n",
       " u'online learning': 1374,\n",
       " u'fisher': 772,\n",
       " u'modelbased': 1243,\n",
       " u'capacity': 225,\n",
       " u'largescale dataset': 1071,\n",
       " u'criteria': 439,\n",
       " u'corrupted': 425,\n",
       " u'test time': 2019,\n",
       " u'color': 297,\n",
       " u'design': 515,\n",
       " u'competitive': 318,\n",
       " u'multipliers': 1270,\n",
       " u'proposing': 1570,\n",
       " u'shallow': 1820,\n",
       " u'planning': 1473,\n",
       " u'optimally': 1385,\n",
       " u'partition': 1429,\n",
       " u'easier': 598,\n",
       " u'average': 148,\n",
       " u'recent years': 1639,\n",
       " u'belief': 169,\n",
       " u'pedestrian': 1442,\n",
       " u'representative': 1712,\n",
       " u'technical': 2010,\n",
       " u'resulting': 1733,\n",
       " u'effectively': 604,\n",
       " u'principal': 1532,\n",
       " u'semantic': 1796,\n",
       " u'object detection': 1353,\n",
       " u'introduce new': 1018,\n",
       " u'bound': 198,\n",
       " u'matching': 1187,\n",
       " u'valuable': 2132,\n",
       " u'regularizer': 1683,\n",
       " u'remains': 1702,\n",
       " u'experimental': 692,\n",
       " u'model parameter': 1239,\n",
       " u'ensemble': 640,\n",
       " u'foreground': 785,\n",
       " u'adaptively': 32,\n",
       " u'inference model': 978,\n",
       " u'normalized': 1336,\n",
       " u'mixture': 1225,\n",
       " u'ridge': 1743,\n",
       " u'previous': 1528,\n",
       " u'unsupervised learning': 2112,\n",
       " u'fourier': 792,\n",
       " u'rank': 1609,\n",
       " u'inequality': 974,\n",
       " u'epsilon': 647,\n",
       " u'behaviour': 168,\n",
       " u'parts': 1431,\n",
       " u'differ': 543,\n",
       " u'loss': 1138,\n",
       " u'gamma': 809,\n",
       " u'highlight': 897,\n",
       " u'incomplete': 958,\n",
       " u'wth': 2190,\n",
       " u'characterize': 257,\n",
       " u'learning model': 1091,\n",
       " u'complete': 321,\n",
       " u'social': 1874,\n",
       " u'does': 583,\n",
       " u'word': 2185,\n",
       " u'nonnegative matrix': 1327,\n",
       " u'compression': 335,\n",
       " u'arise': 113,\n",
       " u'annotation': 85,\n",
       " u'outperforming': 1409,\n",
       " u'model data': 1235,\n",
       " u'geometry': 831,\n",
       " u'adopted': 45,\n",
       " u'secondly': 1786,\n",
       " u'dense': 495,\n",
       " u'pascal': 1432,\n",
       " u'shortterm': 1827,\n",
       " u'fine': 767,\n",
       " u'training example': 2060,\n",
       " u'progress': 1555,\n",
       " u'finite': 769,\n",
       " u'expressive': 712,\n",
       " u'simulated real': 1856,\n",
       " u'constructed': 382,\n",
       " u'stream': 1937,\n",
       " u'far': 741,\n",
       " u'challenging': 249,\n",
       " u'feasible': 748,\n",
       " u'classification accuracy': 269,\n",
       " u'sensing': 1802,\n",
       " u'deep network': 478,\n",
       " u'unified framework': 2098,\n",
       " u'trained': 2055,\n",
       " u'entropy': 645,\n",
       " u'socalled': 1873,\n",
       " u'occur': 1369,\n",
       " u'learner': 1085,\n",
       " u'learned': 1083,\n",
       " u'losses': 1140,\n",
       " u'close': 278,\n",
       " u'hidden markov': 883,\n",
       " u'allowed': 70,\n",
       " u'low rank': 1144,\n",
       " u'object imag': 1354,\n",
       " u'making': 1168,\n",
       " u'inferring': 980,\n",
       " u'tuning': 2082,\n",
       " u'converge': 397,\n",
       " u'expert': 698,\n",
       " u'source': 1882,\n",
       " u'carlo': 230,\n",
       " u'preserving': 1526,\n",
       " u'computationally expensive': 344,\n",
       " u'averaging': 149,\n",
       " u'parameterized': 1422,\n",
       " u'boltzmann': 192,\n",
       " u'relies': 1698,\n",
       " u'facial': 732,\n",
       " u'unique': 2101,\n",
       " u'introducing': 1020,\n",
       " u'bayesian model': 165,\n",
       " u'image': 934,\n",
       " u'condition': 352,\n",
       " u'science': 1779,\n",
       " u'localization': 1123,\n",
       " u'chosen': 261,\n",
       " u'naturally': 1282,\n",
       " u'dirichlet process': 560,\n",
       " u'classifying': 274,\n",
       " u'polynomial': 1480,\n",
       " u'statistical model': 1925,\n",
       " u'criterion': 440,\n",
       " u'central': 243,\n",
       " u'stochastic gradient descent': 1931,\n",
       " u'fully': 799,\n",
       " u'evaluate': 664,\n",
       " u'signal': 1834,\n",
       " u'pixel': 1469,\n",
       " u'modeled': 1244,\n",
       " u'hierarchical': 884,\n",
       " u'affect': 49,\n",
       " u'gradient descent': 845,\n",
       " u'tracker': 2048,\n",
       " u'challenging dataset': 250,\n",
       " u'feature selection': 754,\n",
       " u'network structure': 1303,\n",
       " u'significant': 1837,\n",
       " u'extensive': 717,\n",
       " u'multiclass classification': 1263,\n",
       " u'consequently': 367,\n",
       " u'named': 1277,\n",
       " u'compare stateoftheart': 313,\n",
       " u'approximate inference': 104,\n",
       " u'categorization': 238,\n",
       " u'modes': 1249,\n",
       " u'model': 1230,\n",
       " u'difficult': 548,\n",
       " u'strategy': 1936,\n",
       " u'face imag': 730,\n",
       " u'target domain': 2009,\n",
       " u'argue': 112,\n",
       " u'maximizing': 1196,\n",
       " u'nonparametric': 1328,\n",
       " u'experiment synthetic': 691,\n",
       " u'policies': 1478,\n",
       " u'comprehensive': 332,\n",
       " u'surrogate': 1990,\n",
       " u'asymptotic': 130,\n",
       " u'challenge': 248,\n",
       " u'linear combination': 1112,\n",
       " u'infinite': 981,\n",
       " u'selecting': 1794,\n",
       " u'theoretical analysis': 2028,\n",
       " u'regularizing': 1684,\n",
       " u'highly': 898,\n",
       " u'total': 2046,\n",
       " u'uniform': 2099,\n",
       " u'directly': 558,\n",
       " u'orientation': 1397,\n",
       " u'deformation': 488,\n",
       " u'collected': 295,\n",
       " u'soft': 1876,\n",
       " u'popularity': 1486,\n",
       " u'processes': 1547,\n",
       " u'better performance': 178,\n",
       " u'corresponding': 424,\n",
       " u'wide range': 2181,\n",
       " u'difference': 544,\n",
       " u'gradient descent sgd': 846,\n",
       " u'simple': 1850,\n",
       " u'simply': 1853,\n",
       " u'taking': 2007,\n",
       " u'proper': 1561,\n",
       " u'completely': 322,\n",
       " u'transform': 2070,\n",
       " u'significantly improve': 1842,\n",
       " u'component analysis': 328,\n",
       " u'posterior distribution': 1496,\n",
       " u'known': 1049,\n",
       " u'investigate': 1027,\n",
       " u'quantization': 1594,\n",
       " u'limiting': 1108,\n",
       " u'empirical evidence': 622,\n",
       " u'brings': 208,\n",
       " u'regrsion': 1678,\n",
       " u'wide': 2180,\n",
       " u'publicly available': 1581,\n",
       " u'crowdsourcing': 444,\n",
       " u'viewpoint': 2159,\n",
       " u'quite': 1600,\n",
       " u'extensive experiment': 718,\n",
       " u'stationary': 1922,\n",
       " u'mean': 1200,\n",
       " u'viewing': 2158,\n",
       " u'generative model': 828,\n",
       " u'combine': 301,\n",
       " u'consisting': 377,\n",
       " u'develop new': 533,\n",
       " u'privacy': 1538,\n",
       " u'active': 21,\n",
       " u'arms': 115,\n",
       " u'affinity': 51,\n",
       " u'relative': 1690,\n",
       " u'precise': 1506,\n",
       " u'approximating': 106,\n",
       " u'adversarial': 48,\n",
       " u'naive': 1276,\n",
       " u'graph structure': 849,\n",
       " u'andor': 83,\n",
       " u'comparing': 315,\n",
       " u'faster convergence': 745,\n",
       " u'evidence': 669,\n",
       " u'art': 116,\n",
       " u'called': 217,\n",
       " u'purpose': 1584,\n",
       " u'developing': 536,\n",
       " u'research': 1721,\n",
       " u'clustering': 282,\n",
       " u'predictive performance': 1517,\n",
       " u'recognition': 1642,\n",
       " u'reduce number': 1663,\n",
       " u'concept': 350,\n",
       " u'real world': 1624,\n",
       " u'capability': 223,\n",
       " u'binary classification': 184,\n",
       " u'address': 39,\n",
       " u'vision application': 2162,\n",
       " u'compact': 309,\n",
       " u'completion': 323,\n",
       " u'including': 957,\n",
       " u'special': 1891,\n",
       " u'weakly': 2173,\n",
       " u'predicting': 1512,\n",
       " u'box': 205,\n",
       " u'extended': 714,\n",
       " u'novel framework': 1341,\n",
       " u'imag set': 932,\n",
       " u'minimum': 1219,\n",
       " u'point': 1476,\n",
       " u'performance compare': 1451,\n",
       " u'entire': 642,\n",
       " u'takes': 2006,\n",
       " u'invariant': 1025,\n",
       " u'natural language': 1280,\n",
       " u'selected': 1793,\n",
       " u'encouraging': 632,\n",
       " u'traditionally': 2053,\n",
       " u'class label': 264,\n",
       " u'error rate': 653,\n",
       " u'generalize': 821,\n",
       " u'expectationmaximization': 685,\n",
       " u'training sample': 2062,\n",
       " u'gpu': 843,\n",
       " u'long': 1132,\n",
       " u'partitioning': 1430,\n",
       " u'carried': 231,\n",
       " u'large dataset': 1064,\n",
       " u'score': 1781,\n",
       " u'people': 1445,\n",
       " u'dimensionality': 553,\n",
       " u'studies': 1950,\n",
       " u'matches': 1186,\n",
       " u'objective function': 1360,\n",
       " u'vocabulary': 2168,\n",
       " u'conditional random': 354,\n",
       " u'distance metric': 571,\n",
       " u'scenario': 1776,\n",
       " u'adding': 34,\n",
       " u'global': 838,\n",
       " u'shown': 1831,\n",
       " u'shows': 1832,\n",
       " u'impossible': 948,\n",
       " u'nuclear': 1343,\n",
       " u'characterization': 256,\n",
       " u'gibbs': 832,\n",
       " u'object recognition': 1356,\n",
       " u'probability': 1543,\n",
       " u'loglikelihood': 1131,\n",
       " u'processing': 1548,\n",
       " u'usefulness': 2120,\n",
       " u'inner': 989,\n",
       " u'natural imag': 1279,\n",
       " u'hyperparameter': 910,\n",
       " u'tackle': 2003,\n",
       " u'interactive': 1003,\n",
       " u'create': 438,\n",
       " u'algorithm learn': 57,\n",
       " u'dirichlet': 559,\n",
       " u'compositional': 331,\n",
       " u'lowlevel': 1148,\n",
       " u'signal processing': 1835,\n",
       " u'defining': 485,\n",
       " u'model learn': 1236,\n",
       " u'calibration': 216,\n",
       " u'model trained': 1241,\n",
       " u'assignment': 124,\n",
       " u'quantitative': 1590,\n",
       " u'unit': 2102,\n",
       " u'binary': 183,\n",
       " u'having': 874,\n",
       " u'software': 1877,\n",
       " u'likelihood': 1103,\n",
       " u'inspired': 994,\n",
       " u'visualization': 2165,\n",
       " u'existing algorithm': 680,\n",
       " u'intuitive': 1023,\n",
       " u'competing': 317,\n",
       " u'comparable': 310,\n",
       " u'aligned': 66,\n",
       " u'quantify': 1589,\n",
       " u'distance': 570,\n",
       " u'extracting': 725,\n",
       " u'recognize': 1644,\n",
       " u'map': 1173,\n",
       " u'cascade': 233,\n",
       " u'entries': 644,\n",
       " u'extremely': 728,\n",
       " u'recurrent neural': 1658,\n",
       " u'optimize': 1389,\n",
       " u'standard dataset': 1912,\n",
       " u'network cnn': 1299,\n",
       " u'report': 1707,\n",
       " u'focus': 778,\n",
       " u'generative adversarial': 827,\n",
       " u'stochastic': 1929,\n",
       " u'induced': 972,\n",
       " u'deep neural network': 481,\n",
       " u'attractive': 137,\n",
       " u'categories': 237,\n",
       " u'classify': 273,\n",
       " u'convolutional network': 407,\n",
       " u'offer': 1370,\n",
       " u'consensus': 365,\n",
       " u'respectively': 1728,\n",
       " u'great': 852,\n",
       " u'weaker': 2172,\n",
       " u'covariance matrix': 433,\n",
       " u'bounded': 201,\n",
       " u'overlapping': 1415,\n",
       " u'fusion': 804,\n",
       " u'building': 212,\n",
       " u'recurrent neural network': 1659,\n",
       " u'data model': 457,\n",
       " u'youtube': 2194,\n",
       " u'coordinate descent': 413,\n",
       " u'ground truth': 858,\n",
       " u'contain': 385,\n",
       " u'policy': 1479,\n",
       " u'qualitatively': 1587,\n",
       " u'manual': 1171,\n",
       " u'search space': 1783,\n",
       " u'maximization': 1194,\n",
       " u'input imag': 992,\n",
       " u'tractable': 2050,\n",
       " u'huge': 904,\n",
       " u'built': 213,\n",
       " u'build': 211,\n",
       " u'principal component': 1533,\n",
       " u'patches': 1437,\n",
       " u'risk': 1749,\n",
       " u'rise': 1748,\n",
       " u'computation': 336,\n",
       " u'datadriven': 463,\n",
       " u'action recognition': 19,\n",
       " u'choose': 259,\n",
       " u'public dataset': 1579,\n",
       " u'absolute': 2,\n",
       " u'online': 1373,\n",
       " u'past': 1435,\n",
       " u'experience': 688,\n",
       " u'tested': 2020,\n",
       " u'definition': 486,\n",
       " u'length': 1094,\n",
       " u'obtained': 1366,\n",
       " u'riemannian': 1744,\n",
       " u'high quality': 891,\n",
       " u'applicability': 94,\n",
       " u'dynamically': 595,\n",
       " u'discovered': 562,\n",
       " u'actually': 26,\n",
       " u'systems': 2002,\n",
       " u'cost function': 427,\n",
       " u'multiarmed': 1260,\n",
       " u'dealing': 466,\n",
       " u'specialized': 1893,\n",
       " u'intractable': 1015,\n",
       " u'development': 537,\n",
       " u'alternative': 74,\n",
       " u'sublinear': 1954,\n",
       " u'fixed': 775,\n",
       " u'anomaly': 86,\n",
       " u'despite': 520,\n",
       " u'proposes': 1568,\n",
       " u'impressive': 949,\n",
       " u'support vector': 1984,\n",
       " u'outperform': 1403,\n",
       " u'structure learning': 1947,\n",
       " u'weight': 2176,\n",
       " u'range': 1607,\n",
       " u'missing data': 1222,\n",
       " u'local': 1121,\n",
       " u'effective': 603,\n",
       " u'linear classifier': 1111,\n",
       " u'magnitude faster': 1158,\n",
       " u'number': 1345,\n",
       " u'closely': 280,\n",
       " u'study': 1951,\n",
       " u'strength': 1939,\n",
       " u'satisfy': 1770,\n",
       " u'labeled': 1051,\n",
       " u'ground': 857,\n",
       " u'treatment': 2077,\n",
       " u'encoding': 631,\n",
       " u'semantic segmentation': 1797,\n",
       " u'new': 1314,\n",
       " u'net': 1295,\n",
       " u'rigid': 1746,\n",
       " u'effort': 612,\n",
       " u'regularization': 1681,\n",
       " u'learning deep': 1089,\n",
       " u'carry': 232,\n",
       " u'margin': 1175,\n",
       " u'imag region': 929,\n",
       " u'projected': 1556,\n",
       " u'construct': 381,\n",
       " u'value': 2133,\n",
       " u'boxes': 206,\n",
       " u'advantage': 47,\n",
       " u'theory': 2031,\n",
       " u'explicitly': 701,\n",
       " u'detect': 523,\n",
       " u'model allow': 1233,\n",
       " u'understood': 2094,\n",
       " u'desired': 519,\n",
       " u'regret': 1676,\n",
       " u'rate convergence': 1615,\n",
       " u'inequalities': 973,\n",
       " u'tight': 2037,\n",
       " u'practical application': 1504,\n",
       " u'measurement': 1203,\n",
       " u'face': 729,\n",
       " u'fact': 734,\n",
       " u'fail': 737,\n",
       " u'facilitate': 733,\n",
       " u'sequential': 1811,\n",
       " u'hashing': 873,\n",
       " u'exponentially': 709,\n",
       " u'imag retrieval': 930,\n",
       " u'generic': 829,\n",
       " u'deep architecture': 473,\n",
       " u'setup': 1817,\n",
       " u'gradient': 844,\n",
       " u'future': 805,\n",
       " u'data structure': 461,\n",
       " u'confirm': 360,\n",
       " u'believe': 170,\n",
       " u'word embedding': 2186,\n",
       " u'algorithm solve': 61,\n",
       " u'interaction': 1002,\n",
       " u'wellknown': 2178,\n",
       " u'arising': 114,\n",
       " u'assuming': 128,\n",
       " u'quickly': 1599,\n",
       " u'arbitrary': 109,\n",
       " u'convolution': 404,\n",
       " u'introduce novel': 1019,\n",
       " u'term': 2016,\n",
       " u'light': 1100,\n",
       " u'queries': 1595,\n",
       " u'unlike': 2107,\n",
       " u'revisit': 1738,\n",
       " u'suitable': 1972,\n",
       " u'training': 2056,\n",
       " u'object proposal': 1355,\n",
       " u'neighbor': 1292,\n",
       " u'major': 1163,\n",
       " u'evaluating': 666,\n",
       " u'lack': 1054,\n",
       " u'rigorous': 1747,\n",
       " u'major challenge': 1164,\n",
       " u'clustering algorithm': 283,\n",
       " u'upper': 2115,\n",
       " u'solving': 1880,\n",
       " u'concentration': 349,\n",
       " u'bayesian optimization': 166,\n",
       " u'data distribution': 456,\n",
       " u'unstructured': 2110,\n",
       " u'addresses': 41,\n",
       " u'addressed': 40,\n",
       " u'stereo': 1928,\n",
       " u'subspace': 1961,\n",
       " u'content': 387,\n",
       " u'linearly': 1116,\n",
       " u'multiscale': 1271,\n",
       " u'sharing': 1823,\n",
       " u'bayesian': 163,\n",
       " u'probabilistic model': 1541,\n",
       " u'aspect': 120,\n",
       " u'distinct': 572,\n",
       " u'accelerate': 4,\n",
       " u'proportional': 1566,\n",
       " u'undirected': 2095,\n",
       " u'free': 796,\n",
       " u'informative': 984,\n",
       " u'simplicity': 1852,\n",
       " u'reproducing kernel': 1716,\n",
       " u'finds': 766,\n",
       " u'inference': 976,\n",
       " u'searching': 1784,\n",
       " u'apply': 99,\n",
       " u'outlier': 1402,\n",
       " u'designing': 517,\n",
       " u'imag patches': 928,\n",
       " u'opposed': 1379,\n",
       " u'graphical model': 851,\n",
       " u'budget': 210,\n",
       " u'state space': 1917,\n",
       " u'dictionary learning': 542,\n",
       " u'promising': 1558,\n",
       " u'loss function': 1139,\n",
       " u'essentially': 656,\n",
       " u'thanks': 2025,\n",
       " u'temporally': 2014,\n",
       " u'account': 7,\n",
       " u'output': 1410,\n",
       " u'estimation': 661,\n",
       " u'enhance': 638,\n",
       " u'testing': 2021,\n",
       " u'deal': 465,\n",
       " u'initial': 987,\n",
       " u'sample': 1766,\n",
       " u'boundaries': 199,\n",
       " u'zero': 2195,\n",
       " u'imag segmentation': 931,\n",
       " u'learning setting': 1092,\n",
       " u'intermediate': 1006,\n",
       " u'thorough': 2032,\n",
       " u'situations': 1864,\n",
       " u'inverse': 1026,\n",
       " u'leading': 1081,\n",
       " u'usage': 2117,\n",
       " u'yielding': 2193,\n",
       " u'million': 1214,\n",
       " u'achieve better': 12,\n",
       " u'demonstrating': 493,\n",
       " u'decision': 467,\n",
       " u'synthetic real dataset': 1999,\n",
       " u'cifar': 262,\n",
       " u'classifier': 272,\n",
       " u'ratio': 1616,\n",
       " u'splitting': 1904,\n",
       " u'limit': 1105,\n",
       " u'accurately': 10,\n",
       " u'kernel': 1042,\n",
       " u'empirical evaluation': 621,\n",
       " u'deriving': 507,\n",
       " u'conduct': 356,\n",
       " u'restricted boltzmann': 1731,\n",
       " u'head': 875,\n",
       " u'principal component analysis': 1534,\n",
       " u'reduce computational': 1662,\n",
       " u'empirically': 624,\n",
       " u'robust': 1754,\n",
       " u'extracted': 724,\n",
       " u'streaming': 1938,\n",
       " u'smoothing': 1871,\n",
       " u'superpixel': 1979,\n",
       " u'furthermore': 803,\n",
       " u'dependency': 501,\n",
       " u'series': 1813,\n",
       " u'tree': 2078,\n",
       " u'scalable': 1772,\n",
       " u'feedback': 757,\n",
       " u'useful': 2119,\n",
       " u'enable': 628,\n",
       " u'rnns': 1753,\n",
       " u'learned model': 1084,\n",
       " u'marginal': 1176,\n",
       " u'feature vector': 756,\n",
       " u'increase': 961,\n",
       " u'message': 1208,\n",
       " u'embedding': 617,\n",
       " u'validate': 2129,\n",
       " u'probabilities': 1542,\n",
       " u'step': 1927,\n",
       " u'predictor': 1518,\n",
       " u'semidefinite': 1798,\n",
       " u'costly': 428,\n",
       " u'annotated': 84,\n",
       " u'regular': 1679,\n",
       " u'human': 905,\n",
       " u'character': 254,\n",
       " u'simultaneous': 1858,\n",
       " ...}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6605, 2917)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>form</th>\n",
       "      <th>structural</th>\n",
       "      <th>intuitive</th>\n",
       "      <th>bias</th>\n",
       "      <th>initial</th>\n",
       "      <th>discover</th>\n",
       "      <th>tree</th>\n",
       "      <th>structure</th>\n",
       "      <th>knowledge</th>\n",
       "      <th>human</th>\n",
       "      <th>computational</th>\n",
       "      <th>right</th>\n",
       "      <th>discovered</th>\n",
       "      <th>understood</th>\n",
       "      <th>learn</th>\n",
       "      <th>consequence</th>\n",
       "      <th>model learn</th>\n",
       "      <th>grid</th>\n",
       "      <th>connectivity</th>\n",
       "      <th>qualitative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Both scientists and children make important structural discoveries yet their computational underpinnings are not well understood Structure discover has previously been formalized as probabilistic inference about the right structural form  where form could be a tree ring chain grid etc Kemp  Tenenbaum  The discover of structural form PNAS   While this  can learn intuitive organizations including a tree for animals and a ring for the color circle it assume a strong inductive bias that considers only these particular form and each form is explicitly provided as initial knowledge Here we introduce a new computational model of how organizing structure can be discovered utilizing a broad hypothesis space with a preference for sparse connectivity Given that the inductive bias is more general the model initial knowledge shows little qualitative resemblance to some of the discoveries it support As a consequence the model can also learn complex structure for domain that lack intuitive description as well as predict human property induction judgments without explicit structural form By allowing form to emerge from sparsity our  clarifies how both the richness and flexibility of human conceptual organization can coexist</th>\n",
       "      <td>0.486326</td>\n",
       "      <td>0.362734</td>\n",
       "      <td>0.211940</td>\n",
       "      <td>0.192301</td>\n",
       "      <td>0.190352</td>\n",
       "      <td>0.17779</td>\n",
       "      <td>0.173695</td>\n",
       "      <td>0.156285</td>\n",
       "      <td>0.140797</td>\n",
       "      <td>0.135959</td>\n",
       "      <td>0.129181</td>\n",
       "      <td>0.115584</td>\n",
       "      <td>0.114679</td>\n",
       "      <td>0.111813</td>\n",
       "      <td>0.111715</td>\n",
       "      <td>0.111068</td>\n",
       "      <td>0.109323</td>\n",
       "      <td>0.108993</td>\n",
       "      <td>0.108668</td>\n",
       "      <td>0.107421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>We  joint estimation of multiple graphical model arising from heterogeneous and highdimensional observation Unlike most previous approaches which assume that the cluster structure is given in advance an appealing feature of our  is to learn cluster structure while estimating heterogeneous graphical model This is achieve via a high dimensional version of Expectation Conditional Maximization ECM algorithm Meng and Rubin  A joint graphical lasso penalty is imposed in the conditional maximization step to extract both homogeneity and heterogeneity component across all cluster Our algorithm is computationally efficient due to fast sparse learning routines and can be implemented without unsupervised learning knowledge The superior performance of our  is demonstrated by extensive experiment and its application to a Glioblastoma cancer dataset reveal some new insight in understanding the Glioblastoma cancer In theory a nonasymptotic error bound is established for the output directly from our high dimensional ECM algorithm and it consist of two quantities statistical error statistical accuracy and optimization error computational complexity Such a result gives a theoretical guideline in terminating our ECM iteration</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.108435</td>\n",
       "      <td>0.073267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReLU neural net define piecewise linear function of their input However initializing and training a neural net is very  from fitting a linear spline In this  we expand empirically upon previous theoretical  to  feature of trained neural net Standard net initialization and training produce net vastly simple than a naive parameter count would suggest and can impart odd feature to the trained net However we also show the forced simplicity is beneficial and indeed critical for the wide success of these net</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural network wth rectfed lnear unt actvatons are essentally multvarate lnear splnes As such one of many way to measure the complexty or expressvty of a neural network s to count the number of knots n the splne model We study the number of knots n fullyconnected feedforward neural network wth rectfed lnear unt actvaton functons We ntentonally keep the neural network very smple so as to make theoretcal analyses more approachable An nducton on the number of layer l reveal a tght upper bound on the number of knots n mathbbR to mathbbRp deep neural network Wth n gg  neurons n layer    dots l the upper bound s approxmately n dots nl We then show that the exact upper bound s tght and we  the upper bound wth an example The purpose of these analyses s to pave a path for understandng the behavor of general mathbbRq to mathbbRp neural network</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>We  a new framework for manifold denoising  on processing in the graph Fourier frequency domain derive from the spectral decomposition of the discrete graph Laplacian Our  use the Spectral Graph Wavelet transform in order to per form noniterative denoising directly in the graph frequency domain an  inspired by conventional wavelet signal denoising  We theoretically justify our   on the fact that for smooth manifold the coordinate information energy is localized in the low spectral graph wavelet subbands while the noise affects all frequency bands in a similar way Experimental  show that our d manifold frequency denoising MFD  significantly outperform the state of the art denoising meth ods and is robust to a wide range of parameter selections eg the choice of k nearest neighbor connectivity of the graph</th>\n",
       "      <td>0.065806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102929</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>An associative memory is a framework of contentaddressable memory that stores a collection of message vector or a dataset over a neural network while enabling a neurally feasible mechanism to recover any message in the dataset from its noisy version Designing an associative memory require addressing two main   learning phase given a dataset learn a concise representation of the dataset in the form of a graphical model or a neural network  recall phase given a noisy version of a message vector from the dataset output the correct message vector via a neurally feasible algorithm over the network learn during the learning phase This  studies the  of designing a class of neural associative memories which learn a network representation for a large dataset that ensures correction against a large number of adversarial error during the recall phase Specifically the associative memories designed in this  can store dataset containing expn nlength message vector over a network with On node and can tolerate Omegafracnrm polylog n adversarial error This  carries out this memory design by mapping the learning phase and recall phase to the  of dictionary learning with a square dictionary and iterative error correction in an expander code respectively</th>\n",
       "      <td>0.052806</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127367</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variational autoencoder VAE are scalable and powerful generative model However the choice of the variational posterior determines tractability and flexibility of the VAE Commonly latent variable are modeled  the normal distribution with a diagonal covariance matrix This  in computational efficiency but typically it is not flexible enough to match the true posterior distribution One fashion of enriching the variational posterior distribution is application of normalizing lows ie a series of invertible transformation to latent variable with a simple posterior In this  we  this line of thinking and  a volumepreserving low that use a series of Householder transformation We show empirically on MNIST dataset and histopathology data that the d low allow to obtain more flexible variational posterior and highly competitive  comparing to other normalizing lows</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072858</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Increasing availability of vehicle GPS data has create potentially transformative opportunities for traffic management route planning and other location services Critical to the utility of the data is their accuracy Mapmatching is the process of improving the accuracy by aligning GPS data with the road network In this  we  a purely probabilistic  to mapmatching  on a sequential Monte Carlo algorithm known as article filter The  perform mapmatching by producing a range of candidate solution each with an associated probability core We outline implementation details and thoroughly validate the technique on GPS data of varied quality</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>We address the  of speeding up the training of convolutional network Here we study a distributed  adapted to stochastic gradient descent SGD The parallel optimization setup use several threads each applying individual gradient descents on a local variable We  a new way to share information between  threads inspired by gossip algorithm and showing good consensus convergence properties Our  called GoSGD has the advantage to be fully asynchronous and decentralized We compare our  to the recent EASGD in citeelastic on CIFAR show encouraging</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Phase synchronisation in multichannel EEG is known as the manifestation of functional brain connectivity Traditional phase synchronisation studies are mostly  on time average synchrony measure hence do not preserve the temporal evolution of the phase difference Here we  a new  to show the existence of a small set of unique phase synchronised pattern or state in multichannel EEG recordings each state being stable of the order of ms from typical and pathological subject during face perception  The d ology bridges the concept of EEG microstate and phase synchronisation in time and frequency domain respectively The analysis is reported for four group of children including typical Autism Spectrum Disorder ASD low and high anxiety subject  a total of  subject In all case we observe consistent existence of these state  termed as synchrostate  within specific cognition related frequency bands beta and gamma bands though the topographies of these synchrostate differ for  subject group with  pathological condition The intersynchrostate switching follows a welldefined sequence capturing the underlying interelectrode phase relation dynamic in stimulus and personcentric manner Our study is motivated from the wellknown EEG microstate exhibiting stable potential map over the scalp However here we report a similar observation of quasistable phase synchronised state in multichannel EEG The existence of the synchrostate coupled with their unique switching sequence characteristic could be considered as a potentially new field over contemporary EEG phase synchronisation studies</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085853</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In this  we  a new primaldual algorithm for minimizing fxgxhAx where f g and h are convex function f is differentiable with a Lipschitz continuous gradient and A is a bounded linear operator It has some famous primaldual algorithm for minimizing the sum of two function as special case For example it reduce to the ChambollePock algorithm when f and a primaldual fixedpoint algorithm in P Chen J Huang and X Zhang A primaldual fixedpoint algorithm for convex separable minimization with application to imag restoration Inverse Problems   p when g In addition it recover the threeoperator splitting scheme in D Davis and W Yin A threeoperator splitting scheme and its optimization application arXiv  when A is the identity operator We prove the convergence of this new algorithm for the general case by showing that the iteration is a nonexpansive operator and derive the linear convergence rate with additional assumption Comparing to other primaldual algorithm for solving the same  this algorithm extend the range of acceptable parameter to ensure the convergence and has a smaller periteration cost The numerical experiment show the efficiency of this new algorithm by comparing to other primaldual algorithm</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coadaptation is a speci form of online learning where an  mathcA must assist an unknown  mathcB to perform some  This is a gener framework and has application in recommendation systems search education and much more Today the most common use of coadaptive  is in braincomputer interfacing BCI where  help patients gain and maintain control over prosthic devices While previous studies have shown strong empiric  Kowski    Orsborn    or have been studied in specific example Merel     there is no gener anysis of the coadaptive learning  Here we will study the coadaptive learning  in the online closedloop sting We will prove that with high probability coadaptive learning is guarantee to outperform learning with a fixed decoder as long as a particular condition is m</th>\n",
       "      <td>0.127377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Humans are remarkably adept at interpreting the gaze direction of other individual in their surroundings This skill is at the core of the ability to engage in joint visual attention which is essential for establishing social interaction How accurate are human in determining the gaze direction of others in lifelike scene when they can move their heads and eyes freely and what are the source of information for the underlying perceptual processes These question pose a challenge from both empirical and computational perspectives due to the complexity of the visual input in reallife situations Here we measure empirically human accuracy in perceiving the gaze direction of others in lifelike scene and study computationally the source of information and representation underlying this cognitive capacity We show that human perform better in facetoface condition compare with recorded condition and that this advantage is not due to the availability of input dynamic We further show that human are still performing well when only the eyesregion is visible rather than the whole face We develop a computational model which replicates the pattern of human performance including the finding that the eyesregion contain on its own the require information for estimating both head orientation and direction of gaze Consistent with neurophysiological finding on taskspecific face region in the brain the learned computational representation reproduce perceptual effect such as the Wollaston illusion when trained to estimate direction of gaze but not when trained to recognize object or face</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.348158</td>\n",
       "      <td>0.198481</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Plants sense their environment by producing electril signal which in essence represent change in underlying physiologil processes These electril signal when monitored show both stochastic and deterministic dynamic In this  we compute  statistil feature from the raw nonstationary plant electril signal time series to classify the stimulus applied  the electril signal By   discriminant analysis  classifition technique we successfully establish that there is enough information in the raw electril signal to classify the stimuli In the process we also  two standard feature which consistently give good classifition  for three type of stimuli  Sodium Chloride NaCl Sulphuric Acid HSO and Ozone O This may facilitate reduction in the complexity involve in computing all the feature for online classifition of similar external stimuli in future</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>We ntroduce a new largescale musc dataset MuscNet to serve as a source of supervson and evaluaton of machne   for musc research MuscNet conssts of hundreds of freelylcensed classcal musc recordngs by  composers wrtten for  nstruments together wth nstrumentnote annotatons resultng n over  mllon temporal label on  hours of chamber musc performance under varous studo and mcrophone condtons We defne a multlabel classfcaton  to predct notes n muscal recordngs along wth an evaluaton protocol We benchmark several machne  archtectures for     from handcrafted spectrogram feature  endtoend  wth a neural net  endtoend  wth a convolutonal neural net We show that several endtoend  proposal outperform approaches  on  from handcrafted audo feature</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Demanding sparsity in estimate model has become a routine practice in statistic In many situations we wish to require that the sparsity pattern attained honor certain problemspecific constraint Hierarchical sparse modeling HSM refers to situations in which these constraint specify that one set of parameter be set to zero whenever another is set to zero In recent years numerous s have developed convex regularizers for this form of sparsity structure which arise in many area of statistic including interaction modeling time series analysis and covariance estimation In this  we observe that these  fall into two framework the group lasso GL and latent overlapping group lasso LOG which have not been systematically compare in the context of HSM The purpose of this  is to  a sidebyside comparison of these two framework for HSM in term of their statistical properties and computational efficiency We call special attention to GLs more aggressive shrinkage of parameter deep in the hierarchy a property not share by LOG In term of computation we introduce a finitestep algorithm that exactly solve the proximal operator of LOG for a certain simple HSM structure we later exploit this to develop a novel pathbased BCD scheme for general HSM structure Both algorithm greatly improve the computational performance of LOG Finally we compare the two  in the context of covariance estimation where we introduce a new sparselybanded estimator  LOG which we show achieve the statistical advantage of an existing GLbased  but is simple to express and more efficient to compute</th>\n",
       "      <td>0.063707</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.143309</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In this  we study the efficiency of a bf Restarted bf Subbf Gradient RSG  that periodically restarts the standard subgradient  SG We show that when applied to a broad class of convex optimization  RSG  can find an epsilonoptimal solution with a low complexity than SG  In particular we first show that RSG can reduce the dependence of SGs iteration complexity on the distance between the initial solution and the optimal set to that between the epsilonlevel set and the optimal set In addition we show the advantage of RSG over SG in solving three  families of convex optimization  a For the  whose epigraph is a polyhedron RSG is shown to converge linearly b For the  with local quadratic growth property RSG has an Ofracepsilonlogfracepsilon iteration complexity c For the  that admit a local KurdykaL ojasiewicz property with a power constant of betain RSG has an Ofracepsilonbetalogfracepsilon iteration complexity On the contrary with only the standard analysis the iteration complexity of SG is known to be Ofracepsilon for these three classes of  The novelty of our analysis lies at exploiting the lower bound of the firstorder optimality residual at the epsilonlevel set It is this novelty that allow us to explore the local properties of function eg local quadratic growth property local KurdykaL ojasiewicz property more generally local error bound to develop the improve convergence of RSG We  the effectiveness of the  algorithm on several machine learning  including regression and classification</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093443</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adaptive scheme where  are assigned  on the data collected thus far are widely  in practical crowdsourcing systems to efficiently allocate the budget However existing theoretical analyses of crowdsourcing systems suggest that the gain of adaptive  assignments is minima To ridge this gap we investigate this question under a strictly more general probabilistic model which has been recently introduce to model practical crowdsourcing dataset Under this generalize DawidSkene model we characterize the fundamental tradeoff between budget and accuracy We introduce a novel adaptive scheme that matches this fundamental limit A given budget is allocated over multiple rounds In each round a subset of  with high enough confidence are classified and increasing budget is allocated on remaining ones that are potentially more difficult On each round decision are made  on the leading eigenvector of weighted nonbacktracking operator corresponding to the bipartite assignment graph We further quantify the gain of adaptivity by comparing the tradeoff with the one for nonadaptive scheme and confirm that the gain is significant and can be made arbitrarily large depending on the distribution of the difficult level of the  at hand</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A binary classifier capable of abstaining from making a label prediction has two goals in tension minimizing error and avoiding abstaining unnecessarily often In this  we exactly characterize the best achievable tradeoff between these two goals in a general semisupervised setting given an ensemble of predictor of varying competence as well as unlabeled data on which we wish to predict or abstain We give an algorithm for learning a classifier in this setting which trades off its error with abstentions in a minima optimal manner is as efficient as linear learning and prediction and is demonstrably practical Our analysis extend to a large class of loss function and other scenario including ensemble comprised of specialists that can themselves abstain</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In this  we aim at recovering an undirected weighted graph of N vertices from the knowledge of a perturbed version of the eigenspaces of its adjacency matrix W Our  is  on minimizing a cost function given by the Frobenius norm of the commutator ABBA between symmetric matrices A and B In the ErdHosRenyi model with no selfloops we show that identifiability ie the ability to reconstruct W from the knowledge of its eigenspaces follows a sharp phase transition on the expected number of edge with threshold function Nlog N Given an estimation of the eigenspaces  on a nsample we  support selection procedure from theoretical and practical point of view In particular when deleting an edge from the active support our study unveils that our test statistic is the order of On when we overestimate the true support and lower bounded by a positive constant when the estimate support is smaller than the true support This feature lead to a powerful practical support estimation procedure when properly thresholding Simulated and real life numerical experiment assert our new methodology</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160316</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A typical  in causal modeling is the instability of model structure learning ie small chang in finite data can rult in completely  optimal model The   introduc a novel causal modeling algorithm for longitudinal data that is robust for finite sampl  on recent advanc in stability selection  subsampling and selection algorithm Our  us exploratory search but allow incorporation of prior knowledge eg that causal relationship do not go back in time We re causal relationship  structural equation model Models are scored along two objectiv the model fit and the model complexity Since both objectiv are often conflicting we apply a multiobjective evolutionary algorithm to search for Pareto optimal model To handle the instability of small finite data sampl we repeatedly subsample the data and select those substructur from the optimal model that are both stable and parsimonious The substructur can be visualized through a causal graph Our more exploratory  outperform stateoftheart alternative  on a simulated data set with a known ground truth We also  the  of our  on three realworld longitudinal data set on chronic fatigue syndrome Alzheimer disease and chronic kidney disease The finding obtained with our  are generally in line with  from more hypothisdriven analys in earlier studi and do suggt some novel relationship that derve further rearch</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.089128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051201</td>\n",
       "      <td>0.069191</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gaussian processes GPs are flexible distribution over function that enable highlevel assumption about unknown function to be encode in a parsimonious flexible and general way Although elegant the application of GPs is limited by computational and analytical intractabilities that rise when data are sufficiently numerous or when employing nonGaussian model Consequently a wealth of GP approximation scheme have been developed over the last  years to address these key limitation Many of these scheme employ a small set of pseudo data point to summrise the actual data In this  we develop a new pseudopoint approximation frame  Power Expectation Propagation Power EP that unifies a large number of these pseudopoint approximation Unlike much of the previous venerable  in this area the new frame is built on standard  for approximate inference variational freeenergy EP and power EP  rather than employing approximation to the probabilistic generative model itself In this way all of approximation is performed at inference time rather than at modelling time resolving awkward philosophical and empirical question that trouble previous approaches Crucially we  that the new frame includes new pseudopoint approximation  that outperform current approaches on regression classification and state space modelling</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064521</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Modern discriminative predictor have been shown to match natural intelligences in specific perceptual  in imag classification object and part detection boundary extraction etc However a major advantage that natural intelligences still have is that they  well for all perceptual  together solving them efficiently and coherently in an integrate manner In order to capture some of these advantage in machine perception we ask two question whether deep neural net can learn universal imag representation useful not only for a single  but for all of them and how the solution to the   can be integrate in this frame We answer by proposing a new architecture which we call MultiNet in which not only deep imag feature are share between  but where  can interact in a recurrent manner by encoding the  of their analysis in a common share representation of the data In this manner we show that the performance of individual  in standard benchmark can be improve first by sharing feature between them and then more significantly by integrating their solution in the common representation</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070991</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relatonal  deals wth data that are characterzed by relatonal structure An mportant  s collectve classfcaton whch s to jontly classfy networked object Whle t hold a great promse to produce a better accuracy than noncollectve classfers collectve classfcaton s computatonal challengng and has not leveraged on the recent breakthroughs of deep  We  Column Network CLN a novel deep  model for collectve classfcaton n multrelatonal domans CLN has many desrable theoretcal propertes  t encode multrelatons between any two nstances  t s deep and compact allowng complex functons to be approxmated at the network level wth a small set of free parameter  local and relatonal feature are learned smultaneously v longrange hgherorder dependences between nstances are supported naturally and v crucally  and nference are effcent lnear n the sze of the network and the number of relatons We evaluate CLN on multple realworld applcatons a delay predcton n software projects b PubMed Dabetes publcaton classfcaton and c flm genre classfcaton In all applcatons CLN demonstrates a hgher accuracy than stateoftheart rvals</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095708</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sources of variability in experimentally derive data  measurement error in addition to the physical phenomena of interest This measurement error is a combination of systematic component originating from the measuring instrument and random measurement error Several novel biological technologies such as mass cytometry and singlecell RNAseq are plagued with systematic error that may severely affect statistical analysis if the data is not properly calibrated Here we  a novel deep learning  for removing systematic batch effect Our  is  on a residual network trained to minimize the Maximum Mean Discrepancy MMD between the multivariate distribution of two replicates measure in  batches We apply our  to mass cytometry and singlecell RNAseq dataset and  that it effectively attenuates batch effect and outperform several popular</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>We  a general framework for privacypreserving variational Bayes VB for a large class of probabilistic model called the conjugate exponential CE family Our primary observation is that when model are in the CE family we can privatise the variational posterior distribution simply by perturbing the expected sufficient statistic of the completedata likelihood For widely  nonCE model with binomial likelihoods eg logistic regression we exploit the PolyaGamma data augmentation scheme to bring such model into the CE family such that inferences in the modified model resemble the original private variational Bayes algorithm as closely as possible The iterative nature of variational Bayes presents a further challenge for privacy preservation as each iteration increase the amount of noise needed We overcome this challenge by combining  a relaxed notion of differential privacy called itconcentrated differential privacy which s a tight bound on the privacy cost of multiple VB iteration and thus significantly decreases the amount of additive noise and  the privacy amplification effect resulting from subsampling minibatches from largescale data in stochastic learning We empirically  the effectiveness of our  in CE and nonCE model including latent Dirichlet allocation LDA and Bayesian logistic regression evaluate on realworld dataset</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Various active learning   on logistic regression have been  In this  we investigate seven stateoftheart strategies  an extensive benchmark and  a better understanding of their underlying characteristic Experiments are carried out both on  synthetic dataset and  realworld dataset providing insight into the behaviour of these active learning  with respect to classification accuracy and their computational cost</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The ntroducton of data analytcs nto medcne has changed the nature of treatment In  patents are asked to dsclose personal nformaton such as genetc markers lfestyle habts and clncal hstory Ths data s then  by statstcal model to predct personalzed treatments However due to prvacy concerns patents often desre to wthhold senstve nformaton Ths selfcensorshp can mpede proper dagnoss and treatment whch may lead to serous health complcatons and even death In   we  prvacy dstllaton a mechansm whch allow patents to control the type and amount of nformaton they wsh to dsclose to the healthcare provders for use n statstcal model Meanwhle t retans the accuracy of model that have access to all patent data under a suffcent but not full set of prvacyrelevant nformaton We valdate prvacy dstllaton  a corpus of patents prescrbed to warfarn for a personalzed dosage We use a deep neural network to mplement prvacy dstllaton for tranng and makng dose predctons We fnd that prvacy dstllaton wth suffcent prvacyrelevant nformaton  retans accuracy almost as good as havng all patent data only  worse and  s effectve at preventng error that ntroduce healthrelated rsks yeldng on average  of under or overprescrptons</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This  investigates the case of a net of agent that attempt to learn some unknown state of the world amongst the finitely many possibilities At each time step agent all receive random independently distributed private signal whose distribution are dependent on the unknown state of the world However it may be the case that some or any of the agent cannot distinguish between two or more of the possible state  only on their private observation as when several state result in the same distribution of the private signal In our model the agent form some initial belief probability distribution about the unknown state and then refine their beliefs in accordance with their private observation as well as the beliefs of their neighbor An agent learn the unknown state when her belief converge to a point mass that is concentrated at the true state A rational agent would use the Bayes rule to incorporate her neighbor beliefs and own private signal over time While such repeated application of the Bayes rule in net can become computationally intractable in this  we show that in the canonical case of directed star circle or path net and their combination one can derive a class of memoryless update rule that replicate that of a single Bayesian agent but replace the self beliefs with the beliefs of the neighbor This way one can realize an exponentially fast rate of learning similar to the case of Bayesian fully rational agent The  rule are a special case of the Learning without Recall</th>\n",
       "      <td>0.047067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064478</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Learning a natural language interface for database tables is a challenging  that involve deep language understanding and multistep reasoning The  is often approached by mapping natural language queries to logical form or program that  the desired response when executed on the database To our knowledge this  presents the first weakly supervised endtoend neural network model to induce such program on a realworld dataset We enhance the objective function of Neural Programmer a neural network with builtin discrete operation and apply it on WikiTableQuestions a natural language questionanswering dataset The model is trained endtoend with weak supervision of questionanswer pair and does not require domainspecific grammars rule or annotation that are key element in previous approaches to program induction The main experimental result in this  is that a single Neural Programmer model achieve  accuracy  only  example with weak supervision An ensemble of  model with a trivial combination technique achieve  accuracy which is competitive to the current stateoftheart accuracy of  obtained by a traditional natural language semantic parser</th>\n",
       "      <td>0.064598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Learning to solve complex sequence of while both leveraging transfer and avoiding catastrophic forgettingremains a key obstacle to achieving humanlevel intelligence The progressive network  represent a step forward in this direction they are immune to forgetting and can leverage prior knowledge via lateral connection to previously learned feature We evaluate this architecture extensively on a wide variety of reinforcement learning  Atari and D maze game and show that it outperform common baseline  on pretraining and finetuning Using a novel sensitivity measure we  that transfer occur at both lowlevel sensory and highlevel control layer of the learned policy</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>We introduce a simple recurrent variational autoencoder architecture that significantly improve imag modeling The system represent the stateoftheart in latent variable model for both the ImageNet and Omniglot dataset We show that it naturally separates global conceptual information from lower level details thus addressing one of the fundamentally desired properties of unsupervised learning Furthermore the possibility of restricting ourselves to storing only global information about an imag allow us to achieve high quality conceptual compression</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>We discuss relation between Residual Networks ResNet Recurrent Neural Networks RNNs and the primate visual cortex We begin with the observation that a shallow RNN is exactly equivalent to a very deep ResNet with weight sharing among the layer A direct implementation of such a RNN although having order of magnitude fewer parameter lead to a performance similar to the corresponding ResNet We   a generalization of both RNN and ResNet architecture and  the conjecture that a class of moderately deep RNNs is a biologicallyplausible model of the ventral stream in visual cortex We  the effectiveness of the architecture by testing them on the CIFAR dataset</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Inspred by the recent success of  that employ shape prors to acheve robust D reconstructons we  a novel recurrent neural network archtecture that we call the D Recurrent Reconstructon Neural Network DRN The network learn a mappng from s of object to ther underlyng D shape from a large collecton of synthetc data  Our network takes n one or more s of an object nstance from arbtrary vewponts and output a reconstructon of the object n the form of a D occupancy grd Unlke most of the prevous works our network does not requre any  annotatons or object class label for tranng or testng Our extensve expermental analyss shows that our reconstructon framework  outperform the stateoftheart  for sngle vew reconstructon and  enable the D reconstructon of object n stuatons when tradtonal SFMSLAM  fal because of lack of texture andor wde baselne</th>\n",
       "      <td>0.108442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.087186</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residual network family with hundreds or even thousands of layer dominate major imag recognition  but building a network by simply stacking residual block inevitably limit its optimization ability This  proposes a novel residualnetwork architecture Residual network of Residual network RoR to dig the optimization ability of residual network RoR substitutes optimizing residual mapping of residual mapping for optimizing original residual mapping in particular adding levelwise shortcut connection upon original residual network to promote the learning capability of residual network More importantly RoR can be applied to various kind of residual network PreResNets and WRN and significantly boost their performance Our experiment  the effectiveness and versatility of RoR where it achieve the best performance in all residualnetworklike structure Our RoRWRN model achieve new stateoftheart  on CIFAR CIFAR and SVHN with test error   and  respectively These  outperform layer PreResNets by  on CIFAR and  on CIFAR</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035077</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>We  local binary convolution LBC an efficient alternative to convolutional layer in standard convolutional neural network CNN The design principle of LBC are motivated by local binary pattern LBP The LBC layer comprises of a set of fixed sparse predefined binary convolutional filter that are not update during the training process a nonlinear activation function and a set of learnable linear weight The linear weight combine the activated filter response to approximate the corresponding activated filter response of a standard convolutional layer The LBC layer affords significant parameter savings  to  in the number of learnable parameter compare to a standard convolutional layer Furthermore due to lower model complexity and sparse and binary nature of the weight also  in up to  to  savings in model size compare to a standard convolutional layer We  both theoretically and experimentally that our local binary convolution layer is a good approximation of a standard convolutional layer Empirically CNNs with LBC layer called local binary convolutional neural network LBCNN reach stateoftheart performance on a range of visual dataset MNIST SVHN CIFAR and a subset of ImageNet while enjoying significant computational savings</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>We  a unified framework for learning continuous control policies  backpropagation It support stochastic control by treating stochasticity in the Bellman equation as a deterministic function of exogenous noise The product is a spectrum of general policy gradient algorithm that range from modelfree  with value function to modelbased  without value function We use learned model but only require observation from the environment instead of observation from modelpredicted trajectories minimizing the impact of compounded model error We apply these algorithm first to a toy stochastic control  and then to several physicsbased control s in simulation One of these variant SVG shows the effectiveness of learning model value function and policies simultaneously in continuous domain</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recent advance in machine learning have dramatically improve the accuracy of object recognition in static imag However human and animals are rarely confronted with imag that are completely static and typically perform a variety of interventions to aid in object recognition from change in viewpoint to active manipulation such as turning an object around to see it from all sides or removing occluders Such active perception is particularly important in robotics where correct object classification is often crucial and active interventions are available to aid in recognition In this  we  a  that can learn such active interventions and evaluate our  on a simulated environment that we call Occluded MNIST which require the agent to push distractor object out of the way to perform successful recognition We evaluate a variety of solution  on reinforcement learning and  that active intervention substantially improve recognition accuracy over a passive baseline</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074265</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061022</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kalman Filters are one of the most influential model of timevarying phenomena They admit an intuitive probabilistic interpretation have a simple functional form and enjoy widespread adoption in a variety of disciplines Motivated by recent variational  for learning deep generative model we introduce a unified algorithm to efficiently learn a broad spectrum of Kalman filter Of particular interest is the use of temporal generative model for counterfactual inference We investigate the efficacy of such model for counterfactual inference and to that end we introduce the Healing MNIST dataset where longterm structure noise and action are applied to sequence of digits We show the efficacy of our  for modeling this dataset We further show how our model can be  for counterfactual inference for patients  on electronic health record data of  patients over  years</th>\n",
       "      <td>0.100527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.080823</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Many  in AI require the collaboration of multiple agent Typically the communication protocol between agent is manually specified and not altered during training In this  we explore a simple neural model called CommNN that use continuous communication for fully cooperative  The model consist of multiple agent and the communication between them is learned alongside their policy We apply this model to a diverse set of  demonstrating the ability of the agent to learn to communicate amongst themselves yielding improve performance over noncommunicative agent and baseline In some case it is possible to interpret the language devised by the agent revealing simple but effective strategies for solving the  at hand</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recurrent neural network such as the GRU and LSTM found wide adoption in natural language processing and achieve stateoftheart  for many  These model are characterize by a memory state that can be written to and read from by applying gated composition operation to the current input and the previous state However they only cover a small subset of potentially useful compositions We  MultiFunction Recurrent Units MuFuRUs that allow for arbitrary iable function as composition operation Furthermore MuFuRUs allow for an input and statedependent choice of these composition operation that is learned Our experiment  that the additional functionality help in  sequence modeling  including the evaluation of propositional logic formulae language modeling and sentiment analysis</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deep neural network DNNs have demonstrated stateoftheart  on many pattern recognition  especially vision classification  Understanding the inner workings of such computational brains is both fascinating basic science that is interesting in its own rightsimilar to why we study the human brainand will enable researchers to further improve DNNs One path to understanding how a neural network function internally is to study what each of its neurons has learned to detect One such  is called activation maximization AM which synthesizes an input eg an imag that highly activates a neuron Here we dramatically improve the qualitative state of the art of activation maximization by harnessing a powerful learned prior a deep generator network DGN The algorithm  generate qualitatively stateoftheart synthetic imag that look almost real  reveal the feature learned by each neuron in an interpretable way  generalize well to new dataset and somewhat well to  network architecture without requiring the prior to be relearned and  can be considered as a highquality generative  in this case by generating novel creative interesting recognizable imag</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078479</td>\n",
       "      <td>0.074567</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.124013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>We introduce SENets which are deep network designed to model rigid body motion from raw point cloud data Based only on pair of depth imag along with an action vector and point wise data associations SENets learn to segment effected object parts and predict their motion resulting from the applied force Rather than learning point wise low vector SENets predict SE transformation for  parts of the scene Using simulated depth data of a table top scene and a robot manipulator we show that the structure underlying SE Nets enable them to generate a far more consistent prediction of object motion than traditional low  network</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>We trained a convolutional neural network CNN to map raw pixel from a single frontfacing camera directly to steering commands This endtoend  prove surprisingly powerful With minimum training data from human the system learn to drive in traffic on local roads with or without lane markings and on highways It also operate in area with unclear visual guidance such as in parking lots and on unpaved roads The system automatically learn internal representation of the necessary processing step such as detecting useful road feature with only the human steering angle as the training signal We never explicitly trained it to detect for example the outline of roads Compared to explicit decomposition of the  such as lane marking detection path planning and control our endtoend system optimize all processing step simultaneously We argue that this will eventually lead to better performance and smaller systems Better performance will result because the internal component selfoptimize to maximize overall system performance instead of optimizing humanelected intermediate criteria e g lane detection Such criteria understandably are selected for ease of human interpretation which doesnt automatically guarantee maximum system performance Smaller network are possible because the system learn to solve the  with the minima number of processing step We  an NVIDIA DevBox and Torch  for training and an NVIDIA DRIVETM PX selfdriving car compute also running Torch  for determining where to drive The system operate at  frame per second FPS</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.202860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166687</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Despite recent breakthroughs in the application of deep neural network one setting that presents a persistent challenge is that of oneshot learning Traditional gradientbased network require a lot of data to learn often through extensive iterative training When new data is encountered the model must inefficiently relearn their parameter to adequately incorporate the new information without catastrophic interference Architectures with augmented memory capacities such as Neural Turing Machines NTMs offer the ability to quickly encode and retrieve new information and hence can potentially obviate the downsides of conventional model Here we  the ability of a memoryaugmented neural network to rapidly assimilate new data and leverage this data to make accurate prediction after only a few sample We also introduce a new  for accessing an external memory that focuses on memory content unlike previous  that additionally use memory locationbased focusing mechanism</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Video game are a compelling source of annotated data as they can readily  finegrained groundtruth for diverse  However it is not clear whether the synthetically generate data has enough resemblance to the realworld imag to improve the performance of compute vision model in practice We  experiment assessing the effectiveness on realworld data of systems trained on synthetic RGB imag that are extracted from a video game We collected over  synthetic sample from a modern video game with similar condition to the realworld CamVid and Cityscapes dataset We  several experiment to  that the synthetically generate RGB imag can be  to improve the performance of deep neural net on both imag segmentation and depth estimation These  show that a convolutional net trained on synthetic data achieve a similar test error to a net that is trained on realworld data for dense imag classification Furthermore the synthetically generate RGB imag can  similar or better  compare to the realworld dataset if a simple domain adaptation technique is applied Our  suggest that collaboration with game developers for an accessible interface to gather data is potentially a fruitful direction for future  in compute vision</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Physical viability in particular energy efficiency is a key challenge in realizing the true potential of Deep Neural Networks DNNs In this  we aim to incorporate the energy dimension as a design parameter in the higherlevel hierarchy of DNN training and execution to optimize for the energy resources and constraint We use energy characterization to bound the network size in accordance to the pertinent physical resources An automated customization methodology is  to adaptively conform the DNN configuration to the underlying hardware characteristic while minimally affecting the inference accuracy The key to our  is a new context and resource aware projection of data to a lowerdimensional embedding by which learning the correlation between data sample require significantly smaller number of neurons We leverage the performance gain achieve as a result of the data projection to enable the training of  DNN architecture which can be aggregated together to further boost the inference accuracy Accompanying APIs are provided to facilitate rapid prototyping of an arbitrary DNN application customized to the underlying platform Proofofconcept evaluation for deployment of  visual audio and smartsensing benchmark  up to fold energy improvement compare to the priorart DL solution</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Training directed neural net typically require forwardpropagating data through a computation graph followed by backpropagating error signal to produce weight update All layer or more generally modules of the net are therefore locked in the sense that they must wait for the remainder of the net to execute forwards and propagate error backwards before they can be update In this  we break this constraint by decoupling modules by introducing a model of the future computation of the net graph These model predict what the result of the modelled subgraph will produce  only local information In particular we focus on modelling error gradient by  the modelled synthetic gradient in place of true backpropagated error gradient we decouple subgraphs and can update them independently and asynchronously ie we realise decoupled neural interfaces We show  for feedforward model where every layer is trained asynchronously recurrent neural net RNNs where predicting ones future gradient extend the time over which the RNN can effectively model and also a hierarchical RNN system with ticking at  timescales Finally we  that in addition to predicting gradient the same frame can be  to predict input resulting in model which are decoupled in both the forward and backwards pass  amounting to independent net which colearn such that they can be composed into a single functioning corporation</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This  explore conditional imag generation with a new imag density model  on the PixelCNN architecture The model can be conditioned on any vector including descriptive label or tags or latent embedding create by other net When conditioned on class label from the ImageNet database the model is able to generate diverse realistic scene representing distinct animals object landscapes and structure When conditioned on an embedding produce by a convolutional net given a single imag of an unseen face it generate a variety of new portraits of the same person with  facial expression pose and lighting condition We also show that conditional PixelCNN can serve as a powerful decoder in an imag autoencoder Additionally the gated convolutional layer in the  model improve the loglikelihood of PixelCNN to match the stateoftheart performance of PixelRNN on ImageNet with greatly reduce computational cost</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065522</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The move from handdesigned feature to learned feature in machine learning has been wildly successful In spite of this optimization algorithm are still designed by hand In this  we show how the design of an optimization algorithm can be cast as a learning  allowing the algorithm to learn to exploit structure in the s of interest in an automatic way Our learned algorithm implemented by LSTMs outperform generic handdesigned competitors on the  for which they are trained and also generalize well to new  with similar structure We  this on a number of  including simple convex s training neural network and styling imag with neural art</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Scalable and effective exploration remains a key challenge in reinforcement learning RL While there are  with optimality guarantee in the setting of discrete state and action space these  cannot be applied in highdimensional deep RL scenario As such most contemporary RL relies on simple heuristic such as epsilongreedy exploration or adding Gaussian noise to the control This  introduce Variational Information Maximizing Exploration VIME an exploration strategy  on maximization of information gain about the agent belief of environment dynamic We  a practical implementation  variational inference in Bayesian neural network which efficiently handle continuous state and action space VIME modifies the MDP reward function and can be applied with several  underlying RL algorithm We  that VIME achieve significantly better performance compare to heuristic exploration  across a variety of continuous control  and algorithm including  with very sparse reward</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In this  we introduce a novel interpretation of residual net showing they are exponential ensemble This observation is supported by a largescale lesion study that demonstrates they behave just like ensemble at test time Subsequently we perform an analysis showing these ensemble mostly consist of net that are each relatively shallow For example contrary to our expectations most of the gradient in a residual net with  layer come from an ensemble of very short net ie only  layer deep This suggest that in addition to describing neural net in term of width and depth there is a third dimension multiplicity the size of the implicit ensemble Ultimately residual net do not resolve the vanishing gradient  by preserving gradient low throughout the entire depth of the net  rather they avoid the  simply by ensembling many short net together This insight reveal that depth is still an open research question and invites the exploration of the related notion of multiplicity</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>We  an  to training neural network to generate sequence  actorcritic  from reinforcement learning RL Current loglikelihood training  are limited by the discrepancy between their training and testing modes as model must generate tokens conditioned on their previous guesses rather than the groundtruth tokens We address this  by introducing a critic network that is trained to predict the value of an output token given the policy of an actor network This  in a training procedure that is much closer to the test phase and allow us to directly optimize for a pecific core such as BLEU Crucially since we leverage these technique in the supervised learning setting rather than the traditional RL setting we condition the critic network on the groundtruth output We show that our  lead to improve performance on both a synthetic  and for GermanEnglish machine translation Our analysis paves the way for such  to be applied in natural language generation  such as machine translation caption generation and dialogue modelling</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>We  a variety of new architectural feature and training procedure that we apply to the generative adversarial net GANs frame We focus on two application of GANs semisupervised learning and the generation of imag that human find visually realistic Unlike most  on generative model our primary goal is not to train a model that assigns high likelihood to test data nor do we require the model to be able to learn well without  any label Using our new technique we achieve stateoftheart  in semisupervised classification on MNIST CIFAR and SVHN The generate imag are of high quality as confirmed by a visual Turing test our model generate MNIST sample that human cannot distinguish from real data and CIFAR sample that yield a human error rate of  We also  ImageNet sample with unprecedented resolution and show that our  enable the model to learn recognizable feature of ImageNet classes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.244314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.133832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Directly reading document and being able to answer question from them is a key  To avoid its inherent difficult question answering QA has been directed towards  Knowledge Bases KBs instead which has prove effective Unfortunately KBs suffer from often being too restrictive as the schema cannot support certain type of answer and too sparse eg Wikipedia contain much more information than Freebase In this  we introduce a new  KeyValue Memory Nets that make reading document more viable by utilizing  encodings in the addressing and output stage of the memory read operation To compare  KBs information extraction or Wikipedia document directly in a single frame we construct an analysis tool MovieQA a QA dataset in the domain of movies Our  closes the gap between all three setting It also achieve stateoftheart  on the existing WikiQA benchmark</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.097688</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>This  introduce Adaptive Computation Time ACT an algorithm that allow recurrent neural network to learn how many computational step to take between receiving an input and emitting an output ACT require minima change to the network architecture is deterministic and differentiable and does not add any noise to the parameter gradient Experimental  are d for four synthetic s determining the parity of binary vector applying binary logic operation adding integers and sorting real number Overall performance is dramatically improve by the use of ACT which successfully adapts the number of computational step to the requirement of the  We also  characterlevel language modelling  on the Hutter prize Wikipedia dataset In this case ACT does not yield large gain in performance however it does  intriguing insight into the structure of the data with more computation allocated to hardertopredict transitions such as space between word and ends of sentence This suggest that ACT or other adaptive computation  could  a generic  for inferring segment boundaries in sequence data</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165580</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071597</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reinforcement learning offer a promising methodology for developing skills for simulated characters but typically require working with sparse handcrafted feature Building on recent progress in deep reinforcement learning DeepRL we introduce a mixture of actorcritic expert MACE  that learn terrainadaptive dynamic locomotion skills  highdimensional state and terrain description as input and parameterized leaps or step as output action MACE learn more quickly than a single actorcritic  and  in actorcritic expert that exhibit specialization Additional element of our solution that contribute towards efficient learning  Boltzmann exploration and the use of initial actor biases to encourage specialization Results are demonstrated for multiple planar characters and terrain classes</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142229</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The ability to transfer knowledge gained in previous  into new context is one of the most important mechanism of human learning Despite this adapting autonomous behavior to be reused in partially similar setting is still an open  in current robotics research In this  we take a small step in this direction and  a generic framework for learning transferable motion policies Our goal is to solve a learning  in a target domain by utilizing the training data in a  but related source domain We  this in the context of an autonomous MAV flight  monocular reactive control and  the efficacy of our d  through extensive realworld flight experiment in outdoor cluttered environment</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.120550</td>\n",
       "      <td>0.116408</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In a given scene human can often easily predict a set of immediate future event that might happen However generalize pixellevel anticipation in compute vision systems is difficult because machine learning struggles with the ambiguity inherent in predicting the future In this  we focus on predicting the dense trajectory of pixel in a scene specifically what will move in the scene where it will travel and how it will deform over the course of one second We  a conditional variational autoencoder as a solution to this  In this framework direct inference from the imag shape the distribution of possible trajectories while latent variable encode any necessary information that is not available in the imag We show that our  is able to successfully predict event in a wide variety of scene and can produce multiple  prediction when the future is ambiguous Our algorithm is trained on thousands of diverse realistic video and require absolutely no human labeling In addition to nonsemantic action prediction we find that our  learn a representation that is applicable to semantic vision</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.163327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Very deep convolutional network with hundreds of layer have led to significant reductions in error on competitive benchmark Although the unmatched expressiveness of the many layer can be highly desirable at test time training very deep network come with its own set of challenge The gradient can vanish the forward low often diminishes and the training time can be painfully low To address these  we  stochastic depth a training procedure that enable the seemingly contradictory setup to train short network and use deep network at test time We start with very deep network but during training for each minibatch randomly drop a subset of layer and bypass them with the identity function This simple  complements the recent success of residual network It reduce training time substantially and improve the test error significantly on almost all data set that we  for evaluation With stochastic depth we can increase the depth of residual network even beyond  layer and still yield meaningful improvement in test error  on CIFAR</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6605 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        form  structural  \\\n",
       "  Both scientists and children make important s...  0.486326    0.362734   \n",
       "  We  joint estimation of multiple graphical mo...  0.000000    0.000000   \n",
       "  ReLU neural net define piecewise linear funct...  0.000000    0.000000   \n",
       "  Neural network wth rectfed lnear unt actvaton...  0.000000    0.000000   \n",
       "  We  a new framework for manifold denoising  o...  0.065806    0.000000   \n",
       "  An associative memory is a framework of conte...  0.052806    0.000000   \n",
       "  Variational autoencoder VAE are scalable and ...  0.000000    0.000000   \n",
       "  Increasing availability of vehicle GPS data h...  0.000000    0.000000   \n",
       "  We address the  of speeding up the training o...  0.000000    0.000000   \n",
       "  Phase synchronisation in multichannel EEG is ...  0.000000    0.000000   \n",
       "  In this  we  a new primaldual algorithm for m...  0.000000    0.000000   \n",
       "  Coadaptation is a speci form of online learni...  0.127377    0.000000   \n",
       "  Humans are remarkably adept at interpreting t...  0.000000    0.000000   \n",
       "  Plants sense their environment by producing e...  0.000000    0.000000   \n",
       "  We ntroduce a new largescale musc dataset Mus...  0.000000    0.000000   \n",
       "  Demanding sparsity in estimate model has beco...  0.063707    0.000000   \n",
       "  In this  we study the efficiency of a bf Rest...  0.000000    0.000000   \n",
       "  Adaptive scheme where  are assigned  on the d...  0.000000    0.000000   \n",
       "  A binary classifier capable of abstaining fro...  0.000000    0.000000   \n",
       "  In this  we aim at recovering an undirected w...  0.000000    0.000000   \n",
       "  A typical  in causal modeling is the instabil...  0.000000    0.089128   \n",
       "  Gaussian processes GPs are flexible distribut...  0.000000    0.000000   \n",
       "  Modern discriminative predictor have been sho...  0.000000    0.000000   \n",
       "  Relatonal  deals wth data that are characterz...  0.000000    0.000000   \n",
       "  Sources of variability in experimentally deri...  0.000000    0.000000   \n",
       "  We  a general framework for privacypreserving...  0.000000    0.000000   \n",
       "  Various active learning   on logistic regress...  0.000000    0.000000   \n",
       "  The ntroducton of data analytcs nto medcne ha...  0.000000    0.000000   \n",
       "  This  investigates the case of a net of agent...  0.047067    0.000000   \n",
       "  Learning a natural language interface for dat...  0.064598    0.000000   \n",
       "...                                                      ...         ...   \n",
       "Learning to solve complex sequence of while bot...  0.000000    0.000000   \n",
       "We introduce a simple recurrent variational aut...  0.000000    0.000000   \n",
       "We discuss relation between Residual Networks R...  0.000000    0.000000   \n",
       "Inspred by the recent success of  that employ s...  0.108442    0.000000   \n",
       "Residual network family with hundreds or even t...  0.000000    0.000000   \n",
       "We  local binary convolution LBC an efficient a...  0.000000    0.000000   \n",
       "We  a unified framework for learning continuous...  0.000000    0.000000   \n",
       "Recent advance in machine learning have dramati...  0.000000    0.000000   \n",
       "Kalman Filters are one of the most influential ...  0.100527    0.000000   \n",
       "Many  in AI require the collaboration of multip...  0.000000    0.000000   \n",
       "Recurrent neural network such as the GRU and LS...  0.000000    0.000000   \n",
       "Deep neural network DNNs have demonstrated stat...  0.000000    0.000000   \n",
       "We introduce SENets which are deep network desi...  0.000000    0.000000   \n",
       "We trained a convolutional neural network CNN t...  0.000000    0.000000   \n",
       "Despite recent breakthroughs in the application...  0.000000    0.000000   \n",
       "Video game are a compelling source of annotated...  0.000000    0.000000   \n",
       "Physical viability in particular energy efficie...  0.000000    0.000000   \n",
       "Training directed neural net typically require ...  0.000000    0.000000   \n",
       "This  explore conditional imag generation with ...  0.000000    0.000000   \n",
       "The move from handdesigned feature to learned f...  0.000000    0.000000   \n",
       "Scalable and effective exploration remains a ke...  0.000000    0.000000   \n",
       "In this  we introduce a novel interpretation of...  0.000000    0.000000   \n",
       "We  an  to training neural network to generate ...  0.000000    0.000000   \n",
       "We  a variety of new architectural feature and ...  0.000000    0.000000   \n",
       "Directly reading document and being able to ans...  0.000000    0.000000   \n",
       "This  introduce Adaptive Computation Time ACT a...  0.000000    0.000000   \n",
       "Reinforcement learning offer a promising method...  0.000000    0.000000   \n",
       "The ability to transfer knowledge gained in pre...  0.000000    0.000000   \n",
       "In a given scene human can often easily predict...  0.000000    0.000000   \n",
       "Very deep convolutional network with hundreds o...  0.000000    0.000000   \n",
       "\n",
       "                                                    intuitive      bias  \\\n",
       "  Both scientists and children make important s...   0.211940  0.192301   \n",
       "  We  joint estimation of multiple graphical mo...   0.000000  0.000000   \n",
       "  ReLU neural net define piecewise linear funct...   0.000000  0.000000   \n",
       "  Neural network wth rectfed lnear unt actvaton...   0.000000  0.000000   \n",
       "  We  a new framework for manifold denoising  o...   0.000000  0.000000   \n",
       "  An associative memory is a framework of conte...   0.000000  0.000000   \n",
       "  Variational autoencoder VAE are scalable and ...   0.000000  0.000000   \n",
       "  Increasing availability of vehicle GPS data h...   0.000000  0.000000   \n",
       "  We address the  of speeding up the training o...   0.000000  0.000000   \n",
       "  Phase synchronisation in multichannel EEG is ...   0.000000  0.000000   \n",
       "  In this  we  a new primaldual algorithm for m...   0.000000  0.000000   \n",
       "  Coadaptation is a speci form of online learni...   0.000000  0.000000   \n",
       "  Humans are remarkably adept at interpreting t...   0.000000  0.000000   \n",
       "  Plants sense their environment by producing e...   0.000000  0.000000   \n",
       "  We ntroduce a new largescale musc dataset Mus...   0.000000  0.000000   \n",
       "  Demanding sparsity in estimate model has beco...   0.000000  0.000000   \n",
       "  In this  we study the efficiency of a bf Rest...   0.000000  0.000000   \n",
       "  Adaptive scheme where  are assigned  on the d...   0.000000  0.000000   \n",
       "  A binary classifier capable of abstaining fro...   0.000000  0.000000   \n",
       "  In this  we aim at recovering an undirected w...   0.000000  0.000000   \n",
       "  A typical  in causal modeling is the instabil...   0.000000  0.000000   \n",
       "  Gaussian processes GPs are flexible distribut...   0.000000  0.000000   \n",
       "  Modern discriminative predictor have been sho...   0.000000  0.000000   \n",
       "  Relatonal  deals wth data that are characterz...   0.000000  0.000000   \n",
       "  Sources of variability in experimentally deri...   0.000000  0.000000   \n",
       "  We  a general framework for privacypreserving...   0.000000  0.000000   \n",
       "  Various active learning   on logistic regress...   0.000000  0.000000   \n",
       "  The ntroducton of data analytcs nto medcne ha...   0.000000  0.000000   \n",
       "  This  investigates the case of a net of agent...   0.000000  0.000000   \n",
       "  Learning a natural language interface for dat...   0.000000  0.000000   \n",
       "...                                                       ...       ...   \n",
       "Learning to solve complex sequence of while bot...   0.000000  0.000000   \n",
       "We introduce a simple recurrent variational aut...   0.000000  0.000000   \n",
       "We discuss relation between Residual Networks R...   0.000000  0.000000   \n",
       "Inspred by the recent success of  that employ s...   0.000000  0.000000   \n",
       "Residual network family with hundreds or even t...   0.000000  0.000000   \n",
       "We  local binary convolution LBC an efficient a...   0.000000  0.000000   \n",
       "We  a unified framework for learning continuous...   0.000000  0.000000   \n",
       "Recent advance in machine learning have dramati...   0.000000  0.000000   \n",
       "Kalman Filters are one of the most influential ...   0.153333  0.000000   \n",
       "Many  in AI require the collaboration of multip...   0.000000  0.000000   \n",
       "Recurrent neural network such as the GRU and LS...   0.000000  0.000000   \n",
       "Deep neural network DNNs have demonstrated stat...   0.000000  0.000000   \n",
       "We introduce SENets which are deep network desi...   0.000000  0.000000   \n",
       "We trained a convolutional neural network CNN t...   0.000000  0.000000   \n",
       "Despite recent breakthroughs in the application...   0.000000  0.000000   \n",
       "Video game are a compelling source of annotated...   0.000000  0.000000   \n",
       "Physical viability in particular energy efficie...   0.000000  0.000000   \n",
       "Training directed neural net typically require ...   0.000000  0.000000   \n",
       "This  explore conditional imag generation with ...   0.000000  0.000000   \n",
       "The move from handdesigned feature to learned f...   0.000000  0.000000   \n",
       "Scalable and effective exploration remains a ke...   0.000000  0.000000   \n",
       "In this  we introduce a novel interpretation of...   0.000000  0.000000   \n",
       "We  an  to training neural network to generate ...   0.000000  0.000000   \n",
       "We  a variety of new architectural feature and ...   0.000000  0.000000   \n",
       "Directly reading document and being able to ans...   0.000000  0.000000   \n",
       "This  introduce Adaptive Computation Time ACT a...   0.000000  0.000000   \n",
       "Reinforcement learning offer a promising method...   0.000000  0.000000   \n",
       "The ability to transfer knowledge gained in pre...   0.000000  0.000000   \n",
       "In a given scene human can often easily predict...   0.000000  0.000000   \n",
       "Very deep convolutional network with hundreds o...   0.000000  0.000000   \n",
       "\n",
       "                                                     initial  discover  \\\n",
       "  Both scientists and children make important s...  0.190352   0.17779   \n",
       "  We  joint estimation of multiple graphical mo...  0.000000   0.00000   \n",
       "  ReLU neural net define piecewise linear funct...  0.000000   0.00000   \n",
       "  Neural network wth rectfed lnear unt actvaton...  0.000000   0.00000   \n",
       "  We  a new framework for manifold denoising  o...  0.000000   0.00000   \n",
       "  An associative memory is a framework of conte...  0.000000   0.00000   \n",
       "  Variational autoencoder VAE are scalable and ...  0.000000   0.00000   \n",
       "  Increasing availability of vehicle GPS data h...  0.000000   0.00000   \n",
       "  We address the  of speeding up the training o...  0.000000   0.00000   \n",
       "  Phase synchronisation in multichannel EEG is ...  0.000000   0.00000   \n",
       "  In this  we  a new primaldual algorithm for m...  0.000000   0.00000   \n",
       "  Coadaptation is a speci form of online learni...  0.000000   0.00000   \n",
       "  Humans are remarkably adept at interpreting t...  0.000000   0.00000   \n",
       "  Plants sense their environment by producing e...  0.000000   0.00000   \n",
       "  We ntroduce a new largescale musc dataset Mus...  0.000000   0.00000   \n",
       "  Demanding sparsity in estimate model has beco...  0.000000   0.00000   \n",
       "  In this  we study the efficiency of a bf Rest...  0.093443   0.00000   \n",
       "  Adaptive scheme where  are assigned  on the d...  0.000000   0.00000   \n",
       "  A binary classifier capable of abstaining fro...  0.000000   0.00000   \n",
       "  In this  we aim at recovering an undirected w...  0.000000   0.00000   \n",
       "  A typical  in causal modeling is the instabil...  0.000000   0.00000   \n",
       "  Gaussian processes GPs are flexible distribut...  0.000000   0.00000   \n",
       "  Modern discriminative predictor have been sho...  0.000000   0.00000   \n",
       "  Relatonal  deals wth data that are characterz...  0.000000   0.00000   \n",
       "  Sources of variability in experimentally deri...  0.000000   0.00000   \n",
       "  We  a general framework for privacypreserving...  0.000000   0.00000   \n",
       "  Various active learning   on logistic regress...  0.000000   0.00000   \n",
       "  The ntroducton of data analytcs nto medcne ha...  0.000000   0.00000   \n",
       "  This  investigates the case of a net of agent...  0.064478   0.00000   \n",
       "  Learning a natural language interface for dat...  0.000000   0.00000   \n",
       "...                                                      ...       ...   \n",
       "Learning to solve complex sequence of while bot...  0.000000   0.00000   \n",
       "We introduce a simple recurrent variational aut...  0.000000   0.00000   \n",
       "We discuss relation between Residual Networks R...  0.000000   0.00000   \n",
       "Inspred by the recent success of  that employ s...  0.000000   0.00000   \n",
       "Residual network family with hundreds or even t...  0.000000   0.00000   \n",
       "We  local binary convolution LBC an efficient a...  0.000000   0.00000   \n",
       "We  a unified framework for learning continuous...  0.000000   0.00000   \n",
       "Recent advance in machine learning have dramati...  0.000000   0.00000   \n",
       "Kalman Filters are one of the most influential ...  0.000000   0.00000   \n",
       "Many  in AI require the collaboration of multip...  0.000000   0.00000   \n",
       "Recurrent neural network such as the GRU and LS...  0.000000   0.00000   \n",
       "Deep neural network DNNs have demonstrated stat...  0.000000   0.00000   \n",
       "We introduce SENets which are deep network desi...  0.000000   0.00000   \n",
       "We trained a convolutional neural network CNN t...  0.000000   0.00000   \n",
       "Despite recent breakthroughs in the application...  0.000000   0.00000   \n",
       "Video game are a compelling source of annotated...  0.000000   0.00000   \n",
       "Physical viability in particular energy efficie...  0.000000   0.00000   \n",
       "Training directed neural net typically require ...  0.000000   0.00000   \n",
       "This  explore conditional imag generation with ...  0.000000   0.00000   \n",
       "The move from handdesigned feature to learned f...  0.000000   0.00000   \n",
       "Scalable and effective exploration remains a ke...  0.000000   0.00000   \n",
       "In this  we introduce a novel interpretation of...  0.000000   0.00000   \n",
       "We  an  to training neural network to generate ...  0.000000   0.00000   \n",
       "We  a variety of new architectural feature and ...  0.000000   0.00000   \n",
       "Directly reading document and being able to ans...  0.000000   0.00000   \n",
       "This  introduce Adaptive Computation Time ACT a...  0.000000   0.00000   \n",
       "Reinforcement learning offer a promising method...  0.142229   0.00000   \n",
       "The ability to transfer knowledge gained in pre...  0.000000   0.00000   \n",
       "In a given scene human can often easily predict...  0.000000   0.00000   \n",
       "Very deep convolutional network with hundreds o...  0.000000   0.00000   \n",
       "\n",
       "                                                        tree  structure  \\\n",
       "  Both scientists and children make important s...  0.173695   0.156285   \n",
       "  We  joint estimation of multiple graphical mo...  0.000000   0.108435   \n",
       "  ReLU neural net define piecewise linear funct...  0.000000   0.000000   \n",
       "  Neural network wth rectfed lnear unt actvaton...  0.000000   0.000000   \n",
       "  We  a new framework for manifold denoising  o...  0.000000   0.000000   \n",
       "  An associative memory is a framework of conte...  0.000000   0.000000   \n",
       "  Variational autoencoder VAE are scalable and ...  0.000000   0.000000   \n",
       "  Increasing availability of vehicle GPS data h...  0.000000   0.000000   \n",
       "  We address the  of speeding up the training o...  0.000000   0.000000   \n",
       "  Phase synchronisation in multichannel EEG is ...  0.000000   0.000000   \n",
       "  In this  we  a new primaldual algorithm for m...  0.000000   0.000000   \n",
       "  Coadaptation is a speci form of online learni...  0.000000   0.000000   \n",
       "  Humans are remarkably adept at interpreting t...  0.000000   0.000000   \n",
       "  Plants sense their environment by producing e...  0.000000   0.000000   \n",
       "  We ntroduce a new largescale musc dataset Mus...  0.000000   0.000000   \n",
       "  Demanding sparsity in estimate model has beco...  0.000000   0.143309   \n",
       "  In this  we study the efficiency of a bf Rest...  0.000000   0.000000   \n",
       "  Adaptive scheme where  are assigned  on the d...  0.000000   0.000000   \n",
       "  A binary classifier capable of abstaining fro...  0.000000   0.000000   \n",
       "  In this  we aim at recovering an undirected w...  0.000000   0.000000   \n",
       "  A typical  in causal modeling is the instabil...  0.000000   0.051201   \n",
       "  Gaussian processes GPs are flexible distribut...  0.000000   0.000000   \n",
       "  Modern discriminative predictor have been sho...  0.000000   0.000000   \n",
       "  Relatonal  deals wth data that are characterz...  0.000000   0.095708   \n",
       "  Sources of variability in experimentally deri...  0.000000   0.000000   \n",
       "  We  a general framework for privacypreserving...  0.000000   0.000000   \n",
       "  Various active learning   on logistic regress...  0.000000   0.000000   \n",
       "  The ntroducton of data analytcs nto medcne ha...  0.000000   0.000000   \n",
       "  This  investigates the case of a net of agent...  0.000000   0.000000   \n",
       "  Learning a natural language interface for dat...  0.000000   0.000000   \n",
       "...                                                      ...        ...   \n",
       "Learning to solve complex sequence of while bot...  0.000000   0.000000   \n",
       "We introduce a simple recurrent variational aut...  0.000000   0.000000   \n",
       "We discuss relation between Residual Networks R...  0.000000   0.000000   \n",
       "Inspred by the recent success of  that employ s...  0.000000   0.000000   \n",
       "Residual network family with hundreds or even t...  0.000000   0.035077   \n",
       "We  local binary convolution LBC an efficient a...  0.000000   0.000000   \n",
       "We  a unified framework for learning continuous...  0.000000   0.000000   \n",
       "Recent advance in machine learning have dramati...  0.000000   0.000000   \n",
       "Kalman Filters are one of the most influential ...  0.000000   0.075379   \n",
       "Many  in AI require the collaboration of multip...  0.000000   0.000000   \n",
       "Recurrent neural network such as the GRU and LS...  0.000000   0.000000   \n",
       "Deep neural network DNNs have demonstrated stat...  0.000000   0.000000   \n",
       "We introduce SENets which are deep network desi...  0.000000   0.077495   \n",
       "We trained a convolutional neural network CNN t...  0.000000   0.000000   \n",
       "Despite recent breakthroughs in the application...  0.000000   0.000000   \n",
       "Video game are a compelling source of annotated...  0.000000   0.000000   \n",
       "Physical viability in particular energy efficie...  0.000000   0.000000   \n",
       "Training directed neural net typically require ...  0.000000   0.000000   \n",
       "This  explore conditional imag generation with ...  0.000000   0.065522   \n",
       "The move from handdesigned feature to learned f...  0.000000   0.192046   \n",
       "Scalable and effective exploration remains a ke...  0.000000   0.000000   \n",
       "In this  we introduce a novel interpretation of...  0.000000   0.000000   \n",
       "We  an  to training neural network to generate ...  0.000000   0.000000   \n",
       "We  a variety of new architectural feature and ...  0.000000   0.000000   \n",
       "Directly reading document and being able to ans...  0.000000   0.000000   \n",
       "This  introduce Adaptive Computation Time ACT a...  0.000000   0.066774   \n",
       "Reinforcement learning offer a promising method...  0.000000   0.000000   \n",
       "The ability to transfer knowledge gained in pre...  0.000000   0.000000   \n",
       "In a given scene human can often easily predict...  0.000000   0.000000   \n",
       "Very deep convolutional network with hundreds o...  0.000000   0.000000   \n",
       "\n",
       "                                                    knowledge     human  \\\n",
       "  Both scientists and children make important s...   0.140797  0.135959   \n",
       "  We  joint estimation of multiple graphical mo...   0.073267  0.000000   \n",
       "  ReLU neural net define piecewise linear funct...   0.000000  0.000000   \n",
       "  Neural network wth rectfed lnear unt actvaton...   0.000000  0.000000   \n",
       "  We  a new framework for manifold denoising  o...   0.000000  0.000000   \n",
       "  An associative memory is a framework of conte...   0.000000  0.000000   \n",
       "  Variational autoencoder VAE are scalable and ...   0.000000  0.000000   \n",
       "  Increasing availability of vehicle GPS data h...   0.000000  0.000000   \n",
       "  We address the  of speeding up the training o...   0.000000  0.000000   \n",
       "  Phase synchronisation in multichannel EEG is ...   0.000000  0.000000   \n",
       "  In this  we  a new primaldual algorithm for m...   0.000000  0.000000   \n",
       "  Coadaptation is a speci form of online learni...   0.000000  0.000000   \n",
       "  Humans are remarkably adept at interpreting t...   0.000000  0.348158   \n",
       "  Plants sense their environment by producing e...   0.000000  0.000000   \n",
       "  We ntroduce a new largescale musc dataset Mus...   0.000000  0.000000   \n",
       "  Demanding sparsity in estimate model has beco...   0.000000  0.000000   \n",
       "  In this  we study the efficiency of a bf Rest...   0.000000  0.000000   \n",
       "  Adaptive scheme where  are assigned  on the d...   0.000000  0.000000   \n",
       "  A binary classifier capable of abstaining fro...   0.000000  0.000000   \n",
       "  In this  we aim at recovering an undirected w...   0.160316  0.000000   \n",
       "  A typical  in causal modeling is the instabil...   0.069191  0.000000   \n",
       "  Gaussian processes GPs are flexible distribut...   0.000000  0.000000   \n",
       "  Modern discriminative predictor have been sho...   0.000000  0.000000   \n",
       "  Relatonal  deals wth data that are characterz...   0.000000  0.000000   \n",
       "  Sources of variability in experimentally deri...   0.000000  0.000000   \n",
       "  We  a general framework for privacypreserving...   0.000000  0.000000   \n",
       "  Various active learning   on logistic regress...   0.000000  0.000000   \n",
       "  The ntroducton of data analytcs nto medcne ha...   0.000000  0.000000   \n",
       "  This  investigates the case of a net of agent...   0.000000  0.000000   \n",
       "  Learning a natural language interface for dat...   0.065457  0.000000   \n",
       "...                                                       ...       ...   \n",
       "Learning to solve complex sequence of while bot...   0.118845  0.000000   \n",
       "We introduce a simple recurrent variational aut...   0.000000  0.000000   \n",
       "We discuss relation between Residual Networks R...   0.000000  0.000000   \n",
       "Inspred by the recent success of  that employ s...   0.000000  0.000000   \n",
       "Residual network family with hundreds or even t...   0.000000  0.000000   \n",
       "We  local binary convolution LBC an efficient a...   0.000000  0.000000   \n",
       "We  a unified framework for learning continuous...   0.000000  0.000000   \n",
       "Recent advance in machine learning have dramati...   0.000000  0.074265   \n",
       "Kalman Filters are one of the most influential ...   0.000000  0.000000   \n",
       "Many  in AI require the collaboration of multip...   0.000000  0.000000   \n",
       "Recurrent neural network such as the GRU and LS...   0.000000  0.000000   \n",
       "Deep neural network DNNs have demonstrated stat...   0.000000  0.078479   \n",
       "We introduce SENets which are deep network desi...   0.000000  0.000000   \n",
       "We trained a convolutional neural network CNN t...   0.000000  0.202860   \n",
       "Despite recent breakthroughs in the application...   0.000000  0.000000   \n",
       "Video game are a compelling source of annotated...   0.000000  0.000000   \n",
       "Physical viability in particular energy efficie...   0.000000  0.000000   \n",
       "Training directed neural net typically require ...   0.000000  0.000000   \n",
       "This  explore conditional imag generation with ...   0.000000  0.000000   \n",
       "The move from handdesigned feature to learned f...   0.000000  0.000000   \n",
       "Scalable and effective exploration remains a ke...   0.000000  0.000000   \n",
       "In this  we introduce a novel interpretation of...   0.000000  0.000000   \n",
       "We  an  to training neural network to generate ...   0.000000  0.000000   \n",
       "We  a variety of new architectural feature and ...   0.000000  0.244314   \n",
       "Directly reading document and being able to ans...   0.097688  0.000000   \n",
       "This  introduce Adaptive Computation Time ACT a...   0.000000  0.000000   \n",
       "Reinforcement learning offer a promising method...   0.000000  0.000000   \n",
       "The ability to transfer knowledge gained in pre...   0.120550  0.116408   \n",
       "In a given scene human can often easily predict...   0.000000  0.163327   \n",
       "Very deep convolutional network with hundreds o...   0.000000  0.000000   \n",
       "\n",
       "                                                    computational     right  \\\n",
       "  Both scientists and children make important s...       0.129181  0.115584   \n",
       "  We  joint estimation of multiple graphical mo...       0.067222  0.000000   \n",
       "  ReLU neural net define piecewise linear funct...       0.000000  0.000000   \n",
       "  Neural network wth rectfed lnear unt actvaton...       0.000000  0.000000   \n",
       "  We  a new framework for manifold denoising  o...       0.000000  0.000000   \n",
       "  An associative memory is a framework of conte...       0.000000  0.000000   \n",
       "  Variational autoencoder VAE are scalable and ...       0.072858  0.000000   \n",
       "  Increasing availability of vehicle GPS data h...       0.000000  0.000000   \n",
       "  We address the  of speeding up the training o...       0.000000  0.000000   \n",
       "  Phase synchronisation in multichannel EEG is ...       0.000000  0.000000   \n",
       "  In this  we  a new primaldual algorithm for m...       0.000000  0.000000   \n",
       "  Coadaptation is a speci form of online learni...       0.000000  0.000000   \n",
       "  Humans are remarkably adept at interpreting t...       0.198481  0.000000   \n",
       "  Plants sense their environment by producing e...       0.000000  0.000000   \n",
       "  We ntroduce a new largescale musc dataset Mus...       0.000000  0.000000   \n",
       "  Demanding sparsity in estimate model has beco...       0.118455  0.000000   \n",
       "  In this  we study the efficiency of a bf Rest...       0.000000  0.000000   \n",
       "  Adaptive scheme where  are assigned  on the d...       0.000000  0.000000   \n",
       "  A binary classifier capable of abstaining fro...       0.000000  0.000000   \n",
       "  In this  we aim at recovering an undirected w...       0.000000  0.000000   \n",
       "  A typical  in causal modeling is the instabil...       0.000000  0.000000   \n",
       "  Gaussian processes GPs are flexible distribut...       0.064521  0.000000   \n",
       "  Modern discriminative predictor have been sho...       0.000000  0.000000   \n",
       "  Relatonal  deals wth data that are characterz...       0.000000  0.000000   \n",
       "  Sources of variability in experimentally deri...       0.000000  0.000000   \n",
       "  We  a general framework for privacypreserving...       0.000000  0.000000   \n",
       "  Various active learning   on logistic regress...       0.120379  0.000000   \n",
       "  The ntroducton of data analytcs nto medcne ha...       0.000000  0.000000   \n",
       "  This  investigates the case of a net of agent...       0.000000  0.000000   \n",
       "  Learning a natural language interface for dat...       0.000000  0.000000   \n",
       "...                                                           ...       ...   \n",
       "Learning to solve complex sequence of while bot...       0.000000  0.000000   \n",
       "We introduce a simple recurrent variational aut...       0.000000  0.000000   \n",
       "We discuss relation between Residual Networks R...       0.000000  0.000000   \n",
       "Inspred by the recent success of  that employ s...       0.000000  0.000000   \n",
       "Residual network family with hundreds or even t...       0.000000  0.000000   \n",
       "We  local binary convolution LBC an efficient a...       0.044106  0.000000   \n",
       "We  a unified framework for learning continuous...       0.000000  0.000000   \n",
       "Recent advance in machine learning have dramati...       0.000000  0.000000   \n",
       "Kalman Filters are one of the most influential ...       0.000000  0.000000   \n",
       "Many  in AI require the collaboration of multip...       0.000000  0.000000   \n",
       "Recurrent neural network such as the GRU and LS...       0.000000  0.000000   \n",
       "Deep neural network DNNs have demonstrated stat...       0.074567  0.000000   \n",
       "We introduce SENets which are deep network desi...       0.000000  0.000000   \n",
       "We trained a convolutional neural network CNN t...       0.000000  0.000000   \n",
       "Despite recent breakthroughs in the application...       0.000000  0.000000   \n",
       "Video game are a compelling source of annotated...       0.000000  0.000000   \n",
       "Physical viability in particular energy efficie...       0.000000  0.000000   \n",
       "Training directed neural net typically require ...       0.000000  0.000000   \n",
       "This  explore conditional imag generation with ...       0.081238  0.000000   \n",
       "The move from handdesigned feature to learned f...       0.000000  0.000000   \n",
       "Scalable and effective exploration remains a ke...       0.000000  0.000000   \n",
       "In this  we introduce a novel interpretation of...       0.000000  0.000000   \n",
       "We  an  to training neural network to generate ...       0.000000  0.000000   \n",
       "We  a variety of new architectural feature and ...       0.000000  0.000000   \n",
       "Directly reading document and being able to ans...       0.000000  0.000000   \n",
       "This  introduce Adaptive Computation Time ACT a...       0.165580  0.000000   \n",
       "Reinforcement learning offer a promising method...       0.000000  0.000000   \n",
       "The ability to transfer knowledge gained in pre...       0.000000  0.000000   \n",
       "In a given scene human can often easily predict...       0.000000  0.000000   \n",
       "Very deep convolutional network with hundreds o...       0.000000  0.000000   \n",
       "\n",
       "                                                    discovered  understood  \\\n",
       "  Both scientists and children make important s...    0.114679    0.111813   \n",
       "  We  joint estimation of multiple graphical mo...    0.000000    0.000000   \n",
       "  ReLU neural net define piecewise linear funct...    0.000000    0.000000   \n",
       "  Neural network wth rectfed lnear unt actvaton...    0.000000    0.000000   \n",
       "  We  a new framework for manifold denoising  o...    0.000000    0.000000   \n",
       "  An associative memory is a framework of conte...    0.000000    0.000000   \n",
       "  Variational autoencoder VAE are scalable and ...    0.000000    0.000000   \n",
       "  Increasing availability of vehicle GPS data h...    0.000000    0.000000   \n",
       "  We address the  of speeding up the training o...    0.000000    0.000000   \n",
       "  Phase synchronisation in multichannel EEG is ...    0.000000    0.000000   \n",
       "  In this  we  a new primaldual algorithm for m...    0.000000    0.000000   \n",
       "  Coadaptation is a speci form of online learni...    0.000000    0.000000   \n",
       "  Humans are remarkably adept at interpreting t...    0.000000    0.000000   \n",
       "  Plants sense their environment by producing e...    0.000000    0.000000   \n",
       "  We ntroduce a new largescale musc dataset Mus...    0.000000    0.000000   \n",
       "  Demanding sparsity in estimate model has beco...    0.000000    0.000000   \n",
       "  In this  we study the efficiency of a bf Rest...    0.000000    0.000000   \n",
       "  Adaptive scheme where  are assigned  on the d...    0.000000    0.000000   \n",
       "  A binary classifier capable of abstaining fro...    0.000000    0.000000   \n",
       "  In this  we aim at recovering an undirected w...    0.000000    0.000000   \n",
       "  A typical  in causal modeling is the instabil...    0.000000    0.000000   \n",
       "  Gaussian processes GPs are flexible distribut...    0.000000    0.000000   \n",
       "  Modern discriminative predictor have been sho...    0.000000    0.000000   \n",
       "  Relatonal  deals wth data that are characterz...    0.000000    0.000000   \n",
       "  Sources of variability in experimentally deri...    0.000000    0.000000   \n",
       "  We  a general framework for privacypreserving...    0.000000    0.000000   \n",
       "  Various active learning   on logistic regress...    0.000000    0.000000   \n",
       "  The ntroducton of data analytcs nto medcne ha...    0.000000    0.000000   \n",
       "  This  investigates the case of a net of agent...    0.000000    0.000000   \n",
       "  Learning a natural language interface for dat...    0.000000    0.000000   \n",
       "...                                                        ...         ...   \n",
       "Learning to solve complex sequence of while bot...    0.000000    0.000000   \n",
       "We introduce a simple recurrent variational aut...    0.000000    0.000000   \n",
       "We discuss relation between Residual Networks R...    0.000000    0.000000   \n",
       "Inspred by the recent success of  that employ s...    0.000000    0.000000   \n",
       "Residual network family with hundreds or even t...    0.000000    0.000000   \n",
       "We  local binary convolution LBC an efficient a...    0.000000    0.000000   \n",
       "We  a unified framework for learning continuous...    0.000000    0.000000   \n",
       "Recent advance in machine learning have dramati...    0.000000    0.000000   \n",
       "Kalman Filters are one of the most influential ...    0.000000    0.000000   \n",
       "Many  in AI require the collaboration of multip...    0.000000    0.000000   \n",
       "Recurrent neural network such as the GRU and LS...    0.000000    0.000000   \n",
       "Deep neural network DNNs have demonstrated stat...    0.000000    0.000000   \n",
       "We introduce SENets which are deep network desi...    0.000000    0.000000   \n",
       "We trained a convolutional neural network CNN t...    0.000000    0.000000   \n",
       "Despite recent breakthroughs in the application...    0.000000    0.000000   \n",
       "Video game are a compelling source of annotated...    0.000000    0.000000   \n",
       "Physical viability in particular energy efficie...    0.000000    0.000000   \n",
       "Training directed neural net typically require ...    0.000000    0.000000   \n",
       "This  explore conditional imag generation with ...    0.000000    0.000000   \n",
       "The move from handdesigned feature to learned f...    0.000000    0.000000   \n",
       "Scalable and effective exploration remains a ke...    0.000000    0.000000   \n",
       "In this  we introduce a novel interpretation of...    0.000000    0.000000   \n",
       "We  an  to training neural network to generate ...    0.000000    0.000000   \n",
       "We  a variety of new architectural feature and ...    0.000000    0.000000   \n",
       "Directly reading document and being able to ans...    0.000000    0.000000   \n",
       "This  introduce Adaptive Computation Time ACT a...    0.000000    0.000000   \n",
       "Reinforcement learning offer a promising method...    0.000000    0.000000   \n",
       "The ability to transfer knowledge gained in pre...    0.000000    0.000000   \n",
       "In a given scene human can often easily predict...    0.000000    0.000000   \n",
       "Very deep convolutional network with hundreds o...    0.000000    0.000000   \n",
       "\n",
       "                                                       learn  consequence  \\\n",
       "  Both scientists and children make important s...  0.111715     0.111068   \n",
       "  We  joint estimation of multiple graphical mo...  0.058134     0.000000   \n",
       "  ReLU neural net define piecewise linear funct...  0.000000     0.000000   \n",
       "  Neural network wth rectfed lnear unt actvaton...  0.000000     0.000000   \n",
       "  We  a new framework for manifold denoising  o...  0.000000     0.000000   \n",
       "  An associative memory is a framework of conte...  0.127367     0.000000   \n",
       "  Variational autoencoder VAE are scalable and ...  0.000000     0.000000   \n",
       "  Increasing availability of vehicle GPS data h...  0.000000     0.000000   \n",
       "  We address the  of speeding up the training o...  0.000000     0.000000   \n",
       "  Phase synchronisation in multichannel EEG is ...  0.000000     0.000000   \n",
       "  In this  we  a new primaldual algorithm for m...  0.000000     0.000000   \n",
       "  Coadaptation is a speci form of online learni...  0.000000     0.000000   \n",
       "  Humans are remarkably adept at interpreting t...  0.000000     0.000000   \n",
       "  Plants sense their environment by producing e...  0.000000     0.000000   \n",
       "  We ntroduce a new largescale musc dataset Mus...  0.000000     0.000000   \n",
       "  Demanding sparsity in estimate model has beco...  0.000000     0.000000   \n",
       "  In this  we study the efficiency of a bf Rest...  0.000000     0.000000   \n",
       "  Adaptive scheme where  are assigned  on the d...  0.000000     0.000000   \n",
       "  A binary classifier capable of abstaining fro...  0.000000     0.000000   \n",
       "  In this  we aim at recovering an undirected w...  0.000000     0.000000   \n",
       "  A typical  in causal modeling is the instabil...  0.000000     0.000000   \n",
       "  Gaussian processes GPs are flexible distribut...  0.000000     0.000000   \n",
       "  Modern discriminative predictor have been sho...  0.070991     0.000000   \n",
       "  Relatonal  deals wth data that are characterz...  0.000000     0.000000   \n",
       "  Sources of variability in experimentally deri...  0.000000     0.000000   \n",
       "  We  a general framework for privacypreserving...  0.000000     0.000000   \n",
       "  Various active learning   on logistic regress...  0.000000     0.000000   \n",
       "  The ntroducton of data analytcs nto medcne ha...  0.000000     0.000000   \n",
       "  This  investigates the case of a net of agent...  0.075683     0.000000   \n",
       "  Learning a natural language interface for dat...  0.000000     0.000000   \n",
       "...                                                      ...          ...   \n",
       "Learning to solve complex sequence of while bot...  0.000000     0.000000   \n",
       "We introduce a simple recurrent variational aut...  0.000000     0.000000   \n",
       "We discuss relation between Residual Networks R...  0.000000     0.000000   \n",
       "Inspred by the recent success of  that employ s...  0.087186     0.000000   \n",
       "Residual network family with hundreds or even t...  0.000000     0.000000   \n",
       "We  local binary convolution LBC an efficient a...  0.000000     0.000000   \n",
       "We  a unified framework for learning continuous...  0.000000     0.000000   \n",
       "Recent advance in machine learning have dramati...  0.061022     0.000000   \n",
       "Kalman Filters are one of the most influential ...  0.080823     0.000000   \n",
       "Many  in AI require the collaboration of multip...  0.066962     0.000000   \n",
       "Recurrent neural network such as the GRU and LS...  0.000000     0.000000   \n",
       "Deep neural network DNNs have demonstrated stat...  0.000000     0.000000   \n",
       "We introduce SENets which are deep network desi...  0.083093     0.000000   \n",
       "We trained a convolutional neural network CNN t...  0.166687     0.000000   \n",
       "Despite recent breakthroughs in the application...  0.072511     0.000000   \n",
       "Video game are a compelling source of annotated...  0.000000     0.000000   \n",
       "Physical viability in particular energy efficie...  0.000000     0.000000   \n",
       "Training directed neural net typically require ...  0.000000     0.000000   \n",
       "This  explore conditional imag generation with ...  0.000000     0.000000   \n",
       "The move from handdesigned feature to learned f...  0.102958     0.000000   \n",
       "Scalable and effective exploration remains a ke...  0.000000     0.000000   \n",
       "In this  we introduce a novel interpretation of...  0.000000     0.000000   \n",
       "We  an  to training neural network to generate ...  0.000000     0.000000   \n",
       "We  a variety of new architectural feature and ...  0.133832     0.000000   \n",
       "Directly reading document and being able to ans...  0.000000     0.000000   \n",
       "This  introduce Adaptive Computation Time ACT a...  0.071597     0.000000   \n",
       "Reinforcement learning offer a promising method...  0.166945     0.000000   \n",
       "The ability to transfer knowledge gained in pre...  0.000000     0.000000   \n",
       "In a given scene human can often easily predict...  0.067102     0.000000   \n",
       "Very deep convolutional network with hundreds o...  0.000000     0.000000   \n",
       "\n",
       "                                                    model learn      grid  \\\n",
       "  Both scientists and children make important s...     0.109323  0.108993   \n",
       "  We  joint estimation of multiple graphical mo...     0.000000  0.000000   \n",
       "  ReLU neural net define piecewise linear funct...     0.000000  0.000000   \n",
       "  Neural network wth rectfed lnear unt actvaton...     0.000000  0.000000   \n",
       "  We  a new framework for manifold denoising  o...     0.000000  0.000000   \n",
       "  An associative memory is a framework of conte...     0.000000  0.000000   \n",
       "  Variational autoencoder VAE are scalable and ...     0.000000  0.000000   \n",
       "  Increasing availability of vehicle GPS data h...     0.000000  0.000000   \n",
       "  We address the  of speeding up the training o...     0.000000  0.000000   \n",
       "  Phase synchronisation in multichannel EEG is ...     0.000000  0.000000   \n",
       "  In this  we  a new primaldual algorithm for m...     0.000000  0.000000   \n",
       "  Coadaptation is a speci form of online learni...     0.000000  0.000000   \n",
       "  Humans are remarkably adept at interpreting t...     0.000000  0.000000   \n",
       "  Plants sense their environment by producing e...     0.000000  0.000000   \n",
       "  We ntroduce a new largescale musc dataset Mus...     0.000000  0.000000   \n",
       "  Demanding sparsity in estimate model has beco...     0.000000  0.000000   \n",
       "  In this  we study the efficiency of a bf Rest...     0.000000  0.000000   \n",
       "  Adaptive scheme where  are assigned  on the d...     0.000000  0.000000   \n",
       "  A binary classifier capable of abstaining fro...     0.000000  0.000000   \n",
       "  In this  we aim at recovering an undirected w...     0.000000  0.000000   \n",
       "  A typical  in causal modeling is the instabil...     0.000000  0.000000   \n",
       "  Gaussian processes GPs are flexible distribut...     0.000000  0.000000   \n",
       "  Modern discriminative predictor have been sho...     0.000000  0.000000   \n",
       "  Relatonal  deals wth data that are characterz...     0.000000  0.000000   \n",
       "  Sources of variability in experimentally deri...     0.000000  0.000000   \n",
       "  We  a general framework for privacypreserving...     0.000000  0.000000   \n",
       "  Various active learning   on logistic regress...     0.000000  0.000000   \n",
       "  The ntroducton of data analytcs nto medcne ha...     0.000000  0.000000   \n",
       "  This  investigates the case of a net of agent...     0.000000  0.000000   \n",
       "  Learning a natural language interface for dat...     0.000000  0.000000   \n",
       "...                                                         ...       ...   \n",
       "Learning to solve complex sequence of while bot...     0.000000  0.000000   \n",
       "We introduce a simple recurrent variational aut...     0.000000  0.000000   \n",
       "We discuss relation between Residual Networks R...     0.000000  0.000000   \n",
       "Inspred by the recent success of  that employ s...     0.000000  0.000000   \n",
       "Residual network family with hundreds or even t...     0.000000  0.000000   \n",
       "We  local binary convolution LBC an efficient a...     0.000000  0.000000   \n",
       "We  a unified framework for learning continuous...     0.000000  0.000000   \n",
       "Recent advance in machine learning have dramati...     0.000000  0.000000   \n",
       "Kalman Filters are one of the most influential ...     0.000000  0.000000   \n",
       "Many  in AI require the collaboration of multip...     0.000000  0.000000   \n",
       "Recurrent neural network such as the GRU and LS...     0.000000  0.000000   \n",
       "Deep neural network DNNs have demonstrated stat...     0.000000  0.000000   \n",
       "We introduce SENets which are deep network desi...     0.000000  0.000000   \n",
       "We trained a convolutional neural network CNN t...     0.000000  0.000000   \n",
       "Despite recent breakthroughs in the application...     0.000000  0.000000   \n",
       "Video game are a compelling source of annotated...     0.000000  0.000000   \n",
       "Physical viability in particular energy efficie...     0.000000  0.000000   \n",
       "Training directed neural net typically require ...     0.000000  0.000000   \n",
       "This  explore conditional imag generation with ...     0.000000  0.000000   \n",
       "The move from handdesigned feature to learned f...     0.000000  0.000000   \n",
       "Scalable and effective exploration remains a ke...     0.000000  0.000000   \n",
       "In this  we introduce a novel interpretation of...     0.000000  0.000000   \n",
       "We  an  to training neural network to generate ...     0.000000  0.000000   \n",
       "We  a variety of new architectural feature and ...     0.130967  0.000000   \n",
       "Directly reading document and being able to ans...     0.000000  0.000000   \n",
       "This  introduce Adaptive Computation Time ACT a...     0.000000  0.000000   \n",
       "Reinforcement learning offer a promising method...     0.000000  0.000000   \n",
       "The ability to transfer knowledge gained in pre...     0.000000  0.000000   \n",
       "In a given scene human can often easily predict...     0.000000  0.000000   \n",
       "Very deep convolutional network with hundreds o...     0.000000  0.000000   \n",
       "\n",
       "                                                    connectivity  qualitative  \n",
       "  Both scientists and children make important s...      0.108668     0.107421  \n",
       "  We  joint estimation of multiple graphical mo...      0.000000     0.000000  \n",
       "  ReLU neural net define piecewise linear funct...      0.000000     0.000000  \n",
       "  Neural network wth rectfed lnear unt actvaton...      0.000000     0.000000  \n",
       "  We  a new framework for manifold denoising  o...      0.102929     0.000000  \n",
       "  An associative memory is a framework of conte...      0.000000     0.000000  \n",
       "  Variational autoencoder VAE are scalable and ...      0.000000     0.000000  \n",
       "  Increasing availability of vehicle GPS data h...      0.000000     0.000000  \n",
       "  We address the  of speeding up the training o...      0.000000     0.000000  \n",
       "  Phase synchronisation in multichannel EEG is ...      0.085853     0.000000  \n",
       "  In this  we  a new primaldual algorithm for m...      0.000000     0.000000  \n",
       "  Coadaptation is a speci form of online learni...      0.000000     0.000000  \n",
       "  Humans are remarkably adept at interpreting t...      0.000000     0.000000  \n",
       "  Plants sense their environment by producing e...      0.000000     0.000000  \n",
       "  We ntroduce a new largescale musc dataset Mus...      0.000000     0.000000  \n",
       "  Demanding sparsity in estimate model has beco...      0.000000     0.000000  \n",
       "  In this  we study the efficiency of a bf Rest...      0.000000     0.000000  \n",
       "  Adaptive scheme where  are assigned  on the d...      0.000000     0.000000  \n",
       "  A binary classifier capable of abstaining fro...      0.000000     0.000000  \n",
       "  In this  we aim at recovering an undirected w...      0.000000     0.000000  \n",
       "  A typical  in causal modeling is the instabil...      0.000000     0.000000  \n",
       "  Gaussian processes GPs are flexible distribut...      0.000000     0.000000  \n",
       "  Modern discriminative predictor have been sho...      0.000000     0.000000  \n",
       "  Relatonal  deals wth data that are characterz...      0.000000     0.000000  \n",
       "  Sources of variability in experimentally deri...      0.000000     0.000000  \n",
       "  We  a general framework for privacypreserving...      0.000000     0.000000  \n",
       "  Various active learning   on logistic regress...      0.000000     0.000000  \n",
       "  The ntroducton of data analytcs nto medcne ha...      0.000000     0.000000  \n",
       "  This  investigates the case of a net of agent...      0.000000     0.000000  \n",
       "  Learning a natural language interface for dat...      0.000000     0.000000  \n",
       "...                                                          ...          ...  \n",
       "Learning to solve complex sequence of while bot...      0.000000     0.000000  \n",
       "We introduce a simple recurrent variational aut...      0.000000     0.000000  \n",
       "We discuss relation between Residual Networks R...      0.000000     0.000000  \n",
       "Inspred by the recent success of  that employ s...      0.000000     0.000000  \n",
       "Residual network family with hundreds or even t...      0.000000     0.000000  \n",
       "We  local binary convolution LBC an efficient a...      0.000000     0.000000  \n",
       "We  a unified framework for learning continuous...      0.000000     0.000000  \n",
       "Recent advance in machine learning have dramati...      0.000000     0.000000  \n",
       "Kalman Filters are one of the most influential ...      0.000000     0.000000  \n",
       "Many  in AI require the collaboration of multip...      0.000000     0.000000  \n",
       "Recurrent neural network such as the GRU and LS...      0.000000     0.000000  \n",
       "Deep neural network DNNs have demonstrated stat...      0.000000     0.124013  \n",
       "We introduce SENets which are deep network desi...      0.000000     0.000000  \n",
       "We trained a convolutional neural network CNN t...      0.000000     0.000000  \n",
       "Despite recent breakthroughs in the application...      0.000000     0.000000  \n",
       "Video game are a compelling source of annotated...      0.000000     0.000000  \n",
       "Physical viability in particular energy efficie...      0.000000     0.000000  \n",
       "Training directed neural net typically require ...      0.000000     0.000000  \n",
       "This  explore conditional imag generation with ...      0.000000     0.000000  \n",
       "The move from handdesigned feature to learned f...      0.000000     0.000000  \n",
       "Scalable and effective exploration remains a ke...      0.000000     0.000000  \n",
       "In this  we introduce a novel interpretation of...      0.000000     0.000000  \n",
       "We  an  to training neural network to generate ...      0.000000     0.000000  \n",
       "We  a variety of new architectural feature and ...      0.000000     0.000000  \n",
       "Directly reading document and being able to ans...      0.000000     0.000000  \n",
       "This  introduce Adaptive Computation Time ACT a...      0.000000     0.000000  \n",
       "Reinforcement learning offer a promising method...      0.000000     0.000000  \n",
       "The ability to transfer knowledge gained in pre...      0.000000     0.000000  \n",
       "In a given scene human can often easily predict...      0.000000     0.000000  \n",
       "Very deep convolutional network with hundreds o...      0.000000     0.000000  \n",
       "\n",
       "[6605 rows x 20 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.transpose().sort_values(result_abs[0], ascending=False).head(20).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
