title,abstract
SCALABLE TRAINING OF DEEP LEARNING MACHINES BY INCREMENTAL BLOCK TRAINING,"We present a new approach to scalable training of deep learning
machines by incremental block training with intra-block parallel optimization
to leverage data parallelism and blockwise model-update
filtering to stabilize learning process. By using an implementation
on a distributed GPU cluster with an MPI-based HPC machine
learning framework to coordinate parallel job scheduling and collective
communication, we have trained successfully deep bidirectional
long short-term memory (LSTM) recurrent neural networks (RNNs)
and fully-connected feed-forward deep neural networks (DNNs) for
large vocabulary continuous speech recognition on two benchmark
tasks, namely 309-hour Switchboard-I task and 1,860-hour ‚ÄúSwitchboard+Fisher‚Äù
task. We achieve almost linear speedup up to 16 GPU
cards on LSTM task and 64 GPU cards on DNN task, with either no
degradation or improved recognition accuracy in comparison with
that of running a traditional mini-batch based stochastic gradient
descent training on a single GPU.
"
Scalable and Sustainable Deep Learning via Randomized Hashing,"Current deep learning architectures are growing larger in order to learn from enormous datasets. These architectures require giant matrix multiplication operations to train millions or billions of parameters during forward and back propagation steps. These operations are very expensive from a computational and energy standpoint. We present a novel technique to reduce the amount of computation needed to train and test deep networks drastically. Our approach combines recent ideas from adaptive dropouts and randomized hashing for maximum inner product search to select only the nodes with the highest activation efficiently. Our new algorithm for training deep networks reduces the overall computational cost, of both feed-forward pass and backpropagation, by operating on significantly fewer nodes. As a consequence, our algorithm only requires 5% of computations (multiplications) compared to traditional algorithms, without any loss in the accuracy. Furthermore, due to very sparse gradient updates, our algorithm is ideally suited for asynchronous training leading to near linear speedup with increasing parallelism. We demonstrate the scalability and sustainability (energy efficiency) of our proposed algorithm via rigorous experimental evaluations."
Unifying Count-Based Exploration and Intrinsic Motivation,"We consider an agent‚Äôs uncertainty about its environment and the problem of generalizing this uncertainty across observations. Specifically, we focus on the problem of exploration in non-tabular reinforcement learning. Drawing inspiration from the intrinsic motivation literature, we use sequential density models to measure uncertainty, and propose a novel algorithm for deriving a pseudo-count from an arbitrary sequential density model. This technique enables us to generalize count-based exploration algorithms to the non-tabular case. We apply our ideas to Atari 2600 games, providing sensible pseudo-counts from raw pixels. We transform these pseudo-counts into intrinsic rewards and obtain significantly improved exploration in a number of hard games, including the infamously difficult MONTEZUMA‚ÄôS REVENGE."
Improving Variational Inference with Inverse Autoregressive Flow,"We propose a simple and scalable method for improving the flexibility of variational inference through a transformation with autoregressive networks. Autoregressive networks, such as RNNs and MADE, are very powerful models; however, ancestral sampling in such networks is a sequential operation, therefore unappealing for direct use as approximate posteriors in variational inference on parallel hardware such as GPUs. We find that by inverting autoregressive networks we can obtain equally powerful data transformations that can often be computed in parallel. We show that such data transformations, inverse autoregressive flows (IAF), can be used to transform a simple distribution over the latent variables into a much more flexible distribution, while still allowing us to compute the resulting variables' probability density function. The method is simple to implement, can be made arbitrarily flexible, and (in contrast with previous work) is naturally applicable to latent variables that are organized in multidimensional tensors, such as 2D grids or time series. The method is applied to a novel deep architecture of variational auto-encoders. In experiments we demonstrate that autoregressive flow leads to significant performance gains when applied to variational autoencoders for natural images."
InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets,"This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound of the mutual information objective that can be optimized efficiently. Specifically, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset. It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the CelebA face dataset. Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing supervised methods."
Colorful Image Colorization,"
Given a grayscale photograph as input, this paper attacks the problem of hallucinating a plausible color version of the photograph.	This problem is clearly underconstrained, so previous approaches have either relied on significant user interaction or resulted in desaturated colorizations. We propose a fully automatic approach that produces vibrant and realistic colorizations. We embrace the underlying uncertainty of the	problem by posing it as a classification task and use class-rebalancing at training time to increase the diversity of colors in the result. The system is implemented as a feed-forward pass in a CNN at test time and is trained on over a million color images. We evaluate our algorithm using a ""colorization Turing test,"" asking human participants to choose between a generated and ground truth color image. Our method successfully fools	humans on 32% of the trials, significantly higher than previous methods. Moreover, we show that colorization can be a powerful pretext task for	self-supervised feature learning, acting as a cross-channel encoder. This approach results in state-of-the-art performance on several feature learning benchmarks."
Structured Prediction Energy Networks,"We introduce structured prediction energy networks (SPENs), a flexible framework for structured prediction. A deep architecture is used to define an energy function of candidate labels, and then predictions are produced by using back-propagation to iteratively optimize the energy with respect to the labels. This deep architecture captures dependencies between labels that would lead to intractable graphical models, and performs structure learning by automatically learning discriminative features of the structured output. One natural application of our technique is multi-label classification, which traditionally has required strict prior assumptions about the interactions between labels to ensure tractable learning and prediction. We are able to apply SPENs to multi-label problems with substantially larger label sets than previous applications of structured prediction, while modeling high-order interactions using minimal structural assumptions. Overall, deep learning provides remarkable tools for learning features of the inputs to a prediction problem, and this work extends these techniques to learning features of structured outputs. Our experiments provide impressive performance on a variety of benchmark multi-label classification tasks, demonstrate that our technique can be used to provide interpretable structure learning, and illuminate fundamental trade-offs between feed-forward and iterative structured prediction."
BioSpaun: A large-scale behaving brain model with complex neurons,"We describe a large-scale functional brain model that includes detailed, conductance-based, compartmental models of individual neurons. We call the model BioSpaun, to indicate the increased biological plausibility of these neurons, and because it is a direct extension of the Spaun model \cite{Eliasmith2012b}. We demonstrate that including these detailed compartmental models does not adversely affect performance across a variety of tasks, including digit recognition, serial working memory, and counting. We then explore the effects of applying TTX, a sodium channel blocking drug, to the model. We characterize the behavioral changes that result from this molecular level intervention. We believe this is the first demonstration of a large-scale brain model that clearly links low-level molecular interventions and high-level behavior."
DSD: Regularizing Deep Neural Networks with Dense-Sparse-Dense Training Flow,"Modern deep neural networks have a large number of parameters, making them very powerful machine learning systems. A critical issue for training such large networks on large-scale data-sets is to prevent overfitting while at the same time providing enough model capacity. We propose DSD, a dense-sparse-dense training flow, for regularizing deep neural networks. In the first D step, we train a dense network to learn which connections are important. In the S step, we regularize the network by pruning the unimportant connections and retrain the network given the sparsity constraint. In the final D step, we increase the model capacity by freeing the sparsity constraint, re-initializing the pruned parameters, and retraining the whole dense network. Experiments show that DSD training can improve the performance of a wide range of CNN, RNN and LSTMs on the tasks of image classification, caption generation and speech recognition. On the Imagenet dataset, DSD improved the absolute accuracy of AlexNet, GoogleNet, VGG-16, ResNet-50, ResNet-152 and SqueezeNet by a geo-mean of 2.1 points(Top-1) and 1.4 points(Top-5). On the WSJ'92 and WSJ'93 dataset, DSD improved DeepSpeech-2 WER by 0.53 and 1.08 points. On the Flickr-8K dataset, DSD improved the NeuralTalk BLEU score by 2.0 points. DSD training flow produces the same model architecture and doesn't incur any inference overhead."
Benchmarking Deep Reinforcement Learning for Continuous Control,"Recently, researchers have made significant progress combining the advances in deep learning for learning feature representations with reinforcement learning. Some notable examples include training agents to play Atari games based on raw pixel data and to acquire advanced manipulation skills using raw sensory inputs. However, it has been difficult to quantify progress in the domain of continuous control due to the lack of a commonly adopted benchmark. In this work, we present a benchmark suite of continuous control tasks, including classic tasks like cart-pole swing-up, tasks with very high state and action dimensionality such as 3D humanoid locomotion, tasks with partial observations, and tasks with hierarchical structure. We report novel findings based on the systematic evaluation of a range of implemented reinforcement learning algorithms. Both the benchmark and reference implementations are released at https://github.com/rllab/rllab in order to facilitate experimental reproducibility and to encourage adoption by other researchers."
Layer Normalization,"Training state-of-the-art, deep neural networks is computationally expensive. One way to reduce the training time is to normalize the activities of the neurons. A recently introduced technique called batch normalization uses the distribution of the summed input to a neuron over a mini-batch of training cases to compute a mean and variance which are then used to normalize the summed input to that neuron on each training case. This significantly reduces the training time in feed-forward neural networks. However, the effect of batch normalization is dependent on the mini-batch size and it is not obvious how to apply it to recurrent neural networks. In this paper, we transpose batch normalization into layer normalization by computing the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. Like batch normalization, we also give each neuron its own adaptive bias and gain which are applied after the normalization but before the non-linearity. Unlike batch normalization, layer normalization performs exactly the same computation at training and test times. It is also straightforward to apply to recurrent neural networks by computing the normalization statistics separately at each time step. Layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques."
Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization,"Reinforcement learning can acquire complex behaviors from high-level specifications. However, defining a cost function that can be optimized effectively and encodes the correct task is challenging in practice. We explore how inverse optimal control (IOC) can be used to learn behaviors from demonstrations, with applications to torque control of high-dimensional robotic systems. Our method addresses two key challenges in inverse optimal control: first, the need for informative features and effective regularization to impose structure on the cost, and second, the difficulty of learning the cost function under unknown dynamics for high-dimensional continuous systems. To address the former challenge, we present an algorithm capable of learning arbitrary nonlinear cost functions, such as neural networks, without meticulous feature engineering. To address the latter challenge, we formulate an efficient sample-based approximation for MaxEnt IOC. We evaluate our method on a series of simulated tasks and real-world robotic manipulation problems, demonstrating substantial improvement over prior methods both in terms of task complexity and sample efficiency."
Variational Information Maximizing Exploration,"Scalable and effective exploration remains a key challenge in reinforcement learning (RL). While there are methods with optimality guarantees in the setting of discrete state and action spaces, these methods cannot be applied in high-dimensional deep RL scenarios. As such, most contemporary RL relies on simple heuristics such as -greedy exploration or adding Gaussian noise to the controls. This paper introduces Variational Information Maximizing Exploration (VIME), an exploration strategy based on maximization of information gain about the agent‚Äôs belief of environment dynamics. We propose a practical implementation, using variational inference in Bayesian neural networks which efficiently handles continuous state and action spaces. VIME modifies the MDP reward function, and can be applied with several different underlying RL algorithms. We demonstrate that VIME achieves significantly better performance compared to heuristic exploration methods across a variety of continuous control tasks and algorithms, including tasks with very sparse rewards."
Blockout: Dynamic Model Selection for Hierarchical Deep Networks,"Most deep architectures for image classification--even those that are trained to classify a large number of diverse categories--learn shared image representations with a single model. Intuitively, however, categories that are more similar should share more information than those that are very different. While hierarchical deep networks address this problem by learning separate features for subsets of related categories, current implementations require simplified models using fixed architectures specified via heuristic clustering methods. Instead, we propose Blockout, a method for regularization and model selection that simultaneously learns both the model architecture and parameters. A generalization of Dropout, our approach gives a novel parametrization of hierarchical architectures that allows for structure learning via back-propagation. To demonstrate its utility, we evaluate Blockout on the CIFAR and ImageNet datasets, demonstrating improved classification accuracy, better regularization performance, faster training, and the clear emergence of hierarchical network structures."
Progressive Neural Networks,"Learning to solve complex sequences of tasks--while both leveraging transfer and avoiding catastrophic forgetting--remains a key obstacle to achieving human-level intelligence. The progressive networks approach represents a step forward in this direction: they are immune to forgetting and can leverage prior knowledge via lateral connections to previously learned features. We evaluate this architecture extensively on a wide variety of reinforcement learning tasks (Atari and 3D maze games), and show that it outperforms common baselines based on pretraining and finetuning. Using a novel sensitivity measure, we demonstrate that transfer occurs at both low-level sensory and high-level control layers of the learned policy."
 Towards Conceptual Compression,"We introduce a simple recurrent variational autoencoder
architecture that significantly improves
image modeling. The system represents the stateof-the-art
in latent variable models for both the
ImageNet and Omniglot datasets. We show that
it naturally separates global conceptual information
from lower level details, thus addressing one
of the fundamentally desired properties of unsupervised
learning. Furthermore, the possibility of
restricting ourselves to storing only global information
about an image allows us to achieve high
quality ‚Äòconceptual compression‚Äô."
"Bridging the Gaps Between Residual Learning, Recurrent Neural Networks and Visual Cortex","We discuss relations between Residual Networks (ResNet), Recurrent Neural Networks (RNNs) and
the primate visual cortex. We begin with the observation that a shallow RNN is exactly equivalent to a very deep
ResNet with weight sharing among the layers. A direct implementation of such a RNN, although having orders
of magnitude fewer parameters, leads to a performance similar to the corresponding ResNet. We propose 1) a
generalization of both RNN and ResNet architectures and 2) the conjecture that a class of moderately deep RNNs
is a biologically-plausible model of the ventral stream in visual cortex. We demonstrate the effectiveness of the
architectures by testing them on the CIFAR-10 dataset."
3D-R2N2: A Unified Approach for Single and Multi-view 3D Object Reconstruction,"Inspired by the recent success of methods that employ shape
priors to achieve robust 3D reconstructions, we propose a novel recurrent
neural network architecture that we call the 3D Recurrent Reconstruction
Neural Network (3D-R2N2). The network learns a mapping from
images of objects to their underlying 3D shapes from a large collection
of synthetic data [1]. Our network takes in one or more images of an object
instance from arbitrary viewpoints and outputs a reconstruction of
the object in the form of a 3D occupancy grid. Unlike most of the previous
works, our network does not require any image annotations or object
class labels for training or testing. Our extensive experimental analysis
shows that our reconstruction framework i) outperforms the state-of-theart
methods for single view reconstruction, and ii) enables the 3D reconstruction
of objects in situations when traditional SFM/SLAM methods
fail (because of lack of texture and/or wide baseline)."
Adversarial Feature Learning,"The ability of the Generative Adversarial Networks (GANs) framework to learn
generative models mapping from simple latent distributions to arbitrarily complex
data distributions has been demonstrated empirically, with compelling results
showing generators learn to ‚Äúlinearize semantics‚Äù in the latent space of such
models. Intuitively, such latent spaces may serve as useful feature representations
for auxiliary problems where semantics are relevant. However, in their existing
form, GANs have no means of learning the inverse mapping ‚Äì projecting data
back into the latent space. We propose Bidirectional Generative Adversarial
Networks (BiGANs) as a means of learning this inverse mapping, and demonstrate
that the resulting learned feature representation is useful for auxiliary supervised
discrimination tasks, competitive with contemporary approaches to unsupervised
and self-supervised feature learning."
Adversarially Learned Inference,"We introduce the adversarially learned inference (ALI) model, which jointly learns
a generation network and an inference network using an adversarial process. The
generation network maps samples from stochastic latent variables to the data space
while the inference network maps training examples in data space to the space of
latent variables. An adversarial game is cast between these two networks and a
discriminative network that is trained to distinguish between joint latent/data-space
samples from the generative network and joint samples from the inference network.
We illustrate the ability of the model to learn mutually coherent inference and generation
networks through the inspections of model samples and reconstructions and
confirm the usefulness of the learned representations by obtaining a performance
competitive with other recent approaches on the semi-supervised SVHN task."
A Neural Knowledge Language Model,"Communicating knowledge is a primary purpose of language. However, current
language models have significant limitations in their ability to encode or decode
knowledge. This is mainly because they acquire knowledge based on statistical
co-occurrences, even if most of the knowledge words are rarely observed named
entities. In this paper, we propose a Neural Knowledge Language Model (NKLM)
which combines symbolic knowledge provided by knowledge graphs with RNN
language models. At each time step, the model predicts a fact on which the observed
word is supposed to be based. Then, a word is either generated from the vocabulary
or copied from the knowledge graph. We train and test the model on a new dataset,
WikiFacts. In experiments, we show that the NKLM significantly improves the
perplexity while generating a much smaller number of unknown words. In addition,
we demonstrate that the sampled descriptions include named entities which were
used to be the unknown words in RNN language models."
Residual Networks of Residual Networks: Multilevel Residual Networks,"Residual networks family with hundreds or even thousands of layers dominate major image recognition tasks, but building a network by simply stacking residual blocks inevitably limits its optimization ability. This paper proposes a novel residual-network architecture, Residual networks of Residual networks (RoR), to dig the optimization ability of residual networks. RoR substitutes optimizing residual mapping of residual mapping for optimizing original residual mapping, in particular, adding level-wise shortcut connections upon original residual networks, to promote the learning capability of residual networks. More importantly, RoR can be applied to various kinds of residual networks (Pre-ResNets and WRN) and significantly boost their performance. Our experiments demonstrate the effectiveness and versatility of RoR, where it achieves the best performance in all residual-network-like structures. Our RoR-3-WRN58-4 models achieve new state-of-the-art results on CIFAR-10, CIFAR-100 and SVHN, with test errors 3.77%, 19.73% and 1.59% respectively. These results outperform 1001-layer Pre-ResNets by 18.4% on CIFAR-10 and 13.1% on CIFAR-100."
Local Binary Convolutional Neural Networks,"We propose local binary convolution (LBC), an efficient alternative to convolutional
layers in standard convolutional neural networks (CNN). The design principles of
LBC are motivated by local binary patterns (LBP). The LBC layer comprises of
a set of fixed sparse pre-defined binary convolutional filters that are not updated
during the training process, a non-linear activation function and a set of learnable
linear weights. The linear weights combine the activated filter responses to approximate
the corresponding activated filter responses of a standard convolutional layer.
The LBC layer affords significant parameter savings, 9√ó to 169√ó in the number
of learnable parameters compared to a standard convolutional layer. Furthermore,
due to lower model complexity and sparse and binary nature of the weights also
results in up to 9√ó to 169√ó savings in model size compared to a standard convolutional
layer. We demonstrate both theoretically and experimentally that our local
binary convolution layer is a good approximation of a standard convolutional layer.
Empirically, CNNs with LBC layers, called local binary convolutional neural
networks (LBCNN), reach state-of-the-art performance on a range of visual datasets
(MNIST, SVHN, CIFAR-10, and a subset of ImageNet) while enjoying significant
computational savings."
f-GAN: Training Generative Neural Samplers using Variational Divergence Minimization,"Generative neural samplers are probabilistic models that implement sampling using
feedforward neural networks: they take a random input vector and produce a sample
from a probability distribution defined by the network weights. These models
are expressive and allow efficient computation of samples and derivatives, but
cannot be used for computing likelihoods or for marginalization. The generative adversarial
training method allows to train such models through the use of an
auxiliary discriminative neural network. We show that the generative-adversarial
approach is a special case of an existing more general variational divergence
estimation approach. We show that any f-divergence can be used for training
generative neural samplers. We discuss the benefits of various choices of divergence
functions on training complexity and the quality of the obtained generative models."
Learning Continuous Control Policies by Stochastic Value Gradients,"We present a unified framework for learning continuous control policies using
backpropagation. It supports stochastic control by treating stochasticity in the
Bellman equation as a deterministic function of exogenous noise. The product
is a spectrum of general policy gradient algorithms that range from model-free
methods with value functions to model-based methods without value functions.
We use learned models but only require observations from the environment instead
of observations from model-predicted trajectories, minimizing the impact
of compounded model errors. We apply these algorithms first to a toy stochastic
control problem and then to several physics-based control problems in simulation.
One of these variants, SVG(1), shows the effectiveness of learning models, value
functions, and policies simultaneously in continuous domains."
End to end active perception,"Recent advances in machine learning have dramatically improved the accuracy of object recognition in static images. However, humans and animals are rarely confronted with images that are completely static, and typically perform a variety of interventions to aid in object recognition, from changes in viewpoint to active manipulation, such as turning an object around to see it from all sides or removing occluders. Such active perception is particularly important in robotics, where correct object classification is often crucial, and active interventions are available to aid in recognition. In this paper, we present a method that can learn such active interventions, and evaluate our method on a simulated environment that we call ``Occluded MNIST,'' which requires the agent to push distractor objects out of the way to perform successful recognition. We evaluate a variety of solutions based on reinforcement learning and demonstrate that active intervention substantially improves recognition accuracy over a passive baseline."
Deep Kalman Filters,"Kalman Filters are one of the most influential models of time-varying phenomena. They admit an intuitive probabilistic interpretation, have a simple functional form, and enjoy widespread adoption in a variety of disciplines. Motivated by recent variational methods for learning deep generative models, we introduce a unified algorithm to efficiently learn a broad spectrum of Kalman filters. Of particular interest is the use of temporal generative models for counterfactual inference. We investigate the efficacy of such models for counterfactual inference, and to that end we introduce the ""Healing MNIST"" dataset where long-term structure, noise and actions are applied to sequences of digits. We show the efficacy of our method for modeling this dataset. We further show how our model can be used for counterfactual inference for patients, based on electronic health record data of 8,000 patients over 4.5 years.
"
Learning Multiagent Communication with Backpropagation,"Many tasks in AI require the collaboration of multiple agents. Typically, the communication protocol between agents is manually specified and not altered during training. In this paper we explore a simple neural model, called CommNN, that uses continuous communication for fully cooperative tasks. The model consists of multiple agents and the communication between them is learned alongside their policy. We apply this model to a diverse set of tasks, demonstrating the ability of the agents to learn to communicate amongst themselves, yielding improved performance over non-communicative agents and baselines. In some cases, it is possible to interpret the language devised by the agents, revealing simple but effective strategies for solving the task at hand.
"
MuFuRU: The Multi-Function Recurrent Unit,"Recurrent neural networks such as the GRU and LSTM found wide adoption in natural language processing and achieve state-of-the-art results for many tasks. These models are characterized by a memory state that can be written to and read from by applying gated composition operations to the current input and the previous state. However, they only cover a small subset of potentially useful compositions. We propose Multi-Function Recurrent Units (MuFuRUs) that allow for arbitrary differentiable functions as composition operations. Furthermore, MuFuRUs allow for an input- and state-dependent choice of these composition operations that is learned. Our experiments demonstrate that the additional functionality helps in different sequence modeling tasks, including the evaluation of propositional logic formulae, language modeling and sentiment analysis.
"
Sequence-to-Sequence Learning as Beam-Search Optimization,"Sequence-to-Sequence (seq2seq) modeling has rapidly become an important general-purpose NLP tool that has proven effective for many text-generation and sequence-labeling tasks. Seq2seq builds on deep neural language modeling and inherits its remarkable accuracy in estimating local, next-word distributions. In this work, we introduce a model and beam-search training scheme, based on the work of Daume III and Marcu (2005), that extends seq2seq to learn global sequence scores. This structured approach avoids classical biases associated with local training and unifies the training loss with the test-time usage, while preserving the proven model architecture of seq2seq and its efficient training approach. We show that our system outperforms a highly-optimized attention-based seq2seq system and other baselines on three different sequence to sequence tasks: word ordering, parsing, and machine translation.
"
Stochastic Variance Reduction for Nonconvex Optimization,"We study nonconvex finite-sum problems and analyze stochastic variance reduced gradient (SVRG) methods for them. SVRG and related methods have recently surged into prominence for convex optimization given their edge over stochastic gradient descent (SGD); but their theoretical analysis almost exclusively assumes convexity. In contrast, we prove non-asymptotic rates of convergence (to stationary points) of SVRG for nonconvex optimization, and show that it is provably faster than SGD and gradient descent. We also analyze a subclass of nonconvex problems on which SVRG attains linear convergence to the global optimum. We extend our analysis to mini-batch variants of SVRG, showing (theoretical) linear speedup due to mini-batching in parallel settings."
End-to-End Kernel Learning with Supervised Convolutional Kernel Networks,"In this paper, we propose a new image representation based on a multilayer kernel machine that performs end-to-end learning. Unlike traditional kernel methods, where the kernel is handcrafted or adapted to data in an unsupervised manner, we learn how to shape the kernel for a supervised prediction problem. We proceed by generalizing convolutional kernel networks, which originally provide unsupervised image representations, and we derive backpropagation rules to optimize model parameters. As a result, we obtain a new type of convolutional neural network with the following properties: (i) at each layer, learning filters is equivalent to optimizing a linear subspace in a reproducing kernel Hilbert space (RKHS), where we project data, (ii) the network may be learned with supervision or without, (iii) the model comes with a natural regularization function (the norm in the RKHS). We show that our method achieves reasonably competitive performance on some standard ""deep learning"" image classification datasets such as CIFAR-10 and SVHN, and also state-of-the-art results for image super-resolution, demonstrating the applicability of our approach to a large variety of image-related tasks."
Neural Semantic Encoders,"We present a memory augmented neural network for natural language understanding:
Neural Semantic Encoders (NSE). NSE has a variable sized encoding memory
that evolves over time and maintains the understanding of input sequences through
read, compose and write operations. NSE can access1 multiple and shared memories
depending on the complexity of a task. We demonstrated the effectiveness
and the flexibility of NSE on five different natural language tasks, natural language
inference, question answering, sentence classification, document sentiment analysis
and machine translation where NSE achieved state-of-the-art performance when
evaluated on publically available benchmarks. For example, our shared-memory
model showed an encouraging result on neural machine translation, improving an
attention-based baseline by approximately 1.0 BLEU."
Synthesizing the preferred inputs for neurons in neural networks via deep generator networks,"Deep neural networks (DNNs) have demonstrated state-of-the-art results on many
pattern recognition tasks, especially vision classification problems. Understanding
the inner workings of such computational brains is both fascinating basic science
that is interesting in its own right‚Äîsimilar to why we study the human brain‚Äîand
will enable researchers to further improve DNNs. One path to understanding
how a neural network functions internally is to study what each of its neurons
has learned to detect. One such method is called activation maximization (AM),
which synthesizes an input (e.g. an image) that highly activates a neuron. Here
we dramatically improve the qualitative state of the art of activation maximization
by harnessing a powerful, learned prior: a deep generator network (DGN). The
algorithm (1) generates qualitatively state-of-the-art synthetic images that look
almost real, (2) reveals the features learned by each neuron in an interpretable
way, (3) generalizes well to new datasets and somewhat well to different network
architectures without requiring the prior to be relearned, and (4) can be considered
as a high-quality generative method (in this case, by generating novel, creative,
interesting, recognizable images)."
SE3-Nets: Learning Rigid Body Motion using Deep Neural Networks,"We introduce SE3-Nets which are deep networks
designed to model rigid body motion from raw point cloud data.
Based only on pairs of depth images along with an action vector
and point wise data associations, SE3-Nets learn to segment
effected object parts and predict their motion resulting from
the applied force. Rather than learning point wise flow vectors,
SE3-Nets predict SE3 transformations for different parts of the
scene. Using simulated depth data of a table top scene and a
robot manipulator, we show that the structure underlying SE3-
Nets enables them to generate a far more consistent prediction
of object motion than traditional flow based networks."
End to End Learning for Self-Driving Cars,"We trained a convolutional neural network (CNN) to map raw pixels from a single
front-facing camera directly to steering commands. This end-to-end approach
proved surprisingly powerful. With minimum training data from humans the system
learns to drive in traffic on local roads with or without lane markings and on
highways. It also operates in areas with unclear visual guidance such as in parking
lots and on unpaved roads.
The system automatically learns internal representations of the necessary processing
steps such as detecting useful road features with only the human steering angle
as the training signal. We never explicitly trained it to detect, for example, the outline
of roads.
Compared to explicit decomposition of the problem, such as lane marking detection,
path planning, and control, our end-to-end system optimizes all processing
steps simultaneously. We argue that this will eventually lead to better performance
and smaller systems. Better performance will result because the internal
components self-optimize to maximize overall system performance, instead of optimizing
human-selected intermediate criteria, e. g., lane detection. Such criteria
understandably are selected for ease of human interpretation which doesn‚Äôt automatically
guarantee maximum system performance. Smaller networks are possible
because the system learns to solve the problem with the minimal number of
processing steps.
We used an NVIDIA DevBox and Torch 7 for training and an NVIDIA
DRIVETM PX self-driving car computer also running Torch 7 for determining
where to drive. The system operates at 30 frames per second (FPS)."
Gated-Attention Readers for Text Comprehension,"In this paper we study the problem of answering cloze-style questions over short documents. We introduce a new attention mechanism which uses multiplicative interactions between the query embedding and intermediate states of a recurrent neural network reader. This enables the reader to build query-specific representations of tokens in the document which are further used for answer selection. Our model, the Gated-Attention Reader, outperforms all state-of-the-art models on several large-scale benchmark datasets for this task---the CNN \& Dailymail news stories and Children's Book Test. We also provide a detailed analysis of the performance of our model and several baselines over a subset of questions manually annotated with certain linguistic features. The analysis sheds light on the strengths and weaknesses of several existing models."
One-shot Learning with Memory-Augmented Neural Networks,"Despite recent breakthroughs in the applications of deep neural networks, one setting that presents a persistent challenge is that of ""one-shot learning."" Traditional gradient-based networks require a lot of data to learn, often through extensive iterative training. When new data is encountered, the models must inefficiently relearn their parameters to adequately incorporate the new information without catastrophic interference. Architectures with augmented memory capacities, such as Neural Turing Machines (NTMs), offer the ability to quickly encode and retrieve new information, and hence can potentially obviate the downsides of conventional models. Here, we demonstrate the ability of a memory-augmented neural network to rapidly assimilate new data, and leverage this data to make accurate predictions after only a few samples. We also introduce a new method for accessing an external memory that focuses on memory content, unlike previous methods that additionally use memory location-based focusing mechanisms."
Hierarchical Memory Networks,"Memory networks are neural networks with an explicit memory component that can be both read and written to by the network. The memory is often addressed in a soft way using a softmax function, making end-to-end training with backpropagation possible. However, this is not computationally scalable for applications which require the network to read from extremely large memories. On the other hand, it is well known that hard attention mechanisms based on reinforcement learning are challenging to train successfully. In this paper, we explore a form of hierarchical memory network, which can be considered as a hybrid between hard and soft attention memory networks. The memory is organized in a hierarchical structure such that reading from it is done with less computation than soft attention over a flat memory, while also being easier to train than hard attention over a flat memory. Specifically, we propose to incorporate Maximum Inner Product Search (MIPS) in the training and inference procedures for our hierarchical memory network. We explore the use of various state-of-the art approximate MIPS techniques and report results on SimpleQuestions, a challenging large scale factoid question answering task."
Play and Learn: Using Video Games to Train Computer Vision Models,"Video games are a compelling source of annotated data as they can readily provide fine-grained groundtruth for diverse tasks. However, it is not clear whether the synthetically generated data has enough resemblance to the real-world images to improve the performance of computer vision models in practice. We present experiments assessing the effectiveness on real-world data of systems trained on synthetic RGB images that are extracted from a video game. We collected over 60000 synthetic samples from a modern video game with similar conditions to the real-world CamVid and Cityscapes datasets. We provide several experiments to demonstrate that the synthetically generated RGB images can be used to improve the performance of deep neural networks on both image segmentation and depth estimation. These results show that a convolutional network trained on synthetic data achieves a similar test error to a network that is trained on real-world data for dense image classification. Furthermore, the synthetically generated RGB images can provide similar or better results compared to the real-world datasets if a simple domain adaptation technique is applied. Our results suggest that collaboration with game developers for an accessible interface to gather data is potentially a fruitful direction for future work in computer vision."
TerpreT: A Probabilistic Programming Language for Program Induction,"We study machine learning formulations of inductive program synthesis; given input-output examples, we try to synthesize source code that maps inputs to corresponding outputs. Our aims are to develop new machine learning approaches based on neural networks and graphical models, and to understand the capabilities of machine learning techniques relative to traditional alternatives, such as those based on constraint solving from the programming languages community. 
Our key contribution is the proposal of TerpreT, a domain-specific language for expressing program synthesis problems. TerpreT is similar to a probabilistic programming language: a model is composed of a specification of a program representation (declarations of random variables) and an interpreter describing how programs map inputs to outputs (a model connecting unknowns to observations). The inference task is to observe a set of input-output examples and infer the underlying program. TerpreT has two main benefits. First, it enables rapid exploration of a range of domains, program representations, and interpreter models. Second, it separates the model specification from the inference algorithm, allowing like-to-like comparisons between different approaches to inference. From a single TerpreT specification we automatically perform inference using four different back-ends. These are based on gradient descent, linear program (LP) relaxations for graphical models, discrete satisfiability solving, and the Sketch program synthesis system. 
We illustrate the value of TerpreT by developing several interpreter models and performing an empirical comparison between alternative inference algorithms. Our key empirical finding is that constraint solvers dominate the gradient descent and LP-based formulations. We conclude with suggestions for the machine learning community to make progress on program synthesis."
DeLight: Adding Energy Dimension To Deep Neural Networks,"Physical viability, in particular energy efficiency, is a key challenge in realizing the true potential of Deep Neural Networks (DNNs). In this paper, we aim to incorporate the energy dimension as a design parameter in the higher-level hierarchy of DNN training and execution to optimize for the energy resources and constraints. We use energy characterization to bound the network size in accordance to the pertinent physical resources. An automated customization methodology is proposed to adaptively conform the DNN configurations to the underlying hardware characteristics while minimally affecting the inference accuracy. The key to our approach is a new context and resource aware projection
of data to a lower-dimensional embedding by which learning the correlation between data samples requires significantly smaller number of neurons. We leverage the performance gain achieved as a result of the data projection to enable the training of different DNN architectures which can
be aggregated together to further boost the inference accuracy. Accompanying APIs are provided to facilitate rapid prototyping of an arbitrary DNN application customized to the underlying platform. Proof-of-concept evaluations for deployment of different visual, audio, and smart-sensing benchmarks demonstrate up to 100-fold energy improvement compared to the prior-art DL solutions."
Decoupled Neural Interfaces using Synthetic Gradients,"Training directed neural networks typically requires forward-propagating data through a computation graph, followed by backpropagating error signal, to produce weight updates. All layers, or more generally, modules, of the network are therefore locked, in the sense that they must wait for the remainder of the network to execute forwards and propagate error backwards before they can be updated. In this work we break this constraint by decoupling modules by introducing a model of the future computation of the network graph. These models predict what the result of the modelled subgraph will produce using only local information. In particular we focus on modelling error gradients: by using the modelled synthetic gradient in place of true backpropagated error gradients we decouple subgraphs, and can update them independently and asynchronously i.e. we realise decoupled neural interfaces. We show results for feed-forward models, where every layer is trained asynchronously, recurrent neural networks (RNNs) where predicting one's future gradient extends the time over which the RNN can effectively model, and also a hierarchical RNN system with ticking at different timescales. Finally, we demonstrate that in addition to predicting gradients, the same framework can be used to predict inputs, resulting in models which are decoupled in both the forward and backwards pass -- amounting to independent networks which co-learn such that they can be composed into a single functioning corporation."
Adversarial Autoencoders,"In this paper, we propose the ‚Äúadversarial autoencoder‚Äù (AAE), which is a probabilistic autoencoder that uses the recently proposed generative adversarial networks (GAN) to perform variational inference by matching the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior distribution. Matching the aggregated posterior to the prior ensures that generating from any part of prior space results in meaningful samples. As a result, the decoder of the adversarial autoencoder learns a deep generative model that maps the imposed prior to the data distribution. We show how the adversarial autoencoder can be used in applications such as semi-supervised classification, disentangling style and content of images, unsupervised clustering, dimensionality reduction and data visualization. We performed experiments on MNIST, Street View House Numbers and Toronto Face datasets and show that adversarial autoencoders achieve competitive results in generative modeling and semi-supervised classification tasks."
Virtual Adversarial Training for Semi-Supervised Text Classification,"Adversarial training provides a means of regularizing supervised learning algorithms
while virtual adversarial training is able to extend supervised learning algorithms
to the semi-supervised setting. However, both methods require making
small perturbations to numerous entries of the input vector, which is inappropriate
for sparse high-dimensional inputs such as one-hot word representations. We
extend adversarial and virtual adversarial training to the text domain by applying
perturbations to the word embeddings in a recurrent neural network rather than
to the original input itself. The proposed method achieves state of the art results
on multiple benchmark semi-supervised and purely supervised tasks. We provide
visualizations and analysis showing that the learned word embeddings have improved
in quality and that while training, the model is less prone to overfitting."
Conditional Image Generation with PixelCNN Decoders,"This work explores conditional image generation with a new image density model based on the PixelCNN architecture. The model can be conditioned on any vector, including descriptive labels or tags, or latent embeddings created by other networks. When conditioned on class labels from the ImageNet database, the model is able to generate diverse, realistic scenes representing distinct animals, objects, landscapes and structures. When conditioned on an embedding produced by a convolutional network given a single image of an unseen face, it generates a variety of new portraits of the same person with different facial expressions, poses and lighting conditions. We also show that conditional PixelCNN can serve as a powerful decoder in an image autoencoder. Additionally, the gated convolutional layers in the proposed model improve the log-likelihood of PixelCNN to match the state-of-the-art performance of PixelRNN on ImageNet, with greatly reduced computational cost."
Learning to learn by gradient descent by gradient descent,"The move from hand-designed features to learned features in machine learning has been wildly successful. In spite of this, optimization algorithms are still designed by hand. In this paper we show how the design of an optimization algorithm can be cast as a learning problem, allowing the algorithm to learn to exploit structure in the problems of interest in an automatic way. Our learned algorithms, implemented by LSTMs, outperform generic, hand-designed competitors on the tasks for which they are trained, and also generalize well to new tasks with similar structure. We demonstrate this on a number of tasks, including simple convex problems, training neural networks, and styling images with neural art."
Matching Networks for One Shot Learning,"Learning from a few examples remains a key challenge in machine learning. Despite recent advances in important domains such as vision and language, the standard supervised deep learning paradigm does not offer a satisfactory solution for learning new concepts rapidly from little data. In this work, we employ ideas from metric learning based on deep neural features and from recent advances that augment neural networks with external memories. Our framework learns a network that maps a small labelled support set and an unlabelled example to its label, obviating the need for fine-tuning to adapt to new class types. We then define one-shot learning problems on vision (using Omniglot, ImageNet) and language tasks. Our algorithm improves one-shot accuracy on ImageNet from 87.6% to 93.2% and from 88.0% to 93.8% on Omniglot compared to competing approaches. We also demonstrate the usefulness of the same model on language modeling by introducing a one-shot task on the Penn Treebank."
Learning Representations for Counterfactual Inference,"Observational studies are rising in importance due to the widespread accumulation of data in fields such as healthcare, education, employment and ecology. We consider the task of answering counterfactual questions such as, ""Would this patient have lower blood sugar had she received a different medication?"". We propose a new algorithmic framework for counterfactual inference which brings together ideas from domain adaptation and representation learning. In addition to a theoretical justification, we perform an empirical comparison with previous approaches to causal inference from observational data. Our deep learning algorithm significantly outperforms the previous state-of-the-art."
Density estimation using Real NVP,"Unsupervised learning of probabilistic models is a central yet challenging problem in machine learning. Specifically, designing models with tractable learning, sampling, inference and evaluation is crucial in solving this task. We extend the space of such models using real-valued non-volume preserving (real NVP) transformations, a set of powerful invertible and learnable transformations, resulting in an unsupervised learning algorithm with exact log-likelihood computation, exact sampling, exact inference of latent variables, and an interpretable latent space. We demonstrate its ability to model natural images on four datasets through sampling, log-likelihood evaluation and latent variable manipulations."
On the Expressive Power of Deep Neural Networks,"We study the effects of the depth and width of a neural network on its expressive power.  Precise theoretical and experimental results are derived in the generic setting of neural networks after random initialization. We find that three different measures of functional expressivity:  number of transitions (a measure of non-linearity/complexity), network activation patterns (a new definition with an intrinsic link to hyperplane arrangements in input space) and number of dichotomies, show an exponential dependence on depth but not width.  These three measures are related  to  each  other,  and,  are  also  directly  proportional  to  a  fourth  quantity,trajectory length. Most crucially, we show, both theoretically and experimentally,that  trajectory  length  grows  exponentially  with  depth, which is why all  three measures display an exponential dependence on depth.These results also suggest that parameters earlier in the network have greater influence over the expressive power of the network. So for any layer, its influence on expressivity is determined by the remaining depth of the network after that layer,which is supported by experiments on fully connected and convolutional networks on MNIST and CIFAR-10."
Exponential expressivity in deep neural networks through transient chaos,"We combine Riemannian geometry with the mean field theory of high dimensional chaos to study the nature of signal propagation in generic, deep neural networks with random weights. Our results reveal an order-to-chaos expressivity phase transition, with networks in the chaotic phase computing nonlinear functions whose global curvature grows exponentially with depth but not width. We prove this generic class of deep random functions cannot be efficiently computed by any shallow network, going beyond prior work restricted to the analysis of single functions. Moreover, we formalize and quantitatively demonstrate the long conjectured idea that deep networks can disentangle highly curved manifolds in input space into flat manifolds in hidden space. Our theoretical analysis of the expressive power of deep networks broadly applies to arbitrary nonlinearities, and provides a quantitative underpinning for previously abstract notions about the geometry of deep functions."
Curiosity-driven Exploration in Deep Reinforcement Learning via Bayesian Neural Networks,"Scalable and effective exploration remains a key challenge in reinforcement learning (RL). While there are methods with optimality guarantees in the setting of discrete state and action spaces, these methods cannot be applied in high-dimensional deep RL scenarios. As such, most contemporary RL relies on simple heuristics such as epsilon-greedy exploration or adding Gaussian noise to the controls. This paper introduces Variational Information Maximizing Exploration (VIME), an exploration strategy based on maximization of information gain about the agent's belief of environment dynamics. We propose a practical implementation, using variational inference in Bayesian neural networks which efficiently handles continuous state and action spaces. VIME modifies the MDP reward function, and can be applied with several different underlying RL algorithms. We demonstrate that VIME achieves significantly better performance compared to heuristic exploration methods across a variety of continuous control tasks and algorithms, including tasks with very sparse rewards.
"
Domain-Adversarial Training of Neural Networks,"We introduce a new representation learning approach for domain adaptation, in which data at training and test time come from similar but different distributions. Our approach is directly inspired by the theory on domain adaptation suggesting that, for effective domain transfer to be achieved, predictions must be made based on features that cannot discriminate between the training (source) and test (target) domains. The approach implements this idea in the context of neural network architectures that are trained on labeled data from the source domain and unlabeled data from the target domain (no labeled target-domain data is necessary). As the training progresses, the approach promotes the emergence of features that are (i) discriminative for the main learning task on the source domain and (ii) indiscriminate with respect to the shift between the domains. We show that this adaptation behaviour can be achieved in almost any feed-forward model by augmenting it with few standard layers and a new gradient reversal layer. The resulting augmented architecture can be trained using standard backpropagation and stochastic gradient descent, and can thus be implemented with little effort using any of the deep learning packages. We demonstrate the success of our approach for two distinct classification problems (document sentiment analysis and image classification), where state-of-the-art domain adaptation performance on standard benchmarks is achieved. We also validate the approach for descriptor learning task in the context of person re-identification application."
Residual Networks are Exponential Ensembles of Relatively Shallow Networks,"In this work, we introduce a novel interpretation of residual networks showing they are exponential ensembles. This observation is supported by a large-scale lesion study that demonstrates they behave just like ensembles at test time. Subsequently, we perform an analysis showing these ensembles mostly consist of networks that are each relatively shallow. For example, contrary to our expectations, most of the gradient in a residual network with 110 layers comes from an ensemble of very short networks, i.e., only 10-34 layers deep. This suggests that in addition to describing neural networks in terms of width and depth, there is a third dimension: multiplicity, the size of the implicit ensemble. Ultimately, residual networks do not resolve the vanishing gradient problem by preserving gradient flow throughout the entire depth of the network - rather, they avoid the problem simply by ensembling many short networks together. This insight reveals that depth is still an open research question and invites the exploration of the related notion of multiplicity."
An Actor-Critic Algorithm for Structured Prediction,"We present an approach to training neural networks to generate sequences using actor-critic methods from reinforcement learning (RL). Current log-likelihood training methods are limited by the discrepancy between their training and testing modes, as models must generate tokens conditioned on their previous guesses rather than the ground-truth tokens. We address this problem by introducing a critic network that is trained to predict the value of an output token, given the policy of an actor network. This results in a training procedure that is much closer to the test phase, and allows us to directly optimize for a task-specific score such as BLEU. Crucially, since we leverage these techniques in the supervised learning setting rather than the traditional RL setting, we condition the critic network on the ground-truth output. We show that our method leads to improved performance on both a synthetic task, and for German-English machine translation. Our analysis paves the way for such methods to be applied in natural language generation tasks, such as machine translation, caption generation, and dialogue modelling."
"Control of Memory, Active Perception, and Action in Minecraft","In this paper, we introduce a new set of reinforcement learning (RL) tasks in Minecraft (a flexible 3D world). We then use these tasks to systematically compare and contrast existing deep reinforcement learning (DRL) architectures with our new memory-based DRL architectures. These tasks are designed to emphasize, in a controllable manner, issues that pose challenges for RL methods including partial observability (due to first-person visual observations), delayed rewards, high-dimensional visual observations, and the need to use active perception in a correct manner so as to perform well in the tasks. While these tasks are conceptually simple to describe, by virtue of having all of these challenges simultaneously they are difficult for current DRL architectures. Additionally, we evaluate the generalization performance of the architectures on environments not used during training. The experimental results show that our new architectures generalize to unseen environments better than existing DRL architectures."
Improved Techniques for Training GANs,"We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. We focus on two applications of GANs: semi-supervised learning, and the generation of images that humans find visually realistic. Unlike most work on generative models, our primary goal is not to train a model that assigns high likelihood to test data, nor do we require the model to be able to learn well without using any labels. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3%. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes."
 Key-Value Memory Networks for Directly Reading Documents,"Directly reading documents and being able to answer questions from them is a key problem. To avoid its inherent difficulty, question answering (QA) has been directed towards using Knowledge Bases (KBs) instead, which has proven effective. Unfortunately KBs suffer from often being too restrictive, as the schema cannot support certain types of answers, and too sparse, e.g. Wikipedia contains much more information than Freebase. In this work we introduce a new method, Key-Value Memory Networks, that makes reading documents more viable by utilizing different encodings in the addressing and output stages of the memory read operation. To compare using KBs, information extraction or Wikipedia documents directly in a single framework we construct an analysis tool, MovieQA, a QA dataset in the domain of movies. Our method closes the gap between all three settings. It also achieves state-of-the-art results on the existing WikiQA benchmark."
Adaptive Computation Time for Recurrent Neural Networks,"This paper introduces Adaptive Computation Time (ACT), an algorithm that allows recurrent neural networks to learn how many computational steps to take between receiving an input and emitting an output. ACT requires minimal changes to the network architecture, is deterministic and differentiable, and does not add any noise to the parameter gradients. Experimental results are provided for four synthetic problems: determining the parity of binary vectors, applying binary logic operations, adding integers, and sorting real numbers. Overall, performance is dramatically improved by the use of ACT, which successfully adapts the number of computational steps to the requirements of the problem. We also present character-level language modelling results on the Hutter prize Wikipedia dataset. In this case ACT does not yield large gains in performance; however it does provide intriguing insight into the structure of the data, with more computation allocated to harder-to-predict transitions, such as spaces between words and ends of sentences. This suggests that ACT or other adaptive computation methods could provide a generic method for inferring segment boundaries in sequence data."
Terrain-Adaptive Locomotion Skills Using Deep Reinforcement Learning,"Reinforcement learning offers a promising methodology for developing skills for simulated characters, but typically requires working with sparse hand-crafted features. Building on recent progress in deep reinforcement learning (DeepRL), we introduce a mixture of actor-critic experts (MACE) approach that learns terrain-adaptive dynamic locomotion skills using high-dimensional state and terrain descriptions as input, and parameterized leaps or steps as output actions. MACE learns more quickly than a single actor-critic approach and results in actor-critic experts that exhibit specialization. Additional elements of our solution that contribute towards efficient learning include Boltzmann exploration and the use of initial actor biases to encourage specialization. Results are demonstrated for multiple planar characters and terrain classes."
Learning Transferable Policies for Monocular Reactive MAV Control,"The ability to transfer knowledge gained in previous tasks into new contexts is one of the most important mechanisms of human learning. Despite this, adapting autonomous behavior to be reused in partially similar settings is still an open problem in current robotics research. In this paper, we take a small step in this direction and propose a generic framework for learning transferable motion policies. Our goal is to solve a learning problem in a target domain by utilizing the training data in a different but related source domain. We present this in the context of an autonomous MAV flight using monocular reactive control, and demonstrate the efficacy of our proposed approach through extensive real-world flight experiments in outdoor cluttered environments."
An Uncertain Future: Forecasting from Static Images using Variational Autoencoders,"In a given scene, humans can often easily predict a set of immediate future events that might happen. However, generalized pixel-level anticipation in computer vision systems is difficult because machine learning struggles with the ambiguity inherent in predicting the future. In this paper, we focus on predicting the dense trajectory of pixels in a scene, specifically what will move in the scene, where it will travel, and how it will deform over the course of one second. We propose a conditional variational autoencoder as a solution to this problem. In this framework, direct inference from the image shapes the distribution of possible trajectories, while latent variables encode any necessary information that is not available in the image. We show that our method is able to successfully predict events in a wide variety of scenes and can produce multiple different predictions when the future is ambiguous. Our algorithm is trained on thousands of diverse, realistic videos and requires absolutely no human labeling. In addition to non-semantic action prediction, we find that our method learns a representation that is applicable to semantic vision tasks."
Deep Networks with Stochastic Depth,"Very deep convolutional networks with hundreds of layers
have led to significant reductions in error on competitive benchmarks.
Although the unmatched expressiveness of the many layers can be highly
desirable at test time, training very deep networks comes with its own
set of challenges. The gradients can vanish, the forward flow often diminishes,
and the training time can be painfully slow. To address these
problems, we propose stochastic depth, a training procedure that enables
the seemingly contradictory setup to train short networks and use deep
networks at test time. We start with very deep networks but during training,
for each mini-batch, randomly drop a subset of layers and bypass
them with the identity function. This simple approach complements the
recent success of residual networks. It reduces training time substantially
and improves the test error significantly on almost all data sets that we
used for evaluation. With stochastic depth we can increase the depth
of residual networks even beyond 1200 layers and still yield meaningful
improvements in test error (4.91% on CIFAR-10)."
