{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "# Project 5:  Web Scraping\n",
    "### Finding Underpriced RVs on Craigslist\n",
    "\n",
    "![](https://snag.gy/WrdUMx.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we will be practicing our web scraping skills.  You can use Scrapy or Python requests in order to complete this project.  It may be helpful to write some prototype code in this notebook to test your assumptions, then move it into a Python file that can be run from the command line.\n",
    "\n",
    "> In order to run code from the command line, instead of the notebook, you just need to save your code to a file (with a .py extension), and run it using the Python interpreter:<br><br>\n",
    "> `python my_file.py`\n",
    "\n",
    "You will be building a process to scrape a single category of search results on Craigslist, that can easily be applied to other categories by changing the search terms.  The main goal is to be able to target and scrape a single page given a set of parameters.\n",
    "\n",
    "**If you use Scrapy, provide your code in a folder.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import your libraries for scrapy / requests / pandas / numpy / etc\n",
    "Setup whichever libraries you need. Review past material for reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PREPARE REQUIRED LIBRARIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 1.  Scrape for the largest US cities (non-exhaustive list)\n",
    "Search, research, and scrape Wikipedia for a list of the largest US cities.  There are a few sources but find one that is in a nice table.  We don't want all cities, just signifficant cities.  Examine your source.  Look for what can be differentiable.\n",
    "\n",
    "- Use requests\n",
    "- Build XPath query(ies)\n",
    "- Extract to a list\n",
    "- Clean your list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the necessities\n",
    "from bs4 import BeautifulSoup as bs4\n",
    "import urllib2\n",
    "import numpy as np\n",
    "import requests\n",
    "import pandas as pd\n",
    "import craigslist "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find the table of top cities sorted by population\n",
    "wiki = \"https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population\"\n",
    "page = urllib2.urlopen(wiki)\n",
    "soup = bs4(page)\n",
    "table = soup.find(\"table\", { \"class\" : \"wikitable sortable\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>estimated_15</th>\n",
       "      <th>census_2010</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York</td>\n",
       "      <td>New York</td>\n",
       "      <td>8,550,405</td>\n",
       "      <td>8,175,133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>California</td>\n",
       "      <td>3,971,883</td>\n",
       "      <td>3,792,621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>2,720,546</td>\n",
       "      <td>2,695,598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Houston</td>\n",
       "      <td>Texas</td>\n",
       "      <td>2,296,224</td>\n",
       "      <td>2,100,263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>Pennsylvania</td>\n",
       "      <td>1,567,442</td>\n",
       "      <td>1,526,006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>1,563,025</td>\n",
       "      <td>1,445,632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>San Antonio</td>\n",
       "      <td>Texas</td>\n",
       "      <td>1,469,845</td>\n",
       "      <td>1,327,407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>San Diego</td>\n",
       "      <td>California</td>\n",
       "      <td>1,394,928</td>\n",
       "      <td>1,307,402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dallas</td>\n",
       "      <td>Texas</td>\n",
       "      <td>1,300,092</td>\n",
       "      <td>1,197,816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>San Jose</td>\n",
       "      <td>California</td>\n",
       "      <td>1,026,908</td>\n",
       "      <td>945,942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Austin</td>\n",
       "      <td>Texas</td>\n",
       "      <td>931,830</td>\n",
       "      <td>790,390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>Florida</td>\n",
       "      <td>868,031</td>\n",
       "      <td>821,784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>San Francisco</td>\n",
       "      <td>California</td>\n",
       "      <td>864,816</td>\n",
       "      <td>805,235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Indianapolis</td>\n",
       "      <td>Indiana</td>\n",
       "      <td>853,173</td>\n",
       "      <td>820,445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Columbus</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>850,106</td>\n",
       "      <td>787,033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Fort Worth</td>\n",
       "      <td>Texas</td>\n",
       "      <td>833,319</td>\n",
       "      <td>741,206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Charlotte</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>827,097</td>\n",
       "      <td>731,424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Seattle</td>\n",
       "      <td>Washington</td>\n",
       "      <td>684,451</td>\n",
       "      <td>608,660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Denver</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>682,545</td>\n",
       "      <td>600,158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>El Paso</td>\n",
       "      <td>Texas</td>\n",
       "      <td>681,124</td>\n",
       "      <td>649,121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             city           state estimated_15 census_2010\n",
       "1        New York        New York    8,550,405   8,175,133\n",
       "2     Los Angeles      California    3,971,883   3,792,621\n",
       "3         Chicago        Illinois    2,720,546   2,695,598\n",
       "4         Houston           Texas    2,296,224   2,100,263\n",
       "5    Philadelphia    Pennsylvania    1,567,442   1,526,006\n",
       "6         Phoenix         Arizona    1,563,025   1,445,632\n",
       "7     San Antonio           Texas    1,469,845   1,327,407\n",
       "8       San Diego      California    1,394,928   1,307,402\n",
       "9          Dallas           Texas    1,300,092   1,197,816\n",
       "10       San Jose      California    1,026,908     945,942\n",
       "11         Austin           Texas      931,830     790,390\n",
       "12   Jacksonville         Florida      868,031     821,784\n",
       "13  San Francisco      California      864,816     805,235\n",
       "14   Indianapolis         Indiana      853,173     820,445\n",
       "15       Columbus            Ohio      850,106     787,033\n",
       "16     Fort Worth           Texas      833,319     741,206\n",
       "17      Charlotte  North Carolina      827,097     731,424\n",
       "18        Seattle      Washington      684,451     608,660\n",
       "19         Denver        Colorado      682,545     600,158\n",
       "20        El Paso           Texas      681,124     649,121"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# designate where information should go\n",
    "\n",
    "rank = []\n",
    "city = []\n",
    "state = []\n",
    "est_2015 = []\n",
    "census_2010 = []\n",
    "\n",
    "for row in table.findAll(\"tr\"):\n",
    "    cells = row.findAll(\"td\")\n",
    "    if len(cells) > 0:\n",
    "        rank.append(cells[0].find(text=True))\n",
    "        city.append(cells[1].find(text=True))\n",
    "        state.append(cells[2].find(text=True))\n",
    "        est_2015.append(cells[3].find(text=True))\n",
    "        census_2010.append(cells[4].find(text=True))\n",
    "        #print rank, city, state, est_2015, census_2010\n",
    "        \n",
    "d = {\"city\": city, \"state\": state, \"estimated_15\": est_2015, \n",
    "          \"census_2010\": census_2010}\n",
    "\n",
    "df = pd.DataFrame(d, index = rank, columns = [\"city\", \"state\", \"estimated_15\", \"census_2010\"])\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/xDpSobf.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 1.2 Only retain cities with properly formed ASCII\n",
    "\n",
    "Optionally, filter out any cities with impropper ASCII characters.  A smaller list will be easier to look at.  However you may not need to filter these if you spend more time scraping a more concise city list.  This list should help you narrow down the list of regional Craigslist sites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 2.  Write a function to capture current pricing information via Craigslist in one city.\n",
    "Choose a city from your scraped data, then go to the cooresponding city section on Craigslist, searching for \"rv\" in the auto section.  Write a method that pulls out the prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# san francisco craigslist rv search\n",
    "url = 'http://sfbay.craigslist.org/search/sss?sort=rel&query=rv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_prices(url):\n",
    "    rsp = requests.get(url)\n",
    "    html = bs4(rsp.text, 'html.parser')\n",
    "    prices = html.find_all('p', attrs={'class': 'row'})\n",
    "    titles = html.find_all('a', attrs={\"class\": \"hdrlnk\"})\n",
    "    dates = html.find_all(\"time\")\n",
    "    results = []\n",
    "    for price, title, date in zip(prices, titles, dates):\n",
    "        price = price.find('span', {'class': 'price'})\n",
    "        if price is not None:\n",
    "            price = float(price.text.strip('$'))\n",
    "        else:\n",
    "            price = np.nan\n",
    "        \n",
    "        title_ = title.get_text()\n",
    "        date_ = date.get('title')\n",
    "        results.append([price, title_, date_])\n",
    "    return results\n",
    "\n",
    "\n",
    "def next_page(url, url_base = 'http://sfbay.craigslist.org'):\n",
    "    rsp = requests.get(url)\n",
    "    text = bs4(rsp.text)\n",
    "    #print text\n",
    "    next_page_rel = text.find('a', {'title': 'next page'}).get('href')\n",
    "    next_page = url_base + next_page_rel\n",
    "    return next_page "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[33016.0,\n",
       "  u'2016 Keystone RV Premier 30RIPR***1/2 TON TOWABLE***LARGE LIVING SPACE***',\n",
       "  u'Fri 21 Oct 02:43:26 PM']]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = find_prices('http://sfbay.craigslist.org/search/sss?sort=rel&query=rv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_titles(url):\n",
    "    #url_base = 'http://sfbay.craigslist.org/search/sss?sort=rel&query=rv'\n",
    "    rsp = requests.get(url)\n",
    "    html = bs4(rsp.text, \"html.parser\")\n",
    "    results = html.find_all('a', attrs={\"class\": \"hdrlnk\"})\n",
    "    #print results\n",
    "    titles = []\n",
    "    for title in results:\n",
    "        title_ = title.get_text()\n",
    "        titles.append(title_)\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_dates(url):\n",
    "    rsp = requests.get(url)\n",
    "    html = bs4(rsp.text, \"html.parser\")\n",
    "    results = html.find_all(\"time\")\n",
    "    #rsp = requests.get(url)\n",
    "    #print results\n",
    "    dates = []\n",
    "    for date in results:\n",
    "        date_ = date.get_text()\n",
    "        dates.append(date_)\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "url = 'http://sfbay.craigslist.org/search/sss?sort=rel&query=rv'\n",
    "prices = {}\n",
    "for i in range(10):\n",
    "    prices[i] = find_prices(url)\n",
    "    url = next_page(url)\n",
    "for l in prices.values():\n",
    "    print len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "url = 'http://sfbay.craigslist.org/search/sss?sort=rel&query=rv'\n",
    "titles = {}\n",
    "for i in range(10):\n",
    "    titles[i] = find_titles(url)\n",
    "    url = next_page(url)\n",
    "#print titles\n",
    "for l in titles.values():\n",
    "    print len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "url = 'http://sfbay.craigslist.org/search/sss?sort=rel&query=rv'\n",
    "dates = {}\n",
    "for i in range(10):\n",
    "    dates[i] = find_dates(url)\n",
    "    url = next_page(url)\n",
    "#print titles\n",
    "for l in dates.values():\n",
    "    print len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 2.1 Create a mapping of cities to cooresponding regional Craigslist URLs\n",
    "\n",
    "Major US cities on Craigslist typically have their own cooresponding section (ie: SFBay Area, NYC, Boston, Miami, Seattle, etc).  Later, you will use these to query search results for various metropolitian regions listed on Craigslist.  Between the major metropolitan Craigslist sites, the only thing that will differ is the URL's that correspond to them.\n",
    "\n",
    "The point of the \"mapping\":  Create a data structure that allows you to iterate with both the name of the city from Wikipedia, with the cooresponding variable that that will allow you to construct each craigslist URL for each region.\n",
    "\n",
    "> For San Francsico (the Bay Area metropolitan area), the url for the RV search result is:\n",
    "> http://sfbay.craigslist.org/search/sss?query=rv\n",
    ">\n",
    "> The convention is http://[region].craigslist.org/search/sss?query=rf\n",
    "> Replacing [region] with the cooresponding city name will allow you to quickly iterate through each regional Craigslist site, and scrape the prices from the search results.  Keep this in mind while you build this \"mapping\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "city_dict = {\"los angeles\": \"https://losangeles.craigslist.org/search/sss?query=rv&sort=rel\",\n",
    "          \"san diego\": \"https://sandiego.craigslist.org/search/sss?query=rv&sort=rel\",\n",
    "          \"san jose\": \"https://sfbay.craigslist.org/search/sby/sss?query=rv&sort=rel\",\n",
    "          \"san francisco\": \"https://sfbay.craigslist.org/search/sss?sort=rel&query=rv\"\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 3. Define a function to caculate mean and median price per city.\n",
    "\n",
    "Now that you've created a list of cities you want to scrape, adapt your solution for grabbing data in one region site, to grab data for all regional sites that you collected, then calculate the mean and median price of RV results from each city.\n",
    "\n",
    "> Look at the URLs from a few different regions (ie: portland, phoenix, sfbay), and find what they have in common.  Determine the area in the URL string that needs to change the least, and figure out how to replace only that portion of the URL in order to iterate through each city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grab_prices(city_name):\n",
    "    url = city_dict[city_name]\n",
    "    for i in range(5):\n",
    "        prices[i] = find_prices(url)\n",
    "        url = next_page(url)\n",
    "    flat_price_list = [p for price_page in prices.values() for p in price_page]\n",
    "    return flat_price_list\n",
    "#grab_prices(\"los angeles\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 4. Run your scraping process, and save your results to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grab_titles(city_name):\n",
    "    url = city_dict[city_name]\n",
    "    for i in range(5):\n",
    "        titles[i] = find_titles(url)\n",
    "        url = next_page(url)\n",
    "    flat_title_list = [t for title_page in titles.values() for t in title_page]\n",
    "    return flat_title_list\n",
    "#grab_titles(\"los angeles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grab_dates(city_name):\n",
    "    url = city_dict[city_name]\n",
    "    for i in range(5):\n",
    "        dates[i] = find_dates(url)\n",
    "        url = next_page(url)\n",
    "    flat_dates_list = [d for date_page in dates.values() for d in date_page]\n",
    "    return flat_dates_list\n",
    "#grab_dates(\"los angeles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left;margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 5. Do an analysis of the RV market.\n",
    "\n",
    "Go head we'll wait.  Anything notable about the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = [\"City\", \"Price\"]\n",
    "my_dict = {\n",
    " \"City\": [\"SF\"] * len(grab_prices(\"san francisco\")) + \n",
    "         [\"LA\"] * len(grab_prices(\"los angeles\")) +\n",
    "         [\"SD\"] * len(grab_prices(\"san diego\")) +\n",
    "         [\"SJ\"] * len(grab_prices(\"san jose\")),\n",
    " \"Prices\": grab_prices(\"san francisco\") +\n",
    "           grab_prices(\"los angeles\") +\n",
    "           grab_prices(\"san diego\") +\n",
    "           grab_prices(\"san jose\"),\n",
    " \"Title\":  grab_titles(\"san francisco\") +\n",
    "           grab_titles(\"los angeles\") +\n",
    "           grab_titles(\"san diego\") +\n",
    "           grab_titles(\"san jose\"),\n",
    " \"Date\":   grab_dates(\"san francisco\") +\n",
    "           grab_dates(\"los angeles\") +\n",
    "           grab_dates(\"san diego\") +\n",
    "           grab_dates(\"san jose\")\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(my_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Date</th>\n",
       "      <th>Prices</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SF</td>\n",
       "      <td>Oct 20</td>\n",
       "      <td>13995.0</td>\n",
       "      <td>2013 Cruiser RV Shadow Cruiser S-185FBS (4345)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SF</td>\n",
       "      <td>Oct 20</td>\n",
       "      <td>29995.0</td>\n",
       "      <td>2011 Keystone RV Avalanche 290RL (4359)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SF</td>\n",
       "      <td>Oct 20</td>\n",
       "      <td>42995.0</td>\n",
       "      <td>2016 Keystone RV Outback 315FRE (10397)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SF</td>\n",
       "      <td>Oct 20</td>\n",
       "      <td>23495.0</td>\n",
       "      <td>2016 Keystone RV Outback Terrain 245TBH - Stoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SF</td>\n",
       "      <td>Oct 20</td>\n",
       "      <td>17999.0</td>\n",
       "      <td>SALE - 2016 Keystone RV Springdale 18ft. with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  City    Date   Prices                                              Title\n",
       "0   SF  Oct 20  13995.0     2013 Cruiser RV Shadow Cruiser S-185FBS (4345)\n",
       "1   SF  Oct 20  29995.0            2011 Keystone RV Avalanche 290RL (4359)\n",
       "2   SF  Oct 20  42995.0            2016 Keystone RV Outback 315FRE (10397)\n",
       "3   SF  Oct 20  23495.0  2016 Keystone RV Outback Terrain 245TBH - Stoc...\n",
       "4   SF  Oct 20  17999.0  SALE - 2016 Keystone RV Springdale 18ft. with ..."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3891, 4)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prices</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LA</th>\n",
       "      <td>25354.787645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>23877.729219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF</th>\n",
       "      <td>24882.052830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SJ</th>\n",
       "      <td>22724.629827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Prices\n",
       "City              \n",
       "LA    25354.787645\n",
       "SD    23877.729219\n",
       "SF    24882.052830\n",
       "SJ    22724.629827"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"City\").mean()\n",
    "# it's better to sell in LA and buy in SJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prices</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LA</th>\n",
       "      <td>14999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>12000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF</th>\n",
       "      <td>14588.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SJ</th>\n",
       "      <td>10300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prices\n",
       "City         \n",
       "LA    14999.0\n",
       "SD    12000.0\n",
       "SF    14588.0\n",
       "SJ    10300.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"City\").median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Prices</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th>City</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Oct  1</th>\n",
       "      <th>SJ</th>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Oct  3</th>\n",
       "      <th>LA</th>\n",
       "      <td>4500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>4500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF</th>\n",
       "      <td>4500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SJ</th>\n",
       "      <td>7018.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Oct  5</th>\n",
       "      <th>LA</th>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF</th>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SJ</th>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Oct  6</th>\n",
       "      <th>LA</th>\n",
       "      <td>26900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>26900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF</th>\n",
       "      <td>26900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SJ</th>\n",
       "      <td>26900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oct  7</th>\n",
       "      <th>SJ</th>\n",
       "      <td>14900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Oct 10</th>\n",
       "      <th>SJ</th>\n",
       "      <td>19800.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Oct 12</th>\n",
       "      <th>LA</th>\n",
       "      <td>9500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>9500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF</th>\n",
       "      <td>9500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SJ</th>\n",
       "      <td>9500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Oct 13</th>\n",
       "      <th>LA</th>\n",
       "      <td>17516.391304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>17861.931818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF</th>\n",
       "      <td>17861.931818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SJ</th>\n",
       "      <td>23051.377778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Oct 14</th>\n",
       "      <th>LA</th>\n",
       "      <td>16100.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>15360.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF</th>\n",
       "      <td>15571.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SJ</th>\n",
       "      <td>8029.135135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Oct 15</th>\n",
       "      <th>LA</th>\n",
       "      <td>11532.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>11889.906250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF</th>\n",
       "      <td>11987.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Oct 20</th>\n",
       "      <th>SD</th>\n",
       "      <td>24409.657588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF</th>\n",
       "      <td>25482.265152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SJ</th>\n",
       "      <td>26036.559387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sep 20</th>\n",
       "      <th>SJ</th>\n",
       "      <td>3500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Sep 21</th>\n",
       "      <th>LA</th>\n",
       "      <td>170.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>170.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF</th>\n",
       "      <td>170.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SJ</th>\n",
       "      <td>170.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Sep 22</th>\n",
       "      <th>LA</th>\n",
       "      <td>170.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>170.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF</th>\n",
       "      <td>170.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SJ</th>\n",
       "      <td>170.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Sep 23</th>\n",
       "      <th>LA</th>\n",
       "      <td>140.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>140.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF</th>\n",
       "      <td>140.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SJ</th>\n",
       "      <td>140.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Sep 25</th>\n",
       "      <th>LA</th>\n",
       "      <td>4545.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>4545.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF</th>\n",
       "      <td>4545.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SJ</th>\n",
       "      <td>4545.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sep 27</th>\n",
       "      <th>SJ</th>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Sep 28</th>\n",
       "      <th>LA</th>\n",
       "      <td>16500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>16500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF</th>\n",
       "      <td>16500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SJ</th>\n",
       "      <td>16500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sep 29</th>\n",
       "      <th>SJ</th>\n",
       "      <td>20900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">Sep 30</th>\n",
       "      <th>LA</th>\n",
       "      <td>11997.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SD</th>\n",
       "      <td>11997.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SF</th>\n",
       "      <td>11997.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SJ</th>\n",
       "      <td>26211.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Prices\n",
       "Date   City              \n",
       "Oct  1 SJ     2000.000000\n",
       "Oct  3 LA     4500.000000\n",
       "       SD     4500.000000\n",
       "       SF     4500.000000\n",
       "       SJ     7018.823529\n",
       "Oct  5 LA      250.000000\n",
       "       SD      250.000000\n",
       "       SF      250.000000\n",
       "       SJ      250.000000\n",
       "Oct  6 LA    26900.000000\n",
       "       SD    26900.000000\n",
       "       SF    26900.000000\n",
       "       SJ    26900.000000\n",
       "Oct  7 SJ    14900.000000\n",
       "Oct 10 SJ    19800.000000\n",
       "Oct 12 LA     9500.000000\n",
       "       SD     9500.000000\n",
       "       SF     9500.000000\n",
       "       SJ     9500.000000\n",
       "Oct 13 LA    17516.391304\n",
       "       SD    17861.931818\n",
       "       SF    17861.931818\n",
       "       SJ    23051.377778\n",
       "Oct 14 LA    16100.250000\n",
       "       SD    15360.952381\n",
       "       SF    15571.666667\n",
       "       SJ     8029.135135\n",
       "Oct 15 LA    11532.181818\n",
       "       SD    11889.906250\n",
       "       SF    11987.416667\n",
       "...                   ...\n",
       "Oct 20 SD    24409.657588\n",
       "       SF    25482.265152\n",
       "       SJ    26036.559387\n",
       "Sep 20 SJ     3500.000000\n",
       "Sep 21 LA      170.000000\n",
       "       SD      170.000000\n",
       "       SF      170.000000\n",
       "       SJ      170.000000\n",
       "Sep 22 LA      170.000000\n",
       "       SD      170.000000\n",
       "       SF      170.000000\n",
       "       SJ      170.000000\n",
       "Sep 23 LA      140.000000\n",
       "       SD      140.000000\n",
       "       SF      140.000000\n",
       "       SJ      140.000000\n",
       "Sep 25 LA     4545.000000\n",
       "       SD     4545.000000\n",
       "       SF     4545.000000\n",
       "       SJ     4545.000000\n",
       "Sep 27 SJ      250.000000\n",
       "Sep 28 LA    16500.000000\n",
       "       SD    16500.000000\n",
       "       SF    16500.000000\n",
       "       SJ    16500.000000\n",
       "Sep 29 SJ    20900.000000\n",
       "Sep 30 LA    11997.500000\n",
       "       SD    11997.500000\n",
       "       SF    11997.500000\n",
       "       SJ    26211.000000\n",
       "\n",
       "[78 rows x 1 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"Date\", \"City\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"Month\"] = df[\"Date\"].apply(lambda x: x.split(\" \")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Date</th>\n",
       "      <th>Prices</th>\n",
       "      <th>Title</th>\n",
       "      <th>Month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SF</td>\n",
       "      <td>Oct 20</td>\n",
       "      <td>13995.0</td>\n",
       "      <td>2013 Cruiser RV Shadow Cruiser S-185FBS (4345)</td>\n",
       "      <td>Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SF</td>\n",
       "      <td>Oct 20</td>\n",
       "      <td>29995.0</td>\n",
       "      <td>2011 Keystone RV Avalanche 290RL (4359)</td>\n",
       "      <td>Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SF</td>\n",
       "      <td>Oct 20</td>\n",
       "      <td>42995.0</td>\n",
       "      <td>2016 Keystone RV Outback 315FRE (10397)</td>\n",
       "      <td>Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SF</td>\n",
       "      <td>Oct 20</td>\n",
       "      <td>23495.0</td>\n",
       "      <td>2016 Keystone RV Outback Terrain 245TBH - Stoc...</td>\n",
       "      <td>Oct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SF</td>\n",
       "      <td>Oct 20</td>\n",
       "      <td>17999.0</td>\n",
       "      <td>SALE - 2016 Keystone RV Springdale 18ft. with ...</td>\n",
       "      <td>Oct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  City    Date   Prices                                              Title  \\\n",
       "0   SF  Oct 20  13995.0     2013 Cruiser RV Shadow Cruiser S-185FBS (4345)   \n",
       "1   SF  Oct 20  29995.0            2011 Keystone RV Avalanche 290RL (4359)   \n",
       "2   SF  Oct 20  42995.0            2016 Keystone RV Outback 315FRE (10397)   \n",
       "3   SF  Oct 20  23495.0  2016 Keystone RV Outback Terrain 245TBH - Stoc...   \n",
       "4   SF  Oct 20  17999.0  SALE - 2016 Keystone RV Springdale 18ft. with ...   \n",
       "\n",
       "  Month  \n",
       "0   Oct  \n",
       "1   Oct  \n",
       "2   Oct  \n",
       "3   Oct  \n",
       "4   Oct  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prices</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Oct</th>\n",
       "      <td>24425.706016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sep</th>\n",
       "      <td>9475.476190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Prices\n",
       "Month              \n",
       "Oct    24425.706016\n",
       "Sep     9475.476190"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"Month\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Date</th>\n",
       "      <th>Prices</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Oct</th>\n",
       "      <td>3849</td>\n",
       "      <td>3849</td>\n",
       "      <td>3075</td>\n",
       "      <td>3849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sep</th>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       City  Date  Prices  Title\n",
       "Month                           \n",
       "Oct    3849  3849    3075   3849\n",
       "Sep      42    42      42     42"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"Month\").count()\n",
    "# September is \"low\" because the scraping settings only go so far back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "### 5.1 Does it makes sense to buy RVs in one region and sell them in another?\n",
    "\n",
    "Assuming the cost of shipping or driving from one regional market to another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# see above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/xDpSobf.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "### 5.2 Can you pull out the \"make\" from the markup and include that in your analyis?\n",
    "How reliable is this data and does it make sense?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/xDpSobf.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "### 5.3 Are there any other variables you could pull out of the markup to help describe your dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/xDpSobf.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 6. Move your project into scrapy (if you haven't used Scrapy yet)\n",
    "\n",
    ">Start a project by using the command `scrapy startproject [projectname]`\n",
    "> - Update your settings.py (review our past example)\n",
    "> - Update your items.py\n",
    "> - Create a spiders file in your `[project_name]/[project_name]/spiders` directory\n",
    "\n",
    "You can update your spider class with the complete list of craigslist \"start urls\" to effectively scrape all of the regions.  Start with one to test.\n",
    "\n",
    "Updating your parse method with the method you chose should require minimal changes.  It will require you to update your parse method to use the response parameter, and an item model (defined in items.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# see attached .py's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/GCAf1UX.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 7.  Chose another area of Craigslist to scrape.\n",
    "\n",
    "**Choose an area having more than a single page of results, then scrape multiple regions, multiple pages of search results and or details pages.**\n",
    "\n",
    "This is the true exercise of being able to understand how to succesffuly plan, develop, and employ a broader scraping strategy.  Even though this seems like a challenging task, a few tweeks of your current code can make this very managable if you've pieced together all the touch points.  If you are still confused as to some of the milestones within this process, this is an excellent opportunity to round out your understanding, or help you build a list of questions to fill in your gaps.\n",
    "\n",
    "_Use Scrapy!  Provide your code in this project directory when you submit this project._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Optional: Interview Questions\n",
    "\n",
    "---- \n",
    "\n",
    "### SQL Practice\n",
    "\n",
    "1)\n",
    "We have a deliveries table with 3000 rows\n",
    "\n",
    "`SELECT * FROM deliveries; \n",
    "-- 3000 rows in set (0.05 sec) `\n",
    "\n",
    "15 of those orders are from a customer with the customer_id_number=32\n",
    "\n",
    "`SELECT * FROM deliveries WHERE customer_id_number = 32;\n",
    "-- 15 rows in set (0.10 sec)`\n",
    "\n",
    "Yet, when we SELECT the number of orders that are not from customer_id_number = 32, we only get 2960 results:\n",
    "\n",
    "`SELECT * FROM deliveries WHERE customer_id_number <> 32;\n",
    "-- 2960 rows in set (0.11 sec)`\n",
    "\n",
    "**Question: Whatâ€™s wrong? And why might this be the case? Modify your code to fix this. **\n",
    "\n",
    "2) Construct the following tables:\n",
    "\n",
    "`mysql> SELECT * FROM Employee;\n",
    "+--------+----------+--------+\n",
    "| emp_id | emp_name | salary |\n",
    "+--------+----------+--------+\n",
    "| 1      | James    |   2000 |\n",
    "| 2      | Jack     |   4000 |\n",
    "| 3      | Henry    |   6000 |\n",
    "| 4      | Tom      |   8000 |\n",
    "+--------+----------+--------+\n",
    "4 rows IN SET (0.00 sec)`\n",
    "\n",
    "\n",
    "`mysql> SELECT * FROM Department;\n",
    "+---------+-----------+\n",
    "| dept_id | dept_name |\n",
    "+---------+-----------+\n",
    "| 101     | Sales     |\n",
    "| 102     | Marketing |\n",
    "| 103     | Finance   |\n",
    "| 104     | Accounting   |\n",
    "+---------+-----------+\n",
    "3 rows IN SET (0.00 sec)`\n",
    "\n",
    "\n",
    "`mysql> SELECT * FROM Register;\n",
    "+--------+---------+\n",
    "| emp_id | dept_id |\n",
    "+--------+---------+\n",
    "|      1 |     101 |\n",
    "|      2 |     102 |\n",
    "|      3 |     103 |\n",
    "|      4 |     102 |\n",
    "+--------+---------+\n",
    "4 rows IN SET (0.00 sec)`\n",
    "\n",
    "** Questions: ** \n",
    "- Which employees belong to which department? Show this using one line of code (hint: more than one join) \n",
    "- What is the total marketing salary? \n",
    "- Using a join, can you show that there are no employees in accounting? \n",
    "\n",
    "\n",
    "\n",
    "3) Given an Employee table which has 3 fields â€“ Id (Primary key), Salary and Manager Id, where manager id is the id of the employee that manages the current employee, find all employees that make more than their manager in terms of salary. Create the table and write the code that finds this\n",
    "\n",
    "\n",
    "--- \n",
    "### Predictive Modeling\n",
    "\n",
    "- What are some differences you would expect in a regression model that minimizes squared error, versus a model that minimizes absolute error? In which cases would each error  metric be appropriate?\n",
    "\n",
    "- What error metric would you use to evaluate how good a binary classifier is? What if the classes are imbalanced?  What if there are more than 2 groups?\n",
    "\n",
    "- What are various ways to predict a binary response variable? Can you compare two of them and tell me when one would be more appropriate? Whatâ€™s the difference logistic regression and SVMs? \n",
    "\n",
    "- What is the difference between the loss functions used by SVMs and Logistic Regression? \n",
    "\n",
    "- What is R-squared? What are some other metrics that could be better than R-squared and why?\n",
    "\n",
    "- You run your regression on different subsets of your data, and find that in each subset, the beta value for a certain variable varies wildly. What could be the issue here?\n",
    "\n",
    "\n",
    "--- \n",
    "### Coding Questions \n",
    "\n",
    "- Given a sorted array and a number x, find a pair in array whose sum is closest to x. What is the time complexity of your algorithm? \n",
    "    \n",
    "    `Examples:`\n",
    "        Input: arr[] = {10, 22, 28, 29, 30, 40}, x = 54\n",
    "        Output: 22 and 30\n",
    "\n",
    "        Input: arr[] = {1, 3, 4, 7, 10}, x = 15\n",
    "        Output: 4 and 10\n",
    "        \n",
    "- Check out this video on Linear Time Algorithm for finding the median: https://www.youtube.com/watch?v=_xntajCBLoE. Implement your version of this algorithm in Python. \n",
    "\n",
    "- Search in an almost sorted array: Given an array which is sorted, but after sorting some elements are moved to either of the adjacent positions, i.e., arr[i] may be present at arr[i+1] or arr[i-1]. Write an efficient function to search an element in this array. Basically the element arr[i] can only be swapped with either arr[i+1] or arr[i-1]. For example consider the array {2, 3, 10, 4, 40}, 4 is moved to next position and 10 is moved to previous position. [Hint: You can do this O(log n) time complexity]\n",
    "\n",
    "    `Examples: `\n",
    "        Input: arr[] =  {10, 3, 40, 20, 50, 80, 70}, key = 40\n",
    "        Output: 2 \n",
    "        Output is index of 40 in given array\n",
    "\n",
    "        Input: arr[] =  {10, 3, 40, 20, 50, 80, 70}, key = 90\n",
    "        Output: -1\n",
    "        -1 is returned to indicate element is not present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1 coding question 1\n",
    "import numpy as np\n",
    "def find_best_pair(arr, val):\n",
    "    L, R = 0, len(arr) -1\n",
    "    diff = float(\"inf\")\n",
    "    while L < R:\n",
    "        temp_sum = arr[L] + arr[R]\n",
    "        temp_diff = abs(temp_sum - val)\n",
    "        if temp_diff < diff:\n",
    "            diff = temp_diff\n",
    "            close_pair = arr[L], arr[R]\n",
    "        if temp_sum > val:\n",
    "            R -= 1\n",
    "        elif temp_sum == val:\n",
    "            return close_pair\n",
    "        else:\n",
    "            L += 1\n",
    "    return close_pair\n",
    "find_best_pair([1, 2, 5, 9, 11, 17, 56], 24)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
